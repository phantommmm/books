### HTTP

#### HTTP 1.0 1.1区别？

1.**连接：**1.0默认**短连接**，一个请求建立一个连接，用完关闭。通过报文头部 **Keep-alive**设置长连接。

​				1.1默认**长连接**，并且是**并行管道**连接，即若干个请求串行化单线程处理，后面请求等到前面请求返回才能获得执行机会。

​				通过报文头部 Connetcion:**close**关闭长连接，或者收到错误报文会关闭长连接。

2.**Host域：**1.0主机通过 IP+端口 绑定。

​					1.1增加Host域，一台服务器共享多个虚拟主机。

3.**新增状态码：**100 客户端首先发送 request header 如果服务端接受此请求则返回100

​						   409 请求和资源的当前状态相冲突，请求不成功。通常和PUT有关，上传版本不正确的文件。

​						   410，请求的资源已经永久性删除。

#### HTTP 1.0 2.0区别?

1.**多路复用** 1.0只能一个一个数据包有序发送。一个tcp连接可以对应多个http请求。

​					2.0多个请求同时在一个连接上并行执行，每个request对应一个id，接收方根据request id分辨请求。 一个tcp连接可以**同时**对应多个http请求。

2.**服务端推送** 服务器顺便把客户端需要的资源推送到客户端，例如静态资源。

3.**header压缩** 1.0header带有大量信息，并且每次都要重复发送

​						 2.0使用encoder，双方cache一份header fields表，避免重复header的传输

4.**二进制格式** 1.0基于文本协议 文本的表现形式有多样性，要做到健壮性考虑的场景很多。

​						2.0基于二进制格式

#### HTTP无状态中的状态指的是

**状态 指的是客户端和服务端在临时会话中产生的数据**

无状态是指，当浏览器发送请求给服务器的时候，服务器响应，但是同一个浏览器再发送请求给服务器的时候，他会响应，但是他不知道你就是刚才那个浏览器，简单地说，就是服务器不会去记得你，所以是无状态协议。
而DNS是有状态协议 。

简而言之，把每个请求作为与之前任何请求都无关的独立的事务的服务器。

现在使用的Session等方法辨别用户，这个也不是在 HTTP 协议层面来实现的，而是由后端服务器来实现的，所以现在依然是无状态协议。

**HTTP为什么设置为无状态协议**

1.无状态就意味着服务端可以根据需要将请求分发到集群的任何一个节点，对缓存、负载均衡有明显的好处

2.早期web简单，主要是浏览功能，不需要状态。后续发展使用cookie/session扩展。

**无状态协议**

HTTP、UDP、IP

**有状态协议**

TCP、FTP、SMTP、DNS

```
IP是无状态的，它只负责将一个IP包发送到指定的IP地址上去。它不会考虑这个包与前面已经发送的包和后面的包的联系。（可能是重发包、可能是不连续包，它不管）。

TCP是有状态的，它通过包头中的一些控制字段（序列编码等）来表明各个包之间的关系（前后关系，重包与否等等）。所以，通过这个协议你可以做到一个可靠的传输。

UDP是无状态的，它仅仅是在IP上加了Port，其他的事情什么也不干。这样它不可能做到可靠的传输，同样也不需要连接。
```



#### 打开网页慢原因？

带宽不足

CPU或内存被占满

DNS解析慢

接收数据时间过长（请求的内容过大）

加载某个资源太慢

后端代码问题，死锁等

#### DNS使用的是TCP还是UDP？

DNS占用53号端口，同时使用TCP和UDP协议。

**区域传送**

DNS规定了2种类型的DNS服务器，主DNS服务器和辅助DNS服务器，在一个区中主DNS服务器从自己本机的数据文件中读取该区的DNS数据信息，而辅助DNS服务器则从区的主DNS服务器中读取该区的DNS数据信息。

当一个辅助DNS服务器启动时，它需要与主DNS服务器通信，并加载数据信息，即区域传送。

**DNS在区域传输时使用TCP 其它使用UDP**

辅域名服务器会定时（一般3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，会执行一次区域传送，进行数据同步。

区域传送使用TCP而不是UDP，因为数据同步传送的数据量比一个请求应答的数据量要多得多 ，可靠连接保证数据准确性。

UDP报文最大长度是512字节，而TCP允许报文超过512字节。                      

客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。

不用经过三次握手，这样DNS服务器负载更低，响应更快。

#### HTTP与SMTP的区别

一方面，HTTP协议主要是一个拉协议(pull protocol),即人们可以在方便的时候转载web服务器上的信息，也就是说，用户使用HTTP协议从该服务器上拉取信息。即TCP协议是由想获取文件的机器所发起的。另一方面，SMTP基本上是一个推协议(push protocol),即发送邮件服务器把文件推向邮件服务器。

第二个区别，SMTP要求每个报文都使用7位ASCII码格式。如果某报文包含了非7位ASCII字符或者二进制数据，如图形文件，则该报文必须按照7位ASCII码进行编码，而HTTP没有此限制。

第三个区别HTTP是把每个对象封装在各自的（不同）HTTP响应消息中。SMTP是把同一个邮件内的各个对象置于同一个邮件消息中。

#### 为什么域名访问不用加端口号而IP访问要？

域名访问其实是加了端口的，例如 HTTP 默认端口80 HTTPS 443，其实是加了对于协议的默认端口。

#### GET和POST区别？

Get用于查询/获取资源，Post用于更新/修改资源。

Get请求幂等， Post请求回退后会再次发送请求。

幂等：对同一URL的多个请求应该返回相同的结果。数学中，对一个数进行多次相同的运算，结果一样，则该运算时幂等的。

GET请求会被浏览器主动cache，而POST不会，除非手动设置。 

GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。 

GET请求在URL中传送的参数是有长度限制的，而POST么有。 

对参数的数据类型，GET只接受ASCII字符，而POST没有限制。 

GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。 

GET参数通过URL传递，POST放在Request body中.

#### 转发和重定向区别？

**转发**就是服务器中，一个servlet对这个请求进行了处理，但是，没有返回，而是给了服务器另一个sevrlet再加工，而后返回。这个过程，请求头和响应头用的都是同一个。里面的协议，编码，数据都不改变。即：两个servlet间是实现了通信。
**重定向**就是客户端发送信息，到达了服务器，而后服务器接处理了请求后，返回消息给浏览器，并且告诉他，还要进行后续的操作，返回状态码为301，浏览器立即进一步发送请求。这个过程是两次请求，而非servlet之间的通信。

表现是：重定向浏览器上的url会改变，转发并不会改变。

#### HTTP状态码

**301永久重定向**

请求的资源已被移动到新的位置，返回新的地址和301，后面再次访问会直接去访问新的地址

比如，我们访问 **http**://www.baidu.com 会跳转到 **https**://www.baidu.com，发送请求之后，就会返回301状态码，然后返回一个location，提示新的地址，浏览器就会拿着这个新的地址去访问。 

　　**注意： 301请求是可以缓存的， 即通过看status code，可以发现后面写着from cache。**

　  

**302临时重定向**

一般用于临时跳转，后面再次访问会还是访问旧的地址

比如未登陆的用户访问用户中心重定向到登录页面。访问404页面会重新定向到首页。 



**304 未修改**

所请求的资源在缓存中未修改，表明直接从缓存中获取资源，服务端响应不会返回资源内容。

每个资源请求完成后，通常会被缓存在客户端，并会记录资源的有效时间和修改时间。当客户再次请求该资源，客户端首先从缓存中查找该资源。如果该资源存在，并且在有效期，则不请求服务器，就不会产生对应的请求数据包。

**303**

请求已经被处理，返回URL，客户端应该向返回的URL重新发送请求。

**307**

请求未被处理，因为请求资源不在本地，在响应URL中，客户端应该向返回的URL重新发送请求。

**区别**

对POST，PUT或者DELETE请求

303表明：操作已经成功执行，但响应实体将不随本响应一起返回，若客户端想要获取响应实体主体，它需要向另一个URI发送GET请求

307表明：服务器尚未执行操作，客户端需要向Location报头里的那个URI重新提交整个请求。

**409 请求冲突**

你请求的操作会导致服务器的资源处于一种不可能或不一致的状态。例如你试图修改某个用户的用户名，而修改后的用户名与其他存在的用户名冲突了。


### TCP UDP

#### TCP UDP区别？

1.TCP是面向**字节流**的传输方式，而UDP是面向**数据报**的传输方式。

2.TCP是面向连接，UDP不是面向连接。

3.TCP有保证可靠传输机制（比如对数据包进行排序、效验和、流量控制、拥塞控制、停止等待协议、超时重传、滑动窗口） UDP没有但是传输效率高。

4.TCP首部字段20-60字节，UDP8字节（包括源端口号、目标端口号、数据报长度、校验值）。

#### IP协议也不可靠传输服务，为什么还需要UDP协议？

一个包到达了一个ip地址，这个包被给了这台机器的应用程序中的其中一个。谁决定哪个应用程序得到这个包呢？此时就需要demultiplexing(分用)。
什么叫分用

当目的主机收到一个以太网数据帧时，数据就开始从协议栈中有底向上升，同时去掉各层协议加上的报文首部。每层协议盒都要去检查报文首部的协议标识，以确定接受数据的上层协议。这个过程称作分用（Demultiplexing）（ip是网络层，上层udp是传输层）

也就是此时要交给上层了。上层UDP根据port来识别那个应用程序。

分层协议中，网络层协议到主机，传输层协议到应用。多个应用可以共同使用同一个ip地址。

**（一）协议复用**

IP Header 协议字段只有一个字节，即最多提供255种协议的辨识，而且基本都被大牌协议所霸占着，比如：1 ICMP，2 IGMP，6 TCP，17 UDP，47 GRE，50 ESP，51 AH，88 EIGRP，89 OSPF，115 L2TPv3等等。留给终端用户的空间非常小，所以需要UDP提供更大的端口空间来满足用户的应用程序的需求。UDP端口号占两个字节，理论可以提供65535个端口号，扣除1-1023为系统保留，用户可以使用超过64000个端口号。

**（三）穿越端口翻译 PAT-Transversal** 

普通的IP包因为没有UDP/TCP端口号，无法完成**1对多的PAT翻译**，而基于UDP的封装，有UDP端口号可以无任何障碍穿越任何NAT设备。所以一些基于IP的协议如标准GRE、ESP无法穿越PAT，而造成通信障碍。所以现在越来越多的基于UDP协议的隧道，那是因为现在的网络PAT无处不在啊。

诚然在设计UDP的时候不会想到未来的网络会严重依赖端口号的翻译，由于IPv4资源枯竭，现在不得不依赖这项技术。

补充两句：编写socket小程序，一般都调用stream 或datagram 这两种类型，可以实现TCP-Based 或 UDP-Based程序，即用户只能封装自己application的数据，而无法对IP层、以太层进行控制和协议字段的操纵；可以采用raw 这种模式可以自定义这些底层的协议字段，包括以太网帧头，IP头。自己需要对整个包负责，保证协议字段的正确，虽然增加了复杂性，但更加灵活。

#### 字节流 数据报？

**字节流：**TCP传输过程中，以字节为最小单位进行传输。

**数据报：**UDP以报文为最小传输单位，报文与报文之间不会合并，如果缓冲区大小小于报文大小，就会丢弃多出的该报文。

#### TCP UDP沾包问题？

1.UDP不会发生沾包问题，它是 **保护消息边界：** 把数据当作一条独立的消息在网上传输，接收端接受独立的消息。 

因为UDP接受缓冲区采取链式结构记录每一个到达的UDP包，接收端每次只能读取一个包大小。

2.TCP会发生沾包问题，它是一个 **流：** 没有边界保护 把数据当作一个数据流，当缓冲区足够大时，会接受多个数据包。

#### UDP数据包最大数据长度

![img](https://img-blog.csdn.net/20160529140813320?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

理论上，一个UDP数据包最大为2^16,那么最大数据长度则为2^16-20(ip头)-8（udp头）

**但是 网络传输受到MTU（最大传输单元）限制 如果包大小超过了MTU将会被拆分传输**

**以太网MTU为1500** 所以UDP最大数据包长度为 1500-20-8=**1472**

​										 TCP 1500-20-20=1460

**因特网MTU为576** 576-20-8= **508** 一般用512代替

​								TCP 576-20-20=536

**为什么要分段传输？**

1. 公平使用网络
   组成网络的各种硬件是一种基础设施，为上层应用提供数据传输服务。为了公平，每个数据传输需求应该被被分成合适的大小，再传输。类似cpu时间片
2. 硬件处理能力，大片网络拥塞情况严重
3. 网络吞吐量，这个领域有许多研究性的paper讨论。行文时暂未深入到这个层面，暂时作罢。

#### TCP分段与IP分片

**“分片”指的是一个IP数据报太大(以太网大于1500)，需要拆分成一个一个的小段，变成多个IP数据报。**

**分段 指的是TCP报文数据段太大（以太网大于1460）需要拆分**

**MSS 最大分段大小**

三次握手时协商MSS大小

MSS是**TCP**数据包每次能够传输的最大数据分段，TCP报文段的长度大于MSS时，要进行分段传输。

**重组**

IP数据报文分片后，每个分片都维护相同的IP头部，**通过IP标识是不是同一个组， 通过偏移量确认在组中的位置，通过“更多碎片”字段确认是否是最后一片**。

TCP报文段的每个分段中都有TCP首部，到了端点后根据TCP首部的信息在传输层进行重组。

IP数据报分片后，**只有到达目的地后才进行重组**，而不是向其他网络协议，在下一站就要进行重组。

**重传**

对IP分片的数据报来说，即使只丢失一片数据也要**重新传整个数据报**（既然有重传，说明运输层使用的是具有重传功能的协议，如TCP协议）。这是因为IP层本身没有超时重传机制------由更高层（比如TCP）来负责超时和重传。

**个人理解** 因为不知道丢失的是哪一个片，所以要重传整个数据报

#### TCP可靠机制？

1.**校验和：**目的是检测数据在发送端和接收端传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
2.**序列号：**就是在传输过程中TCP发送的每一个数据包进行编号，接收方对接收到的数据包进行排序，也保证了可靠性传输
3.**确认机制：**就是当发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送
4.**超时重传：**就是在发送方发送完数据包之后，就会启动一个超时计时器，如果在计时器结束之前未收到ACK，就需要发送方需要重新对该数据包进行重新发送。
5.**滑动窗口机制：**其实就是为了防止发送方过快的发送数据包给接受方，导致接收方也不能及时的处理这些数据包的一个机制。
6.**流量控制：**流量控制就是利用滑动窗口机制来进行完成的，控制发送方发送速率，保证接收方来得及接收，接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。
7.**拥塞控制：**拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。它采用了几种算法：慢开始 、 拥塞避免 、快重传 和 快恢复。

#### TCP抓包时为什么只有三次挥手？

服务端无数据发送给客户端时，无需单独发送FIN，而是将第二、三次挥手合成一个报文即FIN+ACK。

#### 三次握手，最后一个ACK丢失会发生什么？

**客户端**

客户端发送完ACK后，便认为连接已建立，会正常发送报文，而服务端会以RST包响应，客户端便能知道Server的错误。

**服务端**

会根据TCP超时重传机制，等待 3、6、12s后重写发送SYN+ACK包。默认重发5次后，关闭连接。 

#### TCP半连接队列和全连接队列

![img](https://image.cnxct.com/2015/06/tcp-sync-queue-and-accept-queue-small-1024x747.jpg)

**半连接队列（SYN队列）**

收到客户端的SYN的TCP连接进入SYN_RECV状态，该半连接队列存储处于SYN_RECV状态的连接信息，

当服务端收到ACK后，会从队列中移除该连接，并进入全连接队列。

**若tcp_syncookies=0**

当队列溢出时，会直接丢弃SYN包，而客户端多次重发后仍然得不到回应就会抛出连接超时错误

**若tcp_syncookies=1**

那么队列没有上限，开启syncookies机制是为了抵抗syn洪水攻击。

其原理是在半连接队列满时，SYN cookies并不丢弃SYN请求，而是将源目的IP、源目的端口号、接

收到的client端初始序列号以及其他一些安全数值等信息进行hash运算，并加密后得到server端的初始序列号，称之为cookie。server端在发送初始序列号为cookie的SYN+ACK包后，会将分配的连接请求块释放。如果接收到client端的ACK包，server端将client端的ACK序列号减1得到的值，与上述要素hash运算得到的值比较，如果相等，直接完成三次握手，构建新的连接。

**注意 只有SYN队列满时且开启syncookies机制时，才会触发cookie机制**

**全连接队列**

第三次握手，服务端收到ACK后，会进入ACCEPT队列，表明为ESTABLISHED状态的连接。

当服务器调用`accept` 函数从 accept队列中获取已建立的连接进行读写时，将该连接信息从队列中移除

**若overflow=1**

当队列溢出时，服务端会直接发送RST包，连接被终止并从 syn queue中删除（**Client端由于多次重发SYN包得不到响应而抛出connection reset by peer错误**）

**若overflow=0**

服务端会丢弃掉Client的ACK包，连接信息仍保留在 SYN queue 中，同时启动定时器按照重传机制重新发送SYN + ACK包到Client，当重传次数超过设定值时，服务端发送RST包，直接终端连接，并从 syn queue 中删除该连接信息；（**在重试次数未达到上限前，重试成功客户端RT变高，Client超时则抛出read timeout异常；达到重试上限，则Client抛出connection reset by peer异常**）

#### Linux查看TCP连接状态

```
netstat -an|grep tcp 查看所有的TCP连接
netstat -an|grep ESTABLISHED 查看所有已建立连接的TCP
netstat -an|grep SYN_RECV 查看半连接的TCP 若收到SYN洪水攻击，则存在大量该状态的连接
```

#### 长连接与短连接选择？

**长连接** 适用于客户端和服务端通信频繁的场景，例如 聊天室，实时游戏等

**短连接** WEB网页等数据刷新频率较低的场景

#### Socket参数

sk = socket.socket(socket.AF_INET,socket.SOCK_STREAM,0)

**参数1** 地址簇

socket.AF_INET IPv4（默认）
socket.AF_INET6 IPv6

**参数2** 类型

socket.SOCK_STREAM　　流式socket , for TCP （默认）
socket.SOCK_DGRAM　　 数据报式socket , for UDP

socket.SOCK_RAW 	原始套接字，普通的套接字无法处理ICMP、IGMP等网络报文，而SOCK_RAW可以；其次，SOCK_RAW也可以处理特殊的IPv4报文；此外，利用原始套接字，可以通过IP_HDRINCL套接字选项由用户构造IP头。
socket.SOCK_RDM 是一种可靠的UDP形式，即保证交付数据报但不保证顺序。SOCK_RAM用来提供对原始协议的低级访问，在需要执行某些特殊操作时使用，如发送ICMP报文。SOCK_RAM通常仅限于高级用户或管理员运行的程序使用。
socket.SOCK_SEQPACKET 可靠的连续数据包服务

**参数3**

0 根据前面两个参数,自动选择一个合适的协议 （TCP/UDP/STCP/TIPC）

**属性设置**

1.TCP_NODELAY 设置true 保证包尽可能的发送，无论包的大小，关闭缓存。

2，SO_LINGER 指定socket关闭的时候，如何处理尚未发送的数据报文。默认情况下，close()方法将立即返回。但是系统仍然会尝试发送剩余的数据。设置0时，关闭socket，所有未关闭的数据包奖杯丢弃，如果SO_LINGER打开而且延迟时间设置任意的正数，close() 方法会阻塞，等待发送和接受确认。

setSoLinger(true,210);最大的延迟的时间为65535秒。

3，SO_TIMEOUT socket读取数据超时，read() 调用会阻塞尽可能长时间来满足得到字节，这是SO_TIMEOUT 可以确保在这次调用阻塞的时间不会超过固定的毫秒数，setSoTimeout(1222)

4,SO_RCVBUF 控制用于网络输入的建议的接受缓冲区的大小。 setReciveBufferSize(int size)

SO_SNDBUF 控制用于网络输入的建议的发送的缓冲区的大小。 setSendBufferSize(int size)

如果将发送缓冲区这只为64KB，而接受缓冲区设置为128KB，那么发送和接受缓冲区的大小都将是64KB。

在UNIX和LINUX系统中通常指定一个最大缓冲区大小，一般是64KB和256KB。

5，SO_KEEPALIVE 偶尔会通过一个空闲发送一个数据包（一般一两个小时一次） ，以确保服务器位崩溃。如果服务器没能响应这个包，客户端会持续尝试11分钟多的时间，直到接受到响应为止。

setKeepAlive(Boolean o)

6,SO_REUSEADDR 允许另一个Socket绑定到这个端口中，即使此时仍然可能存在前一个Socket为接受的数据。setReuseAddress(Boolean on) 这个方法必须在绑定socket之前调用。



#### TCP最大端口数和连接数

**最大端口数**  2^16=65535 用16位标识表示

**最大连接数**

TCP连接由四元组构成 **源IP 源端口 目标IP 目标端口**

**服务端** 服务端固定IP+端口 接收客户端TCP连接，只要 **源IP+源端口** 不同，即可构造唯一连接 session，所以理论上无上限，实际取决于服务器CPU、内存资源等

**客户端** 因为 **源IP+目标IP+目标端口以固定** 所以最大连接数位 65536

linux中取决于最大文件句柄数，



#### 同一端口同时TCP UDP

可以使用同一端口同时使用TCP UDP，唯一标识=端口+协议，通过协议+端口的联合区分进程的通信。

#### 四次挥手为什么2MSL？

**MSL** 报文在网络中最大存活时间，超过该时间的包将被丢弃

**为什么是2MSL？**

主动关闭方A在最后一次挥手时发送ACK给接收方B，这时可能出现

1）如果B没有收到自己的ACK，会超时重传FiN

那么A再次接到重传的FIN，会再次发送ACK

2）如果B收到自己的ACK，也不会再发任何消息，包括ACK

无论是1还是2，A都需要等待，要取这两种情况等待时间的最大值，**以应对最坏的情况发生**，这个最坏情况是：情况1

去向ACK消息最大存活时间（MSL) + 来向FIN消息的最大存活时间(MSL)。

这恰恰就是**2MSL。**等待2MSL时间，没有收到FIN包，A就可以放心地释放TCP占用的资源、端口号，**此时可以使用该端口号连接任何服务器。**



**注意** 超时重传时间远小于2MSL

### Redis

#### ZSet怎么实现？

跳跃表。通过每个节点中维持多个指向其它节点的指针实现达到 查询 插入 删除 时间复杂度为 O(logN)

由zskiplist和zskiplistNode组成。

```
typedef struct zskiplist{
     //表头节点和表尾节点
     structz skiplistNode *header, *tail;
     //表中节点的数量
     unsigned long length;
     //表中层数最大的节点的层数
     int level;
}zskiplist;

typedef struct zskiplistNode {
     //层
     struct zskiplistLevel{
           //前进指针
           struct zskiplistNode *forward;
           //跨度
           unsigned int span;
     }level[];
     //后退指针
     struct zskiplistNode *backward;
     //分值
     double score;
     //成员对象
     robj *obj;
} zskiplistNode
```

#### ZSet底层跳表怎么查询？

从第一层开始查找，查找不到下沉到第二层查找，以此类推。因为每一层都是有序的所以时间复杂度为O(logN)

#### 红黑树和跳表时间复杂度？

两者 查询 插入 删除 时间复杂度都是 O(logN)

#### ZSet为什么不用红黑树？

1.跳表代码实现易于红黑树

2.跳表范围查找易于红黑树。跳表只需找到小值后，往后遍历链表即可。在红黑树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。

3.红黑树的插入和删除操作引发子树的调整（左旋和右旋），逻辑复杂。跳表只需修改相邻节点的指针，简单快速。

#### 介绍下RDB AOF

##### **RDB**（默认）

对redis中的数据执行周期性的持久化（例如每隔24小时持久化一次）

**流程**

1.redis调用系统的fork()函数创建一个子进程（fork过程堵塞父进程）
 2.子进程将数据集写入一个临时的RDB文件
 3.当子进程完成对临时的RDB文件的写入时，redis用新的RDB文件来替换原来旧的RDB文件，并将旧的RDB文件删除

**优点**

1.RDB文件是紧凑压缩的二进制文件，适用于大文件备份，传递等。

2.只需fork子进程后，持久化操作由子进程完成，父进程无需IO磁盘操作。

3.恢复大文件数据时，速度快于AOF。

**缺点**

1.fork过程堵塞父进程，导致父进程服务暂停数毫秒。

2.可能发现数据丢失，假设5分钟保存一次RDB文件，在这种情况下，故障停机，则损失几分钟的数据。

##### AOF

使用文本协议格式每次记录写命令到日记种，重启时在重新执行AOF 文件中的命令达到恢复数据的目的。

命令写入（append）：写入命令追加到aof_buf缓冲区中

文件同步（sync）：根据不同策略向硬盘做同步操作（默认每s同步一次，后台线程执行，不影响主线程）

文件重写（rewrite）：随着AOF文件越来越大，定期对AOF文件重写（fork子进程）

重启加载（load）：Redis重启时，加载AOF文件进行数据恢复

**优点**

1.更好保护数据不丢失，默认每秒持久化一次，最多丢失1秒数据。

2.使用命令追加方式，不需要磁盘寻址开销。

3.日记命令易读，适合误删除的恢复，例如不小心使用flushall命令清空数据，只要还没有重写，则可以把日记文件中的flush删除，进行恢复。

**缺点**

1.相同数据，文件大于RDB

2.AOF开启后支持写的命令会比RDB支持写的命令慢，因为AOF一般会配置成每秒fsync操作，每秒的fsync操作还是很高的

3.数据恢复慢，不适合做备份。

#### Redis为什么快？

1.基于内存，读写不受到磁盘IO限制

2.使用IO多路复用模型，提高吞吐量

3.处理网络请求采用单线程，避免不必要的上下文切换和竞争

多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。

这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗）

#### Redis各数据类型应用场景

**String** 最常用的类型，存放普通的key value

**Hash** 存放对象类信息，比如用户信息

**List** 构建消息队列 最新消息排行等功能（朋友圈的时间线）

**Set** 交集 并集等 比如获取多个人的共同好友，只需将好友id存到集合中，取交集即可。

**Sort Set** 根据好友的 亲密度 排序显示好友列表等需要排序的场合 排行榜



#### 过期键删除

如果没有设置过期时间，会一直呆到内存大于maxmemory后执行相应的淘汰策略

1）：立即删除。在设置键的过期时间时，创建一个回调事件，当过期时间达到时，由时间处理器自动执行键的删除操作。（redis不使用）
2）：惰性删除。键过期了就过期了，不管。每次从dict字典中按key取值时，先检查此key是否已经过期，如果过期了就删除它，并返回nil，如果没过期，就返回键值。
3）：定时删除。每隔一段时间，对expires字典进行检查，删除里面的过期键。

 定时操作：Redis每秒做10次的事情：
        1.从具有相关过期的密钥集中测试20个随机密钥。
        2.删除找到的所有密钥已过期。
        3.如果超过25％的密钥已过期，请从步骤1重新开始。

​        **Redis使用 惰性+定时**



#### 过期键对内存的影响

rdb：在创建新的RDB 文件的时候，程序会对键进行检查，过期键不会被写入到更新后的RDB文件中。因此，过期键对更新后的RDB 文件没有影响。

aof:在键已经过期，但是还没有被惰性删除之前，这个键不会产生任何影响，AOF 文件也不会因为这个键而修改，当过期键被惰性删除或者定期删除之后，程序会向AOF 文件追加一条命令，来显示地记录该键已经被删除。

aof重写：和 RDB 文件类似，当进行AOF重写时，程序会对键进行检查，过期的键不会被保存到重写后的AOF 问价。因此过期键对重写后的AOF 文件没有影响。

#### 淘汰策略

1，noeviction：不执行任何淘汰策略，当达到内存限制的时候客户端执行命令会报错。
2，allkeys-lru：从所有数据范围内查找到最近最少使用的数据进行淘汰，直到有足够的内存来存放新数据。
3，volatile-lru：从所有的最近最少访问数据范围内查找设置到过期时间的数据进行淘汰，如果查找不到数据，则回退到noeviction。
4，allkeys-random：从所有数据范围内随机选择key进行删除。
5，volatile-random：从设置了过期时间的数据范围内随机选择key进行删除。
6，volatile-ttl：从设置了过期时间的数据范围内优先选择设置了TTL的key进行删除。

### Mysql

#### 默认隔离级别？为什么？

默认隔离级别是可重复读RR，而大部分项目默认隔离级别为RC读提交

这是一个上古遗留问题：

在MySQL的早期版本（大概是5.1）中，binlog的默认格式是语句SQL格式。这时候如果启用了RC的隔离级别，binlog记录的顺序可能与实际不一致。所以系统做了一个判断，如果隔离级别为RC，则binlog格式必须要是Mix或者row。

由于当时的默认参数binlog的默认格式是语句格式，所以隔离级别的默认值就设置到了RR。



#### 一条SQL执行过程

![SQL执行的全部过程](http://media.dreamcat.ink/uPic/SQL%E6%89%A7%E8%A1%8C%E7%9A%84%E5%85%A8%E9%83%A8%E8%BF%87%E7%A8%8B.png)

**MySQL内部可以分为服务层和存储引擎层两部分：**

1. **服务层包括连接器、查询缓存、分析器、优化器、执行器等**，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。
2. **存储引擎层负责数据的存储和提取。**其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认的存储引擎。

**Server层按顺序执行sql的步骤为：**

客户端请求->连接器（验证用户身份，给予权限） -> 查询缓存（存在缓存则直接返回，不存在则执行后续操作）->分析器（对SQL进行词法分析和语法分析操作） -> 优化器（主要对执行的sql优化选择最优的执行方案方法） -> 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口）->去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果）

**简单概括**：

- **连接器**：管理连接、权限验证；
- **查询缓存**：命中缓存则直接返回结果；
- **分析器**：对SQL进行词法分析、语法分析；（判断查询的SQL字段是否存在也是在这步）
- **优化器**：执行计划生成、选择索引；
- **执行器**：操作引擎、返回结果；
- **存储引擎**：存储数据、提供读写接口。

#### 一条查询很慢？

**原因**

1.没有用到索引

2.查询的数据量过大

3.死锁

4.IO吞吐量小 内存不足 网络速度慢

#### Hash索引和B+树索引

**哈希索引就是采用一定的哈希算法**，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。

**Hash索引优点**

等值查询，只需经过一次算法即可，速度快

**Hash索引缺点**

不支持范围查询，不能完成排序，当Hash冲突高时需要遍历链表，效率不一定高于B+树。

#### 使用索引注意项

- 只为用于搜索、排序或分组的列创建索引
- 为列的基数大的列创建索引
- 索引列的类型尽量小
- 可以只对字符串值的前缀建立索引
- 只有索引列在比较表达式中单独出现才可以适用索引
- 为了尽可能少的让`聚簇索引`发生页面分裂和记录移位的情况，建议让主键拥有`AUTO_INCREMENT`属性。
- 定位并删除表中的重复和冗余索引
- 尽量使用`覆盖索引`进行查询，避免`回表`带来的性能损耗。

#### 索引失效情况

1.有or语句前后都使用索引才生效，否则失效，即都使用独立索引才行。
2.复合索引未用左列字段;
3.like以%开头;
4.需要类型转换;
5.where中索引列有运算;
6.where中索引列使用了函数;
7.如果mysql觉得全表扫描更快时（数据少）;

#### Count

查询表总共有多少行

**效果**

count(*)=count(1) 查询所有行

count(列)查询列中不为Null的行

**性能**

count(*)≈count(1)>count(列)  1表示非空表达式

**为什么Innodb不跟MyISAM一样，把数字直接存起来呢？**

这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB表“应该返回多少行”也是不确定的

**建议使用Count(*)**

**如果该表只有一个主键索引，没有任何二级索引的情况下，那么COUNT(*)和COUNT(1)都是通过通过主键索引来统计行数的。如果该表有二级索引，则COUNT(1)和COUNT(*)都会通过**占用空间最小的字段的二级索引**进行统计**

普通索引树比主键索引树小很多。对于count(*)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL优化器会找到最小的那棵树来遍历

#### Innodb与Myisam区别

**1.**Innodb支持事务，Myisam不支持。

**2.**Innodb支持外键，Myisam不支持。

**3.**Innodb是聚簇索引，Myisam是非聚簇索引。

**4.**Innodb支持行、表锁，Myisam只支持表锁。

**5.**Innodb不保存表具体行数，需要全表扫描，而Myisam用一个变量保存了整个表的行数，存储在磁盘上，因此效率快于innodb，而当带条件的count时，两者效率差不多。

#### 聚簇索引和非聚簇索引

聚簇索引是一种数据存储方式，Innodb分为聚簇索引和辅助索引（非聚簇索引）

主键索引是聚簇索引，其它索引都是非聚簇索引

聚簇索引指的是B+树叶子节点存放表的整行数据

非聚簇索引指的是B+树叶子节点只存放主键值以及索引值，通常需要通过回表查询完整数据。

#### 隔离级别

读未提交：能够读到其他事务未提交的数据，可能出现脏读，没有加锁

读提交：能够读到其他事务提交的数据，可能出现不可重复读（多次读数据前后不一致），加行锁解决脏读

可重复读：能够多次读数据而不会前后不一致，但可能出现幻读，MVCC解决不可重复读

序列化：读写数据时直接锁表，所以没有问题，但是效率低

#### 怎么解决脏读、不可重复读、幻读？

**脏读：加行锁**，A事务读，B事务update，后锁住行，A事务无法读直到B事务完成，释放锁。

**不可重复读：MVCC**，A事务读，B事务update后提交，A事务由于快照版本低，读取不到新快照版本数据，只能读取到之前对应版本的旧数据。

**幻读：**

next-key lock=行锁+间隙锁

行锁，锁住主键索引的行，间隙锁锁住间隙。

gap lock只作用于非唯一索引，由于是非唯一索引，前后都可以再插入新的等值数据，为了防止幻读，要锁定前后两个范围。

select属于快照读操作，不会出现幻读，只有update、delete这种当前读操作才会出现幻读现象。

mvcc是快照读，本身就解决了幻读，当前读的情况下，用间隙锁解决了幻读

**rr并不解决幻读，只不过innodb在rr下靠加锁解决**

**幻读**

普通update id=20的话，锁住的是 附近两个区间 其它区间操作不会堵塞

select 的话因为快照都 所以不存在幻读

select share in mode 的话会转成update insert这种，当select id <20 share in mode 锁住附近两个区间就包括了整个表范围了，类似于锁表了，所以可以防止幻读。

#### 既然rr解决幻读，那么串行化有什么用？

分布式事务需要用到串行化，特殊情况需要用到串行化

例子：1 A事务开启，B事务开启。
2 B事务往表里面插入了一条数据，但还并未提交。
3 A事务开始查询了，并没有发现B事务这次插入的数据。然后此时B事务提交了数据。
4 于是乎，A事务就以为没有这条数据，就开始添加这条数据，但是却发现，发生了数据重复添加。

在这个情况下，恰恰是因为RR的快照读导致A事务根本无法感知到事务B对表产生的影响，而串行化相当于对全表加锁，一切事务都是串行的，因此事务A必然能感知事务B的添加，因为事务A会在事务B之后才begin。

#### redo log与bin log区别？

**1**.redo log undo log是在innodb存储引擎层产生，binlog是在mysql层产生，即任何引擎对于数据库的更改都会产生binlog

**2.**redo log是物理日记，记录的是数据页的物理修改，bin log是逻辑日记，记录的是sql日记

**3.**redo log在事务中不断写入，而bin log只有当事务提交后一次写入。

**4.**redo log是循环使用日记，binlog不是循环使用，在写满或者重启之后，会生成新的binlog文件，

**5.**redo log用于数据库异常故障后的数据恢复，bin log用于主从复制或普通数据恢复。

redo log分为内存和磁盘，操作数据时不是每次都写入磁盘，而是定期通过redo log把数据刷入磁盘这样即便断电后，重启mysql还是可以恢复

#### redo log

与在事务提交时将所有修改过的内存中的页面刷新到磁盘中相比，只将该事务执行过程中产生的`redo`日志刷新到磁盘的好处如下：

`redo`日志占用的空间非常小,

`redo`日志是顺序写入磁盘的，即顺序io

将redo log刷盘比对数据页刷盘效率高

一条SQL语句，正常执行时候特别快，有时候会突然变得特别慢，而且很难复现，它不只是随机而且持续时间很短。 看上去像数据库抖了一下 – 原因就是MySQL在刷脏页到磁盘，会堵塞写操作。

#### redo log 刷盘时机

- `log buffer`空间不足时

  `log buffer`的大小是有限的（通过系统变量`innodb_log_buffer_size`指定），如果不停的往这个有限大小的`log buffer`里塞入日志，很快它就会被填满。设计`InnoDB`的大叔认为如果当前写入`log buffer`的`redo`日志量已经占满了`log buffer`总容量的大约一半左右，就需要把这些日志刷新到磁盘上。

- 事务提交时

  我们前边说过之所以使用`redo`日志主要是因为它占用的空间少，还是顺序写，在事务提交时可以不把修改过的`Buffer Pool`页面刷新到磁盘，但是为了保证持久性，必须要把修改这些页面对应的`redo`日志刷新到磁盘。

- 后台线程不停的刷刷刷

  后台有一个线程，大约每秒都会刷新一次`log buffer`中的`redo`日志到磁盘。

- 正常关闭服务器时

- 系统内存不足时，会淘汰一些数据页，如果淘汰的是 脏页，就会先将脏页写道磁盘中

#### 主键和唯一索引区别

**1.** 主键不能为空，唯一索引可以为空

**2.** 一张表主键只能有一个，唯一索引可以有多个

**3.** 主键产生聚簇索引，唯一索引产生非聚簇索引

#### 重复值高的字段要不要建索引（性别）

建议不要，如果是非聚簇索引，每次查询到重复值时会进行回表操作，效率低下，并且还需要额外维护索引的开销

#### SQL调优

**1.**尽量指定列为not null,如果查询中包含可为Null的列，会使得索引、索引统计和值比较更为复杂，对mysql来说更难优化。但其实将可为null设置为not null带来的性能提升较小，主要是便于代码的可读性和可维护性。

MySQL中决定使不使用某个索引执行查询的依据很简单：就是成本够不够小。

**2**.limit优化。

首先查询id后再查询limit

```bash
SELECT * FROM product 
WHERE ID > =(select id from product limit 866613, 1) limit 20
```

利用Join

```csharp
SELECT * FROM product a 
JOIN (select id from product limit 866613, 20) b ON a.ID = b.id
```

#### 怎么避免隐式转换

当操作符与不同类型的操作数一起使用时，会发生类型转换以使操作数兼容。则会发生转换隐式。

**注意**

写sql多注意类型值

使用cast显示将类型进行转换 cast(3 as char)

#### drop delete truncate区别

**速度** drop>truncate>delete

DELETE从表中删除一行，事务日记记录每个删除操作，以便回滚。

TRUNCATE TABLE 释放表数据页删除数据，事务日记只记录页的释放，数据无法恢复。

**空间变化**

当表被TRUNCATE 后，这个表和索引所占用的空间会恢复到初始大小（删除数据）

DELETE操作不会减少表或索引所占用的空间。（逻辑删除）

drop语句将表所占用的空间全释放掉（整张表结构和数据）

**最后还可以用 bin log恢复数据**

#### 查看SQL执行时间

**1.** 打开设置 set profiling =1;

**2.** 在执行完的sql后执行 show profiles;

#### 联合索引最多几列

16

#### 自增键不连续的情况

**1.**设置了步长不为1

**2.** 唯一键冲突、事务回滚

**3.** 批量申请比如 insert...select语句

Mysql的申请策略是使用倍增法去申请，所以，假如Insert...Select的结果是4条数据，那么最终会申请1+2+4=7个主键值，就会有3个浪费了。

**为什么事务回滚自增键不连续**

因为当我们申请主键的时候，其他事务也会申请主键，假如事务发生回滚的时候，是否还要考虑其他事务的状态呢?这是个非常复杂又消耗性能的问题，另一方面，自增主键比较大的作用是避免页分割，我们只需要数据是递增而无需连续。



#### select lock in share model / for update 使用场景

**lock in share model**

有两张表：parent表和child表，向child表插入数据时，要保证child的parent在parent表中存在，删除parent表时，会将parent以及该parent的child都删掉。

一般的操作是先select，得到parentId，然后向child中插入一条数据(关联parentId)，但是这样是有问题的，如果select之后，插入之前，另一个session将parent删掉了，那么向child表中插入的数据并不会受到影响，最终造成该child没有parent的状况。
根据上面提到的特性，select时用select … lock in share mode就能解决这个问题。

**for update**

账户表中有一个字段money，取出来后，将money更新(比如加上一个值)后再存进去。

对于这个场景，如果两个session同时select，比如都取出来的是100，然后都加30, 都变成130，然后都update money，最终money的值是130，与预期的160不符。这个时候用select … for update 就能完美解决这个问题，这时因为两个session不能同时select … for update。

###  Tomcat

每个请求对应一个线程

#### Connector 

 默认监听8080和8009端口。

Connector用于接收请求并将请求封装成Request和Response来具体处理。最底层使用的是 Socket。Request和Response封装后交给Container（Servlet的容器）处理请求，Container处理后返回给Connector，最后由Socket返回给客户端。

#### protocol

Connector在处理HTTP请求时，会使用不同的protocol，包括BIO,NIO和APR

**Connecter处理请求流程**

在accept队列中接收连接（当客户端向服务器发送请求时，如果客户端与OS完成三次握手建立了连接，则OS将该连接放入accept队列）；在连接中获取请求的数据，生成request；调用servlet容器处理请求；返回response。

**BIO与NIO区别**

**BIO**

Acceptor接收socket，然后从Worker线程池中找出空闲的线程处理socket，如果worker线程池没有空闲线程，则Acceptor将阻塞。

**NIO**

Acceptor接收socket后，不是直接使用Worker中的线程处理请求，而是先将请求发送给了Poller，而Poller是实现NIO的关键。Acceptor向Poller发送请求通过队列实现，使用了典型的生产者-消费者模式。在Poller中，维护了一个Selector对象；当Poller从队列中取出socket后，注册到该Selector中；然后通过遍历Selector，找出其中可读的socket，并使用Worker中的线程处理相应请求。

![img](https://images2017.cnblogs.com/blog/1174710/201711/1174710-20171108203711513-1728828893.png)

**BIO：** 读取socket并交给Worker中的线程”这个过程是阻塞的，也就意味着在socket等待下一个请求或等待释放的过程中，处理这个socket的工作线程会一直被占用，无法释放

**NIO**:	读取socket并交给Worker中的线程”这个过程是非阻塞的，当socket在等待下一个请求或等待释放时，并不会占用工作线程，因此Tomcat可以同时处理的socket数目远大于最大线程数，并发性能大大提高。

**Accpetor(1个线程)**

用于接受新的连接，并且封装连接注册到Poller中。

**Poller(1个/2个线程)**

用于检测已经就绪的Socket，所有的Poller共用一个Selector,当Socket可读或可写时，将Socket封装添加到Worker线程池的任务队列中。

**Worker(线程池默认200)**

处理请求，封装成Request,调用容器的pipeline。

![img](https://img-blog.csdn.net/20151022113805905?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

**acceptCount**

accpet队列长度，当accept队列中连接的个数达到acceptCount时，队列满，进来的请求一律被拒绝。默认值是100。

**maxConnections**

最大连接数，当Tomcat接收的连接数达到maxConnections时，Acceptor线程不会读取accept队列中的连接；这时accept队列中的线程会一直阻塞着，直到Tomcat接收的连接数小于maxConnections。如果设置为-1，则连接数不受限制。

**maxThreads**

处理请求的最大线程数

#### **Container**

Container用于封装和管理Servlet，以及具体处理Request请求

![这里写图片描述](https://img-blog.csdn.net/20180108201104048?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGxnZW4xNTczODc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

#### Tomcat处理请求过程

1.用户在浏览器中输入网址localhost:8080/test/index.jsp，请求被发送到本机端口8080，被在那里监听的Coyote HTTP/1.1 Connector获得；

2.Connector把该请求交给它所在的Service的Engine（Container）来处理，并等待Engine的回应；

3.Engine获得请求localhost/test/index.jsp，匹配所有的虚拟主机Host；

4.Engine匹配到名为localhost的Host（即使匹配不到也把请求交给该Host处理，因为该Host被定义为该Engine的默认主机）。名为localhost的Host获得请求/test/index.jsp，匹配它所拥有的所有Context。Host匹配到路径为/test的Context（如果匹配不到就把该请求交给路径名为“ ”的Context去处理）；

5.path=“/test”的Context获得请求/index.jsp，在它的mapping table中寻找出对应的Servlet。Context匹配到URL Pattern为*.jsp的Servlet，对应于JspServlet类；

6.构造HttpServletRequest对象和HttpServletResponse对象，作为参数调用JspServlet的doGet()或doPost(),执行业务逻辑、数据存储等；

7.Context把执行完之后的HttpServletResponse对象返回给Host；

8.Host把HttpServletResponse对象返回给Engine；

9.Engine把HttpServletResponse对象返回Connector；

10.Connector把HttpServletResponse对象返回给客户Browser。



### Nginx

#### 负载均衡节点崩了怎么办？

```
upstream ser{
server 192.162.26.20:80 max_fails=1 fail_timeout=30
}
上面表示 30s内有1个请求到该挂了的server就会设置为 down状态 时长是30s
30s内请求不会到该server 30s后认为该server恢复正常
max_fails请求失败次数
fail_timeout请求失败时间
```

#### 节点崩了导致部分请求反应时间很慢？

```
设置proxy_connect_timeout连接超时时间
location / {
	http://localhost;
	proxy_connect_timeout 3;//单位为秒
}
```

#### Ip_hash解决session共享产生的问题？

1.**nginx不是最前端的服务器**

若nginx前面还有服务器，导致nginx获取不到用户的真实ip地址，则分流失败。如squid服务器，则nginx获取到的是squid服务器ip。

2.**nginx后面还有其它负载均衡**

假如nginx后面还有其它负载均衡，请求又通过另外方式分流，则定位不到同一台服务器上。

可以将 session请求通过ip_hash分流直接到服务器，其它请求通过其它负载均衡方式走后端。

3.**某个节点崩了，导致session失效**

### RabbitMQ

#### 怎么保证消息的幂等性？(重复消费)

消费者消费完消息后（例如持久化db了）打算回复ack给MQ时挂了。

这时MQ认为消息没被消费，交给另外消费者。

**解决：**根据业务添加约束，如访问DB查看消息是否已经入库，添加唯一索引保证重复数据不会插入多条。

1.当拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，

那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。

2.当拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。

3.如果上面两种情况还不行，准备一个第三方存储,来做消费记录。以redis为例，给消息分配一个全局id，

只要消费过该消息，将<id,message>以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。

使用setnx命令，设置失败则表明已存在记录。

#### 怎么保证消息传输的可靠性？

消息传输过程 **生产者-->MQ-->消费者**

1.**生产者发送给MQ过程中丢失数据（网络问题）**

1）使用事务

在生产者发送数据之前开启rabbitmq事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。

问题，开始rabbitmq事务机制，基本上吞吐量会下来，因为太耗性能。堵塞直到完成。

```
try {
    channel.txSelect(); // 声明事务
    // 发送消息
    channel.basicPublish("", _queueName, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes("UTF-8"));
    channel.txCommit(); // 提交事务
} catch (Exception e) {
    channel.txRollback();
} finally {
    channel.close();
    conn.close();
}
```

2）confirm模式（推荐）

生产者开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。

而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。
confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了。

```
// 开启发送方确认模式
channel.confirmSelect();

for (int i = 0; i < 10; i++) {
    String message = String.format("时间 => %s", new Date().getTime());
    channel.basicPublish("", config.QueueName, null, message.getBytes("UTF-8"));
}

//异步监听确认和未确认的消息
channel.addConfirmListener(new ConfirmListener() {
    @Override
    public void handleNack(long deliveryTag, boolean multiple) throws IOException {
        System.out.println("未确认消息，标识：" + deliveryTag);
    }
    @Override
    public void handleAck(long deliveryTag, boolean multiple) throws IOException {
        System.out.println(String.format("已确认消息，标识：%d，多个消息：%b", deliveryTag, multiple));
    }
});
```

2.**RabbitMQ丢失数据--开启RabbitMQ数据持久化**

1）创建queue时设置为持久化，保证持久化queue的元数据，但不会持久化queue里的数据

2）发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。

持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。

若生产者那边的confirm机制未开启的情况下，哪怕是你给rabbitmq开启了持久化机制，也有一种可能，就是这个消息写到了rabbitmq中，但是还没来得及持久化到磁盘上，结果不巧，此时rabbitmq挂了，就会导致内存里的一点点数据会丢失。

3.**消费端丢失数据**

刚打算消费还没处理，结果进程挂了 比如 重启

RabbitMQ提供的ack机制，也是一种处理完成发送回执确认的机制。

关闭MQ自动ack,通过处理代码中完成后返回ack告知MQ消费完成。

如果MQ等待一段时间后消费端没有发送过来ack 那么RabbitMQ就认为你还没处理完，这个时候RabbitMQ会把这个消费分配给别的consumer去处理，消息是不会丢的。

### Linux

#### 找出文件中关键字出现的次数

grep 关键字 文件名 |wc -l

grep success a.log|wc -l 找出a.log中success关键字出现的次数

#### 查找日记中IP出现频率最高的10条记录

cat xxx.log | awk '{print $(1)}' | sort | uniq -c | sort -k 1 -n -r|head -10

awk '{print $(1)}'就是打印出日志内容的第几列。$1就是第一列

sort就是对内容进行排序，默认是自然顺序排序。

uniq指令用于排重，而是只适用于相邻两行相同的情况。所以一般结合sort使用。即先sort排序再排重。

uniq -u是只显示唯一的记录行。uniq -c是显示有重复记录的情况。

sort -k 1 -n -r这个指令，参看下面sort指令参数的详细说明

sort选项与参数：
-f  ：忽略大小写的差异，例如 A 与 a 视为编码相同；
-b  ：忽略最前面的空格符部分；
-M  ：以月份的名字来排序，例如 JAN, DEC 等等的排序方法；
-n  ：使用『纯数字』进行排序(默认是以文字型态来排序的)；
-r  ：反向排序；
-u  ：就是 uniq ，相同的数据中，仅出现一行代表；
-t  ：分隔符，默认是用 [tab] 键来分隔；
-k  ：以哪个区间 (field) 来进行排序的意思

所以 sort -k 1 -n -r 指令的意思就是对第一列按照纯数字逆序排序。

head -10这个不用说了吧，显示前10行。



#### 调度算法

**1.先来先服务算法（FCFS）：**

 不可剥夺算法，实现简单，效率低下。

 **2.短作业优先算法（SJF）：**

在同时到达的进程中优先执行最短的进程。

 **3.优先级调度算法：**

采用优先级来表示作业的紧急程度。又可分为：

- 可剥夺优先级调度算法
- 不可剥夺优先级调度算法

根据优先级随后是否可变可分为：

- 静态优先级调度算法
- 动态优先级调度算法

 **4.高响应比优先算法：**

高响应比优先算法是对，先来先服务和短进程优先算法的一种综合考虑。

响应比的计算：

```
响应比=（等待时间+需要执行的时间）/需要执行的时间
```

 **5.时间片轮转调度算法：**

时间片轮转调度算法遵循了先来先服务的原则，不过它的执行流程是这样的：CPU会在就绪的有序进程队列中，去执行第一个就绪的进程，如果在规定的时间片（比如100ms）里没有执行完毕，就会把该进程丢到队列的末尾，继续就绪等待着。

#### 查看日记

cat server.log  由第一行到最后一行连续显示日记

cat server.log | grep "debug" 查看关键字日记

tail -f server.log 实时动态查看日记

#### 查看端口号

查看端口号被谁占用

lsof -i:端口号 

netstat -tunlp | grep 端口号

#### 创建文件

touch 文件名

#### 创建文件夹

mkdir 文件夹名

#### 删除正在被写的文件

当文件正在被进程打开时，执行 unlink() 只会删除文件名，并不会删除文件内容，只有所有打开此文件的进程都关闭此文件后（注意当进程退出时，会自动关闭所有打开的文件），文件内容才会被真正删除。

进程打开一个文件后，如果我们删除被打开的文件，之后再重建这一文件，操作系统依然把之前打开的文件描述符3指向原有旧文件的 i 节点，即使再次建立同名文件，系统也认为文件描述符 3 指向的文件被删除了。

#### 删除正在运行的可执行文件

如果一个可执行文件正在运行，当我们把它删除后，删除的也只是文件名，操作系统依然保留了可执行文件的内容，正在执行的进程并不会崩溃，这一安全性由操作系统来保证。

删除原可执行文件后，如果我们重建一个同名文件，会发现新文件与被删除的pr_pid 文件的 i 节点号不一样。重建文件后，原程序的输出也没有变化，说明重建的文件与原 pr_pid 无关。这种机制与删除被打开文件的机制类似。

#### 写入正在运行的可执行文件

当我们试图向正在运行的可执行文件中写入内容时，会写入失败，系统提示 “Text file busy” 表示有进程正在执行这一文件。当目标文件已经存在时，cp 命令会把原目标文件内容清空，之后写入新内容。因而这里用cp 命令覆盖可执行文件时，也要向 a.out 中写入新内容，系统同样会报错 ”Text file busy“。

#### 如果一个进程有多个线程，那么fork出来的进程有几个线程？

“在多线程执行的情况下调用fork()函数，仅会将发起调用的线程复制到子进程中。（子进程中该线程的ID与父进程中发起fork()调用的线程ID是一样的，因此，线程ID相同的情况有时我们需要做特殊的处理。）也就是说不能同时创建出与父进程一样多线程的子进程。其他线程均在子进程中立即停止并消失，并且不会为这些线程调用清理函数以及针对线程局部存储变量的析构函数。”

这里出现一个潜在的死锁条件，就是子进程继承了父进程的互斥锁但是并不知道该互斥锁的状态，若该互斥锁以上锁且子进程再次加锁该互斥量，此时子进程将死锁。

#### 虚拟内存大小与什么有关

最大虚拟内存受到计算机地址位数限制，例如，32位机的寻址能力为2的32次方，大约为4G。

实际上为受到 内存容量和外存容量之和限制。

即 虚拟内存容量= min（2^计算机位数，内存+外存） 与实际内存无关

### JDK8

#### Lambda表达式与匿名内部类区别？

**1.**Lam只能为函数接口创建实例，而内部类可以是接口，抽象类和具体类。

**2**.Lam接口中只能由一个抽象方法，内部类可以有一个或多个。

**3.**编译之后，Lam不产生class文件，对应的字节码会在运行的时候动态生成，内部类产生一个单独的class文件。

#### Stream流

集合.stream获取sream流。

**foreach**逐一处理集合值。

```
 public static void main(String[] args) {
        Stream.of("张三", "李四", "王五", "赵六", "田七")
        .forEach(name -> System.out.println(name));
}
```

**filter** 过滤 将一个流过滤成另外一个流

```
public static void main(String[] args) {
        Stream.of("张三丰", "张翠山", "王五", "张无忌", "赵六")
        .filter(name -> name.startsWith("张"))
        .forEach(name -> System.out.println(name));
    }
```

**map映射** 将一个流映射到另外一个流

```
public static void main(String[] args) {
        Stream.of("1", "2", "3", "4")
        .map(s -> Integer.parseInt(s))
        .forEach(s -> System.out.println(s));
    }

```

**count **返回个数

 long count = list.stream().count();

**limit** 截取 对流进行截取。

```
 public static void main(String[] args) {
        Stream.of("美羊羊","喜羊羊","懒羊羊","灰太狼")
        .limit(3)
        .forEach(s -> System.out.println(s));
    }

```

### JUC

#### Volatile

**可见性**

（1）修改volatile变量时会强制将修改后的值刷新的主内存中。

（2）修改volatile变量后会导致其他线程工作内存中对应的变量值失效。因此，再读取该变量值的时候就需要重新从读取主内存中的值。

**有序性**

内存屏障，是一组处理器指令，用于实现对内存操作的顺序限制。

（1）LoadLoad 屏障
执行顺序：Load1—>Loadload—>Load2
确保Load2及后续Load指令加载数据之前能访问到Load1加载的数据。

（2）StoreStore 屏障
执行顺序：Store1—>StoreStore—>Store2
确保Store2以及后续Store指令执行前，Store1操作的数据对其它处理器可见。

（3）LoadStore 屏障
执行顺序： Load1—>LoadStore—>Store2
确保Store2和后续Store指令执行前，可以访问到Load1加载的数据。

（4）StoreLoad 屏障
执行顺序: Store1—> StoreLoad—>Load2
确保Load2和后续的Load指令读取之前，Store1的数据对其他处理器是可见的。

**使用场景**

　（1）对变量的写操作不依赖于当前值。 i++;

　（2）该变量没有包含在具有其他变量的不变式中。j=i+5;

#### ThreadLocal

**作用：**它通过为每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题，不会出现一个线程读取变量时被另一个线程修改的现象。

**场景：** 管理数据库Connection，保证当前线程的操作都是同一个Connection。

#### Syn与Lock区别

1.Syn会自动释放锁（执行完同步代码或线程发生异常），Lock需要手动释放锁。

2.Syn尝试获取锁后会死等，Lock可以设置获取锁时间，不会死等。

3.Syn获取锁失败会堵塞且无法响应中断，Lock支持中断响应，一旦发现死锁，可以立即中断线程

4.Lock支持非堵塞方式获取锁，当获取锁失败，线程不会堵塞。

5.Syn是非公平锁，Lock可以是公平锁，也可以是非公平锁（默认）

6.Syn适用于少量同步，Lock适用于大量同步

7.synchronized只有一个等待队列，任何情况的阻塞都是放在一个队列里面的，Lock可以创建多个Condition队列，不同的Condition控制不同的条件，每个Condition有单独的一个队列。

**总而言之，Lock提供更多的API操作，灵活性高于Syn**

#### Lock

**核心是AQS 独占模式 CAS+自旋**

AQS维护一个 **同步队列** 和 一个/多个 **等待队列**

![img](https://img-blog.csdn.net/20170720082720370?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvamF2YXplamlhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

当线程获取锁失败后，将会被封装成Node结点，加入到同步队列中并进行自旋操作，若当前线程结点的前驱结点为head时，将尝试获取同步状态，获取成功将自己设置为head结点。在释放锁成功则唤醒后继结点的线程。

#### 公平性和非公平性的体现？

公平锁在线程请求到来时先会判断同步队列是否存在结点，如果存在先执行同步队列中的结点线程，当前线程将封装成node加入同步队列等待。

非公平锁，当线程请求到来时，不管同步队列是否存在线程结点，直接尝试获取同步状态，获取成功直接访问共享资源。

#### Condition

一个锁拥有多个Condition,即多个等待队列，当唤醒线程时，可以根据Condition选择队列唤醒，而不是随机唤醒。

拥有锁的线程执行了await相关方法，将会释放锁并且加入**等待队列**中，直到被唤醒后加入**同步队列**中自旋获取锁。

#### Syn原理

每个对象的对象头包含一个Mark Word记录Monitor(管程锁)，管程锁包含EntryList和WaitSet存放线程对象，owner指向拥有锁的线程。

当多个线程同时访问一段同步代码时，首先会进入 EntryList 集合，当线程获取到对象的monitor 后把monitor中的owner变量设置为当前线程同时monitor中的计数器count+1，若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSet集合中等待被唤醒，唤醒的线程会再次和EntryList中的线程竞争，完成后释放锁。

<img src="https://img-blog.csdn.net/20170604114223462?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvamF2YXplamlhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="img" style="zoom:67%;" />

#### Syn非公平性怎么体现？

理论上根据策略，所有线程都有机会竞争到锁，提高性能。

缺点是可能会产生线程饥饿现象（即某个线程长时间未竞争到锁）。

#### JDK6的锁优化？

**无锁--偏向锁--轻量级锁--（自旋锁）--重量级锁**

**偏向锁（单线程）**

Mark Word存储锁偏向的线程ID，通过判断线程ID与当前线程ID是否相同决定是否升级锁。

只有等到线程竞争出现才释放偏向锁，持有偏向锁的线程不会主动释放偏向锁。之后的线程竞争偏向锁，会先检查持有偏向锁的线程是否存活，如果不存活，则对象变为无锁状态，重新偏向；如果仍存活，则偏向锁升级为轻量级锁，此时轻量级锁由原持有偏向锁的线程持有，继续执行其同步代码，而正在竞争的线程会进入自旋等待获得该轻量级锁。

**轻量级锁（多线程交替）**

在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，尝试拷贝锁对象的Mark Word到栈帧的Lock Record。

若拷贝成功：将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向对象的Mark Word。

若拷贝失败：若当前只有一个等待线程（自己），则可通过自旋稍微等待一下，可能持有轻量级锁的线程很快就会释放锁。 但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁膨胀为重量级锁

**重量级锁（并发）**

依赖于底层的操作系统的Mutex Lock来实现的。而操作系统实现线程之间阻塞到唤醒的切换这就需要从用户态转换到核心态的切换，消耗系统资源。

**重量级锁ObjectMonitor原理**

同步队列 `_cxq  ，Entrylist`  等待队列 `Waitset`

`1.` **tryLock** 通过 cas 操作将 _owner 字段设置为 Self，其中 _owner 表示当前 ObjectMonitor 对象锁持有的线程指针，Self 指向当前执行的线程。如果设置上了，表示当前线程获得了锁，否则没有获得,如果是重入，则对次数+1。

`2.` cas获取失败，通过自旋获取锁，若任然未获取到则继续下一步

`3.` 任然没有获取到锁，则创建一个 ObjectWaiter 对象将当前线程的对象（注意是 JavaThread 对象）包裹起来。

死循环入队，将当前节点放到 CXQ 队列的头部，将节点的 next 指针通过 cas 操作指向 _cxq 指针就完成了入队操作。

如果入队成功，则退出当前循环，否则再次尝试 **tryLock** ，因为可能这个时候会成功。这里使用循环操作 cas入队 的逻辑，就是处理在高并发的状态下 cas 锁定失败问题

**入队失败后tryLock原因 ** 

这其实是为了在入队阻塞线程之前的最后检查，防止线程无谓地进行状态切换。这么做有一些微妙的亲和力影响？这是很多操作系统中都有的一种 CPU 执行调度逻辑，说的是，如果在过去一段时间内，某个线程尝试获取某种资源一直失败，那么系统在后面会倾向于将该资源分配给这个线程。这里我们前后两次执行，就是告诉系统当前线程「迫切」想要获得这个 cas 资源，如果可以用的话尽量分配给它。当然这种亲和力不是一种得到保证的协议，因此这种操作只能是一种积极的、并且人畜无害的操作。 

`4.` 成功进入__cxq队列后，进入另一个循环_,主要做3件事

1. 尝试获取锁
2. park （堵塞）当前线程
3. 再次尝试获取锁

如果是cxq队列中首个等待线程，不断的重复进行短时间的休眠 （堵塞）1ms-8ms-64ms直到上限后，_检查锁（尝试获取锁）

如果是非首个等待线程，则通过无限期的休眠一直等待对象锁的 exit 函数执行唤醒才行。

**enter总结**

1. ObjectMonitor 内部通过一个 CXQ 队列保存所有的等待线程
2. 在实际进入队列之前，会反复尝试 lock，在某些系统上会存在 CPU 亲和力的优化
3. 入队的时候，通过 ObjectWaiter 对象将当前线程包裹起来，并且入到 CXQ 队列的头部
4. 入队成功以后，会根据当前线程是否为第一个等待线程做不同的处理
5. 如果是第一个等待线程，会根据一个简单的「退避算法」来有条件的 wait
6. 如果不是第一个等待线程，那么会执行无限期等待
7. 线程的 park 在 posix 系统上是通过 pthread 的 condition wait 实现的

**exit释放锁**

根据 Knob_QMode 的值和 _cxq 是否为空执行不同策略，选择唤醒cxq中的线程还是Entrylist中的线程去tryLock，或是连接两个队列。

**notify随机唤醒也是因为策略不同，导致唤醒的线程去到的队列不同导致的**

**线程获取锁是在exit中，而不是notify，notify只是将节点放入队列中**

![img](https://xiaomi-info.github.io/2020/03/24/synchronized/sync_2.png)



#### 为什么Wait在Object 而sleep在Thread

Wait是锁级别操作，锁是在每个对象的对象头中的管程锁，所以wait是在Object中，锁是对象级别，可以是任意对象。

Sleep是让线程暂停运行一段时间不占用CPU资源，决定权在线程手里，只是为了让线程暂停一段时间，所以是在线程里。

#### JMM

JMM规定了内存主要划分为**主内存**和**工作内存**两种。此处的主内存和工作内存跟JVM内存划分（堆、栈、方法区）是在不同的层次上进行的，如果非要对应起来，主内存对应的是Java堆中的对象实例部分，工作内存对应的是栈中的部分区域，从更底层的来说，主内存对应的是**硬件的物理内存**，工作内存对应的是**寄存器和高速缓存**。

<img src="https://images2018.cnblogs.com/blog/1102674/201808/1102674-20180815143324915-2024156794.png" alt="img" style="zoom: 67%;" />

每条线程拥有各自的工作内存，工作内存中的变量是主内存中的一份拷贝，线程对变量的读取和写入，直接在工作内存中操作，而不能直接去操作主内存中的变量。

volatile关键字要求被修改之后的变量要求立即更新到主内存，并且其它线程使用前从主内存处进行读取。因此volatile可以保证可见性。

#### 自旋锁

**优点**

自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗，这些操作会导致线程发生两次上下文切换！

**缺点**

但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用 cpu 做无用功，消耗着cpu，同时有大量线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要 cpu 的线程又不能获取到 cpu，造成 cpu 的浪费。所以这种情况下我们要关闭自旋锁。

**自旋与挂起/唤醒**

自旋 cpu一直再做空循环无用功，cpu一直消耗

挂起/唤醒 cpu消耗只在挂起和唤醒的操作

通过对两个操作消耗的CPU大小决定是自旋还是挂起操作



#### 并发编程bug根源？

Java内存模型，为提高性能，将变量从主内存拷贝到cpu高速缓存（线程内存）中进行操作,导致不同缓存中修改了数据版本不一致，造成线程安全问题。

### Java

#### 创建线程需要什么资源

**1.** 为线程栈分配并初始化内存

**2.** 需要对操作系统进行系统调用，创建本地线程

**3.** 需要创建、初始化描述符并将他添加到JVM内部数据结构种

#### 为什么不建议创建过多线程

主要涉及 **cpu时间** 问题，创建过多的线程，会在线程切换的时候消耗CPU工作时间，当线程数达到一个极限值以后CPU就会什么都不用做了，只是在切换每一个线程，但是每个线程都没有实际的执行

多线程处理线程同步时可能会使用很多的内核对象来完成同步，这种情况也会消耗内核资源。

#### Linux怎么创建线程

```
int pthread_create(pthread_t *tidp,const pthread_attr_t *attr,
(void*)(*start_rtn)(void*),void *arg);
```

*入参解析*
1.pthread_t *tidp 线程ID的指针，对于每一个线程来说是唯一的
2.pthread_attr_t \*attr 此参数为Posix的线程属性，缺省值为NULL
3.(void\*)(*start_rtn)(void*) 线程运行函数的起始地址
4.运行函数的参数，多个参数的时候可以定义结构体

*返回值解析*
如果创建线程成功，返回0；创建线程失败返回错误的原因；
如果线程创建成功，tidp指向的内存单元被设置为新创建的线程的线程ID

#### Thread vs Runnable

Java单继承多实现，若继承于Thread则无法扩展其它类，即无法继承其它类。

Runnable只有一个run抽象方法，Thread实现于Runnable并且还有其它方法

**个人理解**  如果只是想重写run方法，那么实现于Runnable,如果还想重写其它方法那么继承于Thread,因为从继承的角度来说，是对父类的增强。 

#### 为什么用线程池不new?

1.通过重复利用已创建的线程，减少在创建和销毁线程上所花的时间以及系统资源的开销。

2.提高响应速度，当任务到达时，任务可以不需要等到线程创建就可以立即执行。 

3.提高线程的可管理性，使用线程池可以对线程进行统一的分配和监控。

4.如果不使用线程池，有可能造成系统创建大量线程而导致消耗完系统内存。

#### Execute和Submit区别

1.execute提交的是Runnable类型的任务，而submit提交的是Callable或者Runnable类型的任务

2.execute的提交没有返回值，而submit的提交会返回一个Future类型的对象，当为Runnable时，返回值为null

3.execute提交的时候，如果有异常，就会直接抛出异常，而submit在遇到异常的时候，通常不会立马抛出异常，而是会将异常暂时存储起来，等待你调用Future.get()方法的时候，才会抛出异常

submit里面的，任务提交的时候，底层都是使用execute来提交的

#### 进程创建线程数限制在哪里

创建一个新线程时，它会占用系统资源（跟创建一个进程一样的效果，比如占用 pid），也会占用进程内资源（比如线程栈就要占一个vma）内存空间，如果这两个资源任何一个超标了，都会造成创建线程失败。

一个线程栈需要1M内存空间，一个进程虚拟内存为2G，理论上可以开2048个线程，但是不可能所有内存都被用作线程栈所以实际要小。

#### 设计线程池？

1.线程管理类：用于创建并管理线程池，添加新任务，摧毁线程池。

2.工作线程：线程池中的线程，有任务时执行任务，没任务时处于等待状态。

3.任务接口：每个任务必须实现的接口，以供工作线程获取调度任务的执行。

4.任务队列：用于存放没有处理的任务，提供缓冲机制。

#### 线程死锁怎么检测

**使用jstack工具导出线程堆栈信息**

查看死锁信息

**使用Jconsole工具**

1.选择目标jvm进程。

2.切换到 ’线程‘ 标签页

3.点击 ’检测到死锁‘

4.可以看到不同的线程，查询堆栈信息，定位到哪个类的哪一行

#### java程序加载过程

1.**编译** java源文件编译成字节码文件

2.**类加载** 包括 加载、验证、准备、解析、初始化、使用、卸载七个方面

3.**类使用** 执行程序输出结果

#### String三兄弟

`String` 适用于少量字符串

`StringBuilder` 适用于单线程大量字符串操作

`StringBuffer` 适用于多线程大量字符串操作

**运行速度** StringBuilder>StringBuffer>String

**线程安全** StringBuffer append方法使用synchronized关键字 而 StringBuilder没有

String最慢的原因 :String为字符串常量，而StringBuilder和StringBuffer均为字符串变量，即String对象一旦创建之后该对象是不可更改的，但后两者的对象是变量，是可以更改的。

Java中对String对象进行的操作实际上是一个不断创建新的对象（new）并且将旧的对象回收的一个过程，所以执行速度很慢。而StringBuilder和StringBuffer的对象是变量,内部维护可变长度char[]，可以进行数组扩容，而不进行创建和回收的操作，所以速度要比String快很多。

#### 父子类初始化顺序

① 父类静态代码块和静态变量。② 子类静态代码块和静态变量。③ 父类普通代码块和普通变量。④ 父类构造方法。⑤ 子类普通代码块和普通变量。⑥ 子类构造方法。

#### 为什么要实现Serializable接口

一个类只有实现了Serializable接口，才能被序列化，将对象转化为字节流进行传输。

#### B树和B+树

（1）B+树查询时间复杂度固定是logn，B树查询复杂度最好是 O(1)。

（2）B+树相邻接点的指针可以大大增加区间访问性，可使用在范围查询等，而B-树每个节点 key 和 data 在一起，则无法区间查找。

（3）B+树更适合外部存储，也就是磁盘存储。由于内节点无 data 域，每个节点能索引的范围更大更精确

**（4）注意这个区别相当重要，是基于（1）（2）（3）的，B树每个节点即保存数据又保存索引，所以磁盘IO的次数很少，B+树只有叶子节点保存，磁盘IO多，但是区间访问比较好。**

B树用于 MongoDB B+树用于 Mysql

MongoDB 是文档型的数据库，是一种 nosql，它使用类 Json 格式保存数据,为了就是高性能，大部分数据放到内存上。

![img](https://pic2.zhimg.com/80/v2-d6fe8d74a0b9fbfe31de3f820b88449b_1440w.jpg)

**MongoDB使用B树，所有节点都有Data域，只要找到指定索引就可以进行访问，无疑单次查询平均快于Mysql**。

#### B+树高度和IO次数

**一条查询的过程**

			  	1 查看缓存中是否存在id，
				2 如果有 则从内存中访问，否则要访问磁盘，
				 3 并将索引数据存入内存，利用索引来访问数据,
				4 对于数据也会检查数据是否存在于内存，
				 5 如果没有则访问磁盘获取数据，读入内存。
				6 返回结果给用户。
一般来说`B+Tree`的高度一般都在`2-4`层，`MySQL`的`InnoDB`存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要`1~3`次磁盘`I/O`操作（根节点的那次不算磁盘`I/O`）。

每次`io`都是在树的一层查找符合的`id`范围的页数据，通过对比页里面的最大最小主键来确定下层的查找范围。

**为什么树的高度等于IO次数**

个人理解，一次IO读取的数据是有限的，所以先从上层**大范围**中确定一个**小范围**，再**在小范围**中确定**小小范围**，所以每次IO读取的是一个树的层数

#### 前K个最小的数

用 **大顶堆** ，构建容量为k的大顶堆，首先将前 *k* 个数插入大根堆中，

随后从第 *k*+1 个数开始遍历，如果当前遍历到的数比大根堆的堆顶的数要**小**，就把堆顶的数弹出 该数入堆，调整堆

时间复杂度：O(nlogk)，其中 n 是数组 arr 的长度。由于大根堆实时维护前 k 小值，因为插入删除都是 O(logk) ，最坏情况下数组里 n 个数都会插入，所以一共需要 O(nlogk) 的时间复杂度。

使用大顶堆只需和首个元素比较，使用小顶堆每次都需要入堆并且进行重建

**注意 如果使用小顶堆 则为 O(nlogn)**

#### 第K个最小的数

**大顶堆**  构建容量为k的大顶堆，首先将前 *k* 个数插入大根堆中，随后从第 *k*+1 个数开始遍历，如果当前遍历到的数比大根堆的堆顶的数要**小**，则替换，直到遍历完成。那么堆顶就是第k小的数。

#### 字节流和字符流区别

- 字节流操作的基本单元为字节；字符流操作的基本单元为Unicode码元。
- 字节流默认不使用缓冲区；字符流使用缓冲区。
- 字节流通常用于处理二进制数据，实际上它可以处理任意类型的数据，但它不支持直接写入或读取Unicode码元；字符流通常处理文本数据，它支持写入及读取Unicode码元。



#### final finally finalize区别

`final` 修饰符（关键字）。被final修饰的类，就意味着不能再派生出新的子类，不能作为父类而被子类继承。因此一个类不能既被abstract声明，又被final声明。将变量或方法声明为final，可以保证他们在使用的过程中不被修改。被声明为final的变量必须在声明时给出变量的初始值，而在以后的引用中只能读取。被final声明的方法也同样只能使用，即不能方法重写。

`finally` 是在异常处理时提供finally块来执行任何清除操作。不管有没有异常被抛出、捕获，finally块都会被执行。try块中的内容是在无异常时执行到结束。catch块中的内容，是在try块内容发生catch所声明的异常时，跳转到catch块中执行。finally块则是无论异常是否发生，都会执行finally块的内容，

`finalize` 方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。这个方法是由垃圾收集器在确定这个对象没有被引用时对这个对象调用的。它是在object类中定义的，因此所有的类都继承了它。子类覆盖finalize（）方法以整理系统资源或者被执行其他清理工作。finalize（）方法是在垃圾收集器删除对象之前对这个对象调用的。 

#### String为什么被设计为final

**1.安全性**

final类型的类不能被继承，并且String类中的final方法可以防止其内部的方法被重写，乱改。

**2.实现字符串常量池**

只有当字符串是不可变的，字符串池才有可能实现。字符串池的实现可以在运行时节约很多heap空间，因为不同的字符串变量都指向池中的同一个字符串。但如果字符串是可变的，那么String interning将不能实现，因为这样的话，如果变量改变了它的值，那么其它指向这个值的变量的值也会一起改变。

String就被设计成一个不变类，这样有助于共享，提高性能。可以将字符串对象保存在字符串常量池中以供与字面值相同字符串对象共 享。如果String对象是可变的，那就不能这样共享，因为一旦对某一个String类型变量引用的对象值改变，将同时改变一起共享字符串对象的其他 String类型变量所引用的对象的值	

#### 非对称性加密和对称性加密区别

对称加密指的就是加密和解密使用同一个秘钥，所以叫做对称加密。

非对称加密指的是：加密和解密使用不同的秘钥，一把作为公开的公钥，另一把作为私钥。公钥加密的信息，只有私钥才能解密。私钥加密的信息，只有公钥才能解密。

#### static方法不能访问非static变量？

类的静态成员（变量和方法）都属于类本身，在类加载的时候就会分配内存，可以通过类名直接访问；

非静态成员（变量和方法）属于类的对象，所以只有在类的对象产生（创建类的实例）时才会分配内存，然后通过类的对象（实例）去访问。

由于静态成员在类加载的时候就会被分配内存，而非静态成员则不会。因此，在一个类的静态成员中去访问其非静态成员会出错，是因为**在类的非静态成员不存在的时候，类的静态成员就已经存在了，访问一个内存中不存在的东西当然会出错。**

#### 单例模式子类问题

子类构造器默认调用父类无参构造器，所以如果父类无参构造器私有了，则不能被继承。

#### final关键字

`final` 修饰基本数据类型时，变量的值不能再改变。

`final` 修饰引用类型时，引用变量的地址不能再改变，即一直引用该对象，但对象的属性可以改变。

类变量 `final static int a`  实例变量 `final int b`

**类变量**：必须要在**静态初始化块**中指定初始值或者**声明该类变量时**指定初始值，而且只能在这**两个地方**之一进行指定；

**实例变量**：必要要在**非静态初始化块**，**声明该实例变量时**或者在**构造器中**指定初始值，而且只能在这**三个地方**进行指定。

`final` 修饰方法时，该方法不能被子类重写，重载是可以的。

`final` 修饰类时，表明该类不能被继承。

**安全发布**

对于final，当你创建一个对象时，使用final关键字能够使得另一个线程不会访问到处于“部分创建”的对象

```
memory = allocate();　　// 1：分配对象的内存空间
instance = memory;　　// 3：设置instance指向刚分配的内存地址
// 注意，此时对象还没有被初始化！
ctorInstance(memory);　// 2：初始化对象java
```

基本数据类型:

1. final域写：禁止**final域写**与**构造方法**重排序，即禁止final域写重排序到构造方法之外，从而保证该对象对所有线程可见时，该对象的final域全部已经初始化过。
2. final域读：禁止初次**读对象的引用**与**读该对象包含的final域**的重排序。

引用数据类型：

额外增加约束：禁止在构造函数对**一个final修饰的对象的成员域的写入**与随后将**这个被构造的对象的引用赋值给引用变量** 重排序



#### String问题

String s1 = new String(“HelloWorld”)和String s2 = "HelloWorld"由区别么？

前者在使用的时候创建了两个对象，一个在堆内存中 `s1`，一个在方法区中的字符串常量池中 `HelloWorld`
后者只是个变量

s1：指向的是堆内存中的位置
s2：指向的是方法区中字符串常量池的位置

==为false,equals为true

**int a=1 存放位置**

1.a若是类的成员变量，存放在方法区中，1存放于堆中。 a指向堆中的1.

2.a若是方法局部变量，位于虚拟机栈中的局部变量表中，1也保存在栈中。

#### 序列化和反序列化

Java序列化是指把Java对象转换为字节序列的过程，而Java反序列化是指把字节序列恢复为Java对象的过程

**作用**

（1）永久性保存对象，保存对象的字节序列到本地文件或者数据库中；

（2）通过序列化以字节流的形式使对象在网络中进行传递和接收（网络传输只存在二进制序列）

**原理**

通过特定的规则将对象转换为字节序列，通过特定的规则将字节序列反序列化为对象

**其它**

1、序列化时，只对对象的状态进行保存，而不管对象的方法；

2、当一个父类实现序列化，子类自动实现序列化，不需要显式实现Serializable接口；

3、当一个对象的实例变量引用其他对象，序列化该对象时也把引用对象进行序列化；

4、并非所有的对象都能直接序列化，至于为什么不可以，有很多原因了，比如：

- 安全方面的原因，比如一个对象拥有private，public等field，对于一个要传输的对象，比如写到文件，或者进行RMI传输等等，在序列化进行传输的过程中，这个对象的private等域是不受保护的；
- 资源分配方面的原因，比如socket，thread类，如果可以序列化，进行传输或者保存，也无法对他们进行重新的资源分配，而且，也是没有必要这样实现；

5、声明为static和transient类型的成员数据不能被序列化。因为static代表类的状态，transient代表对象的临时数据。

6、序列化运行时使用一个称为 serialVersionUID 的版本号与每个可序列化类相关联，该序列号在反序列化过程中用于验证序列化对象的发送者和接收者是否为该对象加载了与序列化兼容的类。为它赋予明确的值。显式地定义serialVersionUID有两种用途：

- 在某些场合，希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有相同的serialVersionUID；
- 在某些场合，不希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有不同的serialVersionUID。

### 操作系统

#### IO多路复用模型

多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。

这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗）

### JVM

#### 哪些对象可以作为GC root

- 虚拟机栈（栈帧中的本地变量表）中引用的对象
- 方法区中类静态属性引用的对象
- 方法区中常量引用的对象
- 本地方法栈中 JNI（即一般说的 Native 方法）引用的对象

#### 方法区存放什么

> 它存储已被Java虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等

- **静态变量之所以又称为类变量，是因为静态变量和类关联在一起，随着类的加载而存在于方法区（而不是堆中）**
- **八种基本数据类型（byte、short、int、long、float、double、char、boolean）的静态变量会在方法区开辟空间，并将对应的值存储在方法方法区**

#### 方法区如何判断是否需要回收 

方法区主要回收的内容有：废弃常量和无用的类。对于废弃常量也可通过引用的可达性来判断，但是对于无用的类则需要同时满足下面3个条件： 

① 该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例； 

② 加载该类的ClassLoader已经被回收； 

③ 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。

#### 方法区回收

虽然JVM垃圾回收主要集中在堆中，但是方法区也会进行回收

**回收的对象**

**1.废弃常量**

废弃常量一般包括 字面量以及符号引用

回收废弃常量与回收Java堆中的对象非常类似。以常量池中字面量的回收为例，假如一个字符串“abc”已经进入了常量池中，但是当前系统没有任何一个String对象是叫做“abc”的，换句话说是没有任何String对象引用常量池中的“abc”常量，也没有其他地方引用了这个字面量，如果在这时候发生内存回收，而且必要的话，这个“abc”常量就会被系统“请”出常量池。常量池中的其他类（接口）、方法、字段的符号引用也与此类似。

**2.无用的类** 

同时满足以下条件才是无用的类 即 实例+ClassLoader+Class不存在

​    （1）、该类所有实例都已经被回收（即Java椎中不存在该类的任何实例）；

​    （2）、加载该类的ClassLoader已经被回收，也即通过引导程序加载器加载的类不能被回收；

​    （3）、该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法；

#### 进入老年代的条件

1.大对象:所谓的大对象是指需要大量连续内存空间的java对象,最典型的大对象就是那种很长的字符串以及数组。

2.长期存活的对象:虚拟机给每个对象定义了一个对象年龄(Age)计数器,如果对象在Eden出生并经过第一次Minor GC后仍然存活,并且能被Survivor容纳的话,将被移动到Survivor空间中,并且对象年龄设为1,。对象在Survivor区中每熬过一次Minor GC,年龄就增加1,当他的年龄增加到一定程度(默认是15岁), 就将会被晋升到老年代中。对象晋升到老年代的年龄阈值,可以通过参数-XX:MaxTenuringThreshold设置。

3.动态对象年龄判定:,如果在Survivor空间中相同年龄的所有对象大小的总和大于Survivor空间的一半,年龄大于或等于该年龄的对象就可以直接进入老年代,无须等到MaxTenuringThreshold中要求的年龄。

4.在一次安全Minor GC 中，仍然存活的对象不能在另一个Survivor 完全容纳，则会通过担保机制进入老年代。 

#### 什么时候发送Young GC / Full GC

**Young GC**

Eden区满时

**Full GC**

（1）System.gc()方法的调用【此方法的调用是建议JVM进行Full GC,虽然只是建议而非一定】

（2）老年代空间不足

（3）方法区空间不足

（4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存

（5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小



####  JVM new一个对象具体发生了什么

在Java中我们创建对象都会用new进行创建，下面我来接收一下new之后对象创建及内存分配的具体的过程

一：虚拟机遇到一条new指令后，先去检查这条指令参数是否能在常量池中定位到一个类的符号引用（类的带路径全名），并检查这个符号引用代表的类是否已被加载、解析和初始化过，如果没有，那必须先执行相应的**类加载**过程，即验证是否是第一次使用该类。

二：类加载检查通过后，接下来虚拟机为新生对象**分配内存**，因为对象所需内存的大小在类加载后是完全确定的(用引用，堆中存放实例),所以只需分配一个固定大小的内存即可。分配内存的方法用两种(Java虚拟机中)

①**指针碰撞**：假设Java堆中内存是绝对规整的，所有用过的内存都存放在一边，空闲的内存存在在另一边，中间放着一个以指针为分界点的指示器，分配内存就是把指针往空闲的那侧移动对象需要的内存即可。但是如果Java内存堆不是完整的，就没有办法进行简单的指针碰撞，

②**空闲列表**：空闲列表就是虚拟机先对内存分块，**并用一个表记录每个内存块是否使用的情况**，为对象分配内存时只需更新列表上的记录即可，选择哪一种分配方式取决于堆中的内存使用情况是否完整。

但是在为对象分配内存的同时，需要考虑其它线程是否也在这一时刻需要分配，因此需要考虑到线程的安全问题，通过以下两种方法进行解决：

①同步处理[**乐观锁**]：一种是对分配内存的空间动作进行同步处理--实际上虚拟机采用CAS配上失败重试的方式保证更新操作的原子性

②本地线程分配缓存TLAB:另一种是把内存分配的动作按照线程在不同的空间之中进行，及每个线程先预先分配一定的缓存。

TLAB的全称是**Thread Local Allocation Buffer**，即**线程本地分配缓存区**，这是一个线程专用的内存分配区域。:)

三：内存分配完成后，虚拟机将分配到的内存空间都初始化为零值(不包括对象头)，如果采用的是TLAB的方法分配，则这一步骤在分配之前完成。这一步操作保证了对象的实例字段在Java代码中可以不付初始值就直接使用，程序访问的值为false。

四：在上面的步骤完成后，从虚拟机的视角，一个新的对象已经产生了，但是从Java程序的视角来看，对象创建方法才刚刚开始，还要执行对象的init方法（构造方法），一个对象才完成创建

#### 元空间

1.8不存在方法区,将方法区的实现给去掉了，而是在本地内存中,新加入元数据区(元空间).
元空间: 存储.class 信息, 类的信息,方法的定义,静态变量等.而常量池放到堆里存储

**为什么jdk1.8要把方法区从JVM里移到直接内存？**

1.因为直接内存，JVM将会在IO操作上具有更高的性能，因为它直接作用于本地系统的IO操作。而非直接内存，也就是堆内存中的数据，如果要作IO操作，会先复制到直接内存，再利用本地IO处理。

- 从数据流的角度，非直接内存是下面这样的作用链：本地IO --> 直接内存 --> 非直接内存 --> 直接内存 --> 本地IO
- 而直接内存是：本地IO --> 直接内存 --> 本地IO

2.整个永久代有一个 JVM 本身设置固定大小上线，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，并且永远不会得到java.lang.OutOfMemoryError。

1. 字符串存在永久代中，容易出现性能问题和内存溢出。

2. 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。

3. 永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。


#### 为什么设置这么多类加载器

**1.区分同名的类**

假定存在一个应用服务器，上面部署着许多独立的应用，同时他们拥有许多同名却不同版本的类库。试想，这时候jvm该怎么加载这些类同时能尽可能的避免掉类加载时对同名类的差异检测呢？当然是不同的应用都拥有自己独立的类加载器了。

**2.更方便的加强类的能力**

类加载器可以在loadclass时对class进行重写和覆盖，在此期间就可以对类进行功能性的增强。比如添加面向切面编程时用到的动态代理，以及debug等原理。怎么样达到仅修改一个类库而不对其他类库产生影响的效果呢？一个比较方便的模式就是每个类库都可以使用独立的类加载器

#### 既然有GC为什么还会出现内存泄漏？

内存泄漏指的是已经不再被程序需要的已分配内存无法被回收，即对象已经不需要了但却还被引用导致无法回收。

GC通过可达性分析法判断内存是否可以回收，但由于编码错误或其它原因，导致过期的对象引用仍然被持有，则无法回收造成内存泄漏。

**例子**

```
List<Object> list=new ArrayList<>();
        for (int i=0;i<100;i++){
            Object o=new Object();
            list.add(o);
            o=null;
        }
```

如果发生GC，对象o不会被回收，因为虽然o被置空，但list仍然存在对o对象的引用，所以不会对它进行回收，发生内存泄漏

#### 既然有GC为什么还会有OOM？

full gc收集的是垃圾，及不可用的东西，如果对内存中的对象大部分是可达的，而此时又有新的对象需要分配内存空间，如果此时可用空间不够就会OOM。

一个简单的例子，你的堆只有100M，你new了一个101M的大数组，这时候神也帮不了你。

#### 堆变量和栈变量

全局、静态、new产生的变量都在堆中，动态分配的变量在堆中分配，局部变量在栈里面分配。

函数中声明的变量在栈中，用了new标识符在堆中，全局变量和static变量在全局区。

程序为栈变量分配动态内存，在程序结束为栈变量清除内存，但是堆变量不会被清除。

**作用域**

全局变量和静态全局变量具有全局作用域。局部变量和静态局部变量具有局部作用域。

**分配区**

全局变量，静态局部变量，静态全局变量在方法区，局部变量在栈中

#### 堆、栈默认大小

`-xmx ` 堆最大空间

`-xms` 初始化堆大小，jvm启动时分配的内存

`-xmn` 新生代大小 

`-xss` 每个线程堆栈大小 默认1m

`-XX:MaxPermSize` 永久代大小，默认64m

堆默认大小与物理内存有关

- ###### 最大堆大小：物理内存小于192MB时，为物理内存的一半；物理内存大192MB且小于1GB时，为物理内存的四分之一；大于等于1GB时，都为256MB

- ###### 初始化堆大小：至少为8MB；物理内存大于512MB且小于1GB时，为物理内存的六十四分之一；大于等于1GB时，都为16MB

### 其它

#### 项目怎么部署到服务器上

① 基础的 JDK 环境
② 一个 Web 服务器。如 Tomcat、JBoss
③ 一款数据库。如：mysql

我们要部署 Java Web 项目，那就至少得将项目上传到云服务器。其实过程很简单，基本上也就是下面三个步骤：
① 打包上传：将项目打包成 war 文件，然后利用FTP传到远程服务器
② 将 war 文件移动到 Tomcat 目录下的 webapps 下。
③ 重启 Tomcat，访问我们的项目。

在这个过程中，我们需要注意。因为一般而已，作为一个 Web 项目，我们肯定是有数据库的使用的。那么数据库部分怎么办呢？其实，只需要将我们已有的数据库转储为 sql 文件，然后将 sql 文件上传到云服务器上执行即可。以 mysql 为例，如下操作：

① 转储为 sql 脚本，并上传：先在本地将我们项目使用的数据库转为 sql 文件，上传到云服务器上 （可以利用 Navicat 将数据库转储为.sql文件）。
② 执行 sql：然后进入 mysql 中执行该 sql 文件。（若服务器装有Navicat，可直接用Navicat执行.sql文件，执行前需要选中存放表的数据库，应该与代码中数据库连接语句包含的数据库名保持一致）

**使用 jenkins 可以进行增量发布**

#### 数据结构堆和栈的区别

堆是一个完全二叉树，实现有最大堆、最小堆等

最大堆:孩子节点小于或等于父节点

最小堆:孩子节点大于或等于父节点

栈 先进后出结构。实现有Stack、LinkedList,区别在于Stack为数组实现，LinkedList为链表实现

#### 内存堆和栈的区别

栈区（stack）— 由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。
堆区（heap） — 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。

1.申请方式
    堆是由程序员自己申请并指明大小，在c中malloc函数 如p1 = (char *)malloc(10);
    栈由系统自动分配，如声明在函数中一个局部变量 int b; 系统自动在栈中为b开辟空间

2.申请后系统的响应
    栈：只要栈的剩余空间大于所申请空间，系统将为程序提供内存，否则将报异常提示栈溢出。
    堆：首先应该知道操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时，会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点的空间分配给程序，另外，对于大多数系统，会在这块内 存空间中的首地址处记录本次分配的大小，这样，代码中的delete语句才能正确的释放本内存空间。另外，由于找到的堆结点的大小不一定正好等于申请的大 小，系统会自动的将多余的那部分重新放入空闲链表中。

3.申请大小的限制
    栈：是一块连续的内存的区域。如果申请的空间超过栈的剩余空间时，将提示overflow。能从栈获得申请的空间较小。
    堆：是不连续的内存区域。这是由于系统是用链表来存储的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。

4.申请效率的比较：
    栈由系统自动分配，速度较快。但程序员是无法控制的。
    堆是由new分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便.

#### 面向对象三大特征

**封装**

隐藏对象的属性和方法，只对外公开接口，增强安全性和简化编程，使用者不用知道对象的具体实现细节，只需通过接口访问，通过访问权限府对外公开接口。

![img](https://gss0.baidu.com/9vo3dSag_xI4khGko9WTAnF6hhy/zhidao/wh%3D600%2C800/sign=1156177ca04bd1130498bf346a9f8837/cdbf6c81800a19d865fd770a3efa828ba71e46c7.jpg)

**继承**

子类可以使用现有的类的功能，并且在原来的类的功能下进行扩展。从 一般 到 特殊，无需重复编写同样功能的代码，提高代码利用率。

**多态**

允许将子类类型的指针赋值给父类类型的指针。

相同的方法，多种实现，表现尾 重写与重载。

**重写**

子类修改父类的同名方法，同样参数。重写是动态分态

**重载**

方法名相同，参数列表不同。 重载是静态分态

f（Object o） f（String s） 是重载么

f（List<String> l） f（List<Integer> l）是重载么



第1个是重载，因为静态类型改变了。比如A 是 B的父类，那么A a = new B（） A就是静态类型 B是实际类型。重载是根据静态类型看的。

第2个不是重载
静态类型一致，并不会因为泛型而改变。因为编译期间，会对泛型进行擦除。

#### 接口和抽象类区别

接口中所有的方法都是抽象的，而抽象类则可以同时包含抽象和非抽象的方法

类如果要实现一个接口，它必须要实现接口声明的所有方法。但是，类可以不实现抽象类声明的所有方法（但一定要实现所有的抽象方法）

接口中声明的变量默认都是static final的常量。抽象类没限制

类可以实现很多个接口，但是只能继承一个抽象类

Java接口中的成员函数默认是public的。抽象类的成员函数可以是protected或者是public。

抽象类可以没有抽线方法

**从设计角度来说**

接口的设计目的，是**对类的行为进行约束**（更准确的说是一种“有”约束，因为接口不能规定类不可以有什么行为），也就是提供一种机制，可以强制要求不同的类具有相同的行为。它只约束了行为的有无，但不对如何实现行为进行限制。

抽象类的设计目的，是**代码复用**。当不同的类具有某些相同的行为，且其中一部分行为的实现方式一致时，可以让这些类都派生于一个抽象类。达到了代码复用的目的。

#### Java传值还是传引用？

Java方法参数是传值

如果参数是基本类型，则传递的是基本类型的字面量值的拷贝。

如果参数是引用类型，传递的是该参数引用的对象在堆中的地址值的拷贝。

#### 数据量大的表怎么设计？

**水平分割**

按照时间分割表，（经常查询数据只是在一段时间内）将经常查询的和不常用的分开多个表。

**垂直分割**

某些字段常常被使用，而其他不常被使用，则根据字段垂直分割。

**查询**

添加索引。

使用中间表，例如查询一年的用户数量，可以先统计每一个月的结果放在中间表后，再累计。

**把大的查询拆分为多个小的查询**

#### 关系型数据库和非关系型数据库

##### 关系型数据库mysql

**优点**

使用二维表结构存储数据，易于理解

使用SQL语言操作数据库，可以执行复杂操作一个或多个表

基于硬盘存储，容量大

支持ACID保证数据完整性。

**缺点**

海量数据的读写性能差

并发高的请求硬盘IO造成瓶颈

Join的多表查询机制导致难于横向扩展 涉及多个表。  

##### 非关系型数据库redis

数据结构化存储方法的集合

**优点**

基于内存存储数据,高并发下读写能力强

支持存储多种数据结构

基于分布式，扩展性更加灵活

**缺点**

无法使用SQL，通用性差，无法使用复杂查询

不支持ACID，基于分布式节点，只能在CAP中选择两项满足。

内存占用有限

##### 使用场景

**redis**

经常被查询的热点数据

高并发场景下的数据存储

**mysql**

关联多的数据，例如查询某个用户的订单，需要 用户表 和 订单表。

#### **前后端怎么通讯**

**AJAX**

短链接

浏览器发送请求，服务器返回数据，服务器不能主动返回数据。

轮询发送请求然后更新客户端显示。

XMLHttpRequest对象是AJAX的基础，用于在后台和服务器交换数据。

可以在不重新加载整个页面的情况下，对网页的某个部分进行更新。

1. 创建XMLHTTPRequest对象

2. 使用open方法设置和服务器的交互信息

3. 设置发送的数据，开始和服务器端交互

4. 注册事件

5. 更新界面

   ```
   //步骤一:创建异步对象
   var ajax = new XMLHttpRequest();
   //步骤二:设置请求的url参数,参数一是请求的类型,参数二是请求的url,可以带参数,动态的传递参数starName到服务端
   ajax.open('get','getStar.php?starName='+name);
   //步骤三:发送请求
   ajax.send();
   //步骤四:注册事件 onreadystatechange 状态改变就会调用
   ajax.onreadystatechange = function () {
      if (ajax.readyState==4 &&ajax.status==200) {
       //步骤五 如果能够进到这个判断 说明 数据 完美的回来了,并且请求的页面是存在的
   　　　　console.log(ajax.responseText);//输入相应的内容
     　　}
   
   }
   ```

**WebSocket**

客户端和服务端的双向长连接。

解决了http协议只能单方面发送请求的问题，服务端可以主动向客户端推送信息。

（1）建立在 TCP 协议之上，服务器端的实现比较容易。

（2）与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。

（3）数据格式比较轻量，性能开销小，通信高效。

（4）可以发送文本，也可以发送二进制数据。

（5）没有同源限制，客户端可以与任意服务器通信。

（6）协议标识符是`ws`（如果加密，则为`wss`），服务器网址就是 URL。

![img](http://www.ruanyifeng.com/blogimg/asset/2017/bg2017051502.png)

#### JDK默认垃圾回收器

jdk1.7 默认垃圾收集器Parallel Scavenge（新生代）+Parallel Old（老年代）

jdk1.8 默认垃圾收集器Parallel Scavenge（新生代）+Parallel Old（老年代）

jdk1.9 默认垃圾收集器G1

#### CPU过高的原因？

1.死循环 死锁

2.频繁的创建对象造成GC频繁 创建过多的线程

3.存在文件流操作，高并发时每个请求产生一个文件流

#### CPU100%怎么排查？

1.top命令查找CPU占用最高的进程PID

2.ps-mp pid -o THREAD,tid,time查找进程中那个线程CPU占用最高TID

3.jstack 29099 >> xxx.log 打印出该线程日记

4.sz xxx.log 下载日记到本地

5.查看日记对应线程问题

#### OOM原因？

1.堆溢出 创建实例对象过多，存在大对象的分配，内存泄漏

2.栈溢出，线程开启过多

3.持久代溢出，运行期间采用反射，生成大量的代理类，导致方法区被撑爆

#### OOM怎么排查？

查看服务器运行日记

1.查看进程号 jps

2.查看线程信息 jstack 19645(PID)

3.查看内存信息 jmap -histo 19645

4.dump内存信息到heap.bin文件 jmap -dump:format=b,file=heap.bin 19645

#### 内存泄漏

**原因**

**1、static字段引起的内存泄露**

大量使用static字段会潜在的导致内存泄露，在Java中，静态字段通常拥有与整个应用程序相匹配的生命周期，不会被GC回收

解决办法：最大限度的减少静态变量的使用；单例模式时，依赖于延迟加载对象而不是立即加载方式。

**2、未关闭的资源导致内存泄露**

每当创建连接或者打开流时，JVM都会为这些资源分配内存。如果没有关闭连接，会导致持续占有内存。在任意情况下，资源留下的开放连接都会消耗内存，如果我们不处理，就会降低性能，甚至OOM。

解决办法：使用finally块关闭资源；

**3、不正确的equals()和hashCode()**

在HashMap和HashSet这种集合中，常常用到equal()和hashCode()来比较对象，如果重写不合理，将会成为潜在的内存泄露问题。

解决办法：用最佳的方式重写equals()和hashCode。

**5、finalize()方法造成的内存泄露**

重写finalize()方法时，该类的对象不会立即被垃圾收集器收集，如果finalize()方法的代码有问题，那么会潜在的引发OOM；

解决办法：避免重写finalize()。

**7、使用ThreadLocal造成内存泄露**

使用ThreadLocal时，每个线程只要处于存活状态就可保留对其ThreadLocal变量副本的隐式调用，且将保留其自己的副本。使用不当，就会引起内存泄露。

一旦线程不在存在，ThreadLocals就应该被垃圾收集，而现在线程的创建都是使用线程池，线程池有线程重用的功能，因此线程就不会被垃圾回收器回收。所以使用到ThreadLocals来保留线程池中线程的变量副本时，ThreadLocals没有显示的删除时，就会一直保留在内存中，不会被垃圾回收。

解决办法：不在使用ThreadLocal时，调用remove()方法，该方法删除了此变量的当前线程值。不要使用ThreadLocal.set(null)，它只是查找与当前线程关联的Map并将键值对设置为当前线程为null。

**内存泄漏最终导致内存溢出，实际场景，系统正常工作一段时间后，突然变慢，可能是出现了内存泄漏**

#### 内存泄漏排查

1.查看正在运行的Java程序 **jps** 记录下进程ID

 ![img](https://upload-images.jianshu.io/upload_images/2843224-def5f922430879f6.png?imageMogr2/auto-orient/strip|imageView2/2/w/182/format/webp)

2.查看进程运行状态 **jstat -gc** 各种堆区使用情况

![img](https://img2018.cnblogs.com/blog/978388/201906/978388-20190626150321415-587548863.png)

```
S0C：第一个幸存区的大小
S1C：第二个幸存区的大小
S0U：第一个幸存区的使用大小
S1U：第二个幸存区的使用大小
EC：伊甸园区的大小
EU：伊甸园区的使用大小
OC：老年代大小
OU：老年代使用大小
MC：方法区大小
MU：方法区使用大小
CCSC:压缩类空间大小
CCSU:压缩类空间使用大小
YGC：年轻代垃圾回收次数
YGCT：年轻代垃圾回收消耗时间
FGC：老年代垃圾回收次数
FGCT：老年代垃圾回收消耗时间
GCT：垃圾回收消耗总时间
```

 3.生成快照dump文件 **jmap** 显示堆中对象的统计信息

![img](https://upload-images.jianshu.io/upload_images/2843224-ae30cd960ae03498.png?imageMogr2/auto-orient/strip|imageView2/2/w/498/format/webp)

![img](https://upload-images.jianshu.io/upload_images/2843224-6cd762ab4b8d9c9a.png?imageMogr2/auto-orient/strip|imageView2/2/w/467/format/webp)

这个命令执行，JVM会将整个heap的信息dump写入到一个文件，heap如果比较大的话，就会导致这个过程比较耗时，并且执行的过程中为了保证dump的信息是可靠的，所以会暂停应用， 线上系统慎用。

4.使用 **jhat** 命令讲dump文件转成html形式，通过html查看堆情况。

#### P2P使用TCP还是UDP?

迅雷高速稳定下载的根本原因在于同时整合多个稳定服务器的资源实现多资源多线程的数据传输。多资源多线程技术使得迅雷在不降低用户体验的前提下，对服务器资源进行均衡，有效降低了服务器负载。

每个用户在网上下载的文件都会在迅雷的服务器中进行数据记录，如有其他用户再下载同样的文件，迅雷的服务器会在它的数据库中搜索曾经下载过这些文件的用户，服务器再连接这些用户，通过用户已下载文件中的记录进行判断，如用户下载文件中仍存在此文件(文件如改名或改变保存位置则无效)，用户将在不知不觉中扮演下载中间服务角色，上传文件。

P2P网络中，每个节点既可以从其他节点得到服务，也可以向其他节点提供服务。

udp,保证实时性以及多播，TCP包超时重传不合适。

UDP比TCP损耗小，不但是网速损耗，还有控制损耗（即额外一次三次握手，两次窗口控制等）。

#### 分布式锁的三种实现原理？

```
1. 基于数据库实现分布式锁；
2. 基于缓存（Redis等）实现分布式锁；
3. 基于Zookeeper实现分布式锁；
```

**数据库分布式锁实现**
缺点：

1.db操作性能较差，并且有锁表的风险
2.非阻塞操作失败后，需要轮询，占用cpu资源;
3.长时间不commit或者长时间轮询，可能会占用较多连接资源

**Redis(缓存)分布式锁实现**
缺点：

1.锁删除失败 过期时间不好控制
2.非阻塞，操作失败后，需要轮询，占用cpu资源;

**ZK分布式锁实现**
缺点：性能不如redis实现，主要原因是写操作（获取锁释放锁）都需要在Leader上执行，然后同步到follower。

总之：ZooKeeper有较好的性能和可靠性。  	