# 集合

## HashMap

### 特性

**1.** `null` 可以作为键，但只能有一个，多次赋值会进行覆盖操作，值可以有多个null(无限制)

**2.** 当`get` 方法获取值为 `null` 时，有可能是没有这个key,也有可能是key的值就为null,所以判断是否存在某个键得用 `containsKey`判断

**3.** 计算 `index`=hash&（length-1）

**4.** 负载因子0.75

**5.** 初始容量为16  newSize=oldSize*2

**6.** Map中的键值对包括 **数组** 和 **链表/红黑树** 的，即现容量大小既包括数组有kv的数量也包括链表/红黑树中节点的数量

**7.** 1.8中，链表长度为8则进化为红黑树，6则退化为链表

**8.** 真正初始化哈希表（初始化存储数组`table`）是在第1次添加键值对时，即第1次调用`put（）`时，`new` 只是接收 负载因子 等参数。

### 负载因子0.75？

负载因子过大，可存放的元素多，空间利用率高，但是哈希冲突大，导致查找效率低。

负载因子过小，可存放的元素少，空间利用率低，但是哈希冲突小，查询效率高。

**空间+时间** 之间的平衡。

若内存充足，可以适当调小负载因子。若内存不足，则可适当调大负载因子。

### 扩容为2的幂？

`index` = (hash & length-1)  只有当length为2的幂时，length-1所有位才为1，则比较的是hash的值，不然为0的话结果就一定是0 主要还是为了减少哈希冲突

### 红黑树的阀值为8？

泊松分布概率统计，发生8次哈希冲突的概率很低。7作为中间值，防止频繁的转化。

### 1.7 1.8的区别

![img](https://upload-images.jianshu.io/upload_images/944365-f5a75aa358889853.png)

<img src="https://upload-images.jianshu.io/upload_images/944365-45ec8c640c5e5363.png" alt="img" style="zoom:100%;" />

进行扰动处理的目的是为了分布均匀，减少哈希冲突。

#### 扩容时机

**1.7**

先扩容 后插入

插入值时判断 **当前容量>=阀值且发生Hash冲突** 扩容

**1.8**

先插入 后扩容

先插入再判断 **当前容量>=阀值** 扩容

#### 1.8扩容时，位置计算方式

![img](https://upload-images.jianshu.io/upload_images/944365-a467fdaa3a110350.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp)

#### 1.7头插法 1.8尾插法原因？

1.7是用单链表进行的纵向延伸，当采用头插法时会容易出现 **数据丢失** 和 **环形链表** 死循环问题。

在并发   扩容`resize（）`过程中，在将旧数组上的数据 转移到新数组上时，**转移数据操作 = 按旧链表的正序遍历链表、在新链表的头部依次插入**，即在转移数据、扩容后，容易出现**链表逆序的情况**

1.8 使用尾插法，可能发生 **数据覆盖** 

如果线程A和线程B同时进行put操作，刚好这两条不同的数据hash值一样，并且该位置数据为null，所以这线程A、B都会进入第6行代码中。假设一种情况，线程A进入后还未进行数据插入时挂起，而线程B正常执行，从而正常插入数据，然后线程A获取CPU时间片，此时线程A不用再进行hash判断了，问题出现：线程A会把线程B插入的数据给**覆盖**，发生线程不安全。

### Key为Student类需要重写什么方法？

 `hashCode` 和 `equals` 方法

**假设Stu类有 id属性**

首先重写 `hashCode` ，因为是通过 `hashCode` 计算 `index` 的。

一般认为id相同即为同个Stu，若不重写hashCode，则获取值为对象的地址，那么即时id相同的不同对象，hashCode也不同，则定位到的位置 `index` 也不同，则不符合逻辑，因此得重写`hashCode` 逻辑为返回id。

接着要重写 `equals` ,因为假若发生哈希冲突后，链表上所有key的`hashCode`相等，这时得用 `equals` 判断插入的新Key与已存在的Key对比，默认 `equals` 方法等于 ‘==’ 比较对象地址，因此要重写。重写可以将两个对象的各个属性依次对比，只有全部符合才相等。为了保证key在Map中的唯一性。

**简单来说**

通过 `hashCode`定位，通过`equals`比较链表上的key

### 为什么不用B+树、AVL树而用红黑树

红黑树和AVL树都是**最常用的平衡二叉搜索树**，它们的查找、删除、修改都是O(lgn) 

在插入/修改时，红黑树完成平衡的次数小于AVL树，即红黑树快于AVL树。

在查找时，AVL树快于红黑树。

（1）AVL树是更加严格的平衡，因此可以提供更快的查找速度，一般读取查找密集型任务，适用AVL树。
（2）红黑树更适合于插入修改密集型任务。



B+树数据都存储在叶子节点，数据挤在一个节点里，遍历为链表，时间复杂度慢。



## ConcurrentHashMap

### 1.7

**ReentrantLock+Segment+HashEntry+链表**

Segment 继承于 `ReentrantLock`

**每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment。**理论上可以并发的线程数为Segment大小

![img](https://upload-images.jianshu.io/upload_images/2184951-af57d9d50ae9f547.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/767/format/webp)

**定位**

两次定位。

segment[]位置：key **hash值的高位**  & **segment数组大小-1**

hashEntry[]位置：key **hash值的高位**  & **entry数组大小-1**

- 由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值。
- ConcurrentHashMap 的 get 方法是非常高效的，**因为整个过程都不需要加锁**。

**put**

当执行`put`方法插入数据的时候，根据key的hash值，在`Segment`数组中找到对应的位置

如果当前位置没有值，则通过**CAS**进行赋值，接着执行`Segment`的`put`方法通过加锁机制插入数据

假如有线程AB同时执行相同`Segment`的`put`方法

> 线程A 执行`tryLock`方法成功获取锁，然后把`HashEntry`对象插入到相应位置
>
> 线程B 尝试获取锁失败，则执行`scanAndLockForPut()`方法自旋，通过重复执行`tryLock()`方法尝试获取锁
>
> 在**多处理器**环境重复**64**次，**单处理器**环境重复**1**次，当执行`tryLock()`方法的次数超过上限时，则执行`lock()`方法挂起线程B
>
> 当线程A执行完插入操作时，会通过`unlock`方法施放锁，接着唤醒线程B继续执行

**size**

统计每个 segment对象中的元素个数，然后累加。

当计算后面的 segment 元素个数时，前面segment 发生增加或删除 则结果不一定准确

**先采用不加锁方式，连续计算两次**

若两次结果相等，则结果准确。

若两次结果不相等，则把所有 segment 加锁 然后再次计算

**resize**

put元素时做扩容，获取到锁之后，在当线程中扩容（和hashmap差不多）

### 1.8

**synchronized+CAS+HashEntry+链表+红黑树**

![img](https://upload-images.jianshu.io/upload_images/2184951-d9933a0302f72d47.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/768/format/webp)

为每一行数据加锁，即每个数组元素行加锁。

**为什么改为synchronized？**

**锁的粒度变小，并且新版本对syn进行了优化**

**put**

检查传入的参数, ConcurrentHashmap 不允许null值

根据key hash值找到 node数组位置。

若当前位置node未初始化，则通过 **CAS** 插入数据

若当前位置已有值并且hash值！=-1，则对该节点加 synchronized锁，然后从该节点遍历，直到有空的位置。尾插法。

若当前位置已有值并且hash值==-1，说明其它线程在扩容，参与一起扩容

#### 扩容

**属性**

`nextTable` 新的数组，大小为旧的两倍。

`sizeCtl` 

多线程之间，以volatile的方式读取sizeCtl属性，来判断ConcurrentHashMap当前所处的状态。通过cas设置sizeCtl属性，告知其他线程ConcurrentHashMap的状态变更。

![img](https://upload-images.jianshu.io/upload_images/6283837-f2a6af20a4c73b93.png?imageMogr2/auto-orient/strip|imageView2/2/w/969/format/webp)



![img](https://upload-images.jianshu.io/upload_images/4236553-9fd0441a1f41116b.png?imageMogr2/auto-orient/strip|imageView2/2/w/906/format/webp)

该变量高 16 位保存 length 生成的标识符，低 16 位保存并发扩容的线程数，通过这连个数字，可以判断出，是否结束扩容了。

`stride`

指定每个线程可以负责多少个桶，若当前机器的cpu核数大于1的时候，每个线程负责 n/(8 * 核数)。其中每个线程最小也需要负责16个桶

`transferIndex` 

扩容索引，表示已经分配给扩容线程的table数组索引位置。主要用来协调多个线程，并发安全地
获取迁移任务（hash桶）。



1 在扩容之前，transferIndex 在数组的最右边 。此时有一个线程发现已经到达扩容阈值，准备开始扩容。

![img](https:////upload-images.jianshu.io/upload_images/6283837-6a95de459a4f48d5.png?imageMogr2/auto-orient/strip|imageView2/2/w/833/format/webp)

2 扩容线程，在迁移数据之前，首先要将transferIndex左移（以cas的方式修改 **transferIndex=transferIndex-stride(要迁移hash桶的个数)**），获取迁移任务。每个扩容线程都会通过for循环+CAS的方式设置transferIndex，因此可以确保多线程扩容的并发安全，按照降序的顺序进行迁移数据table[31]--->table[16]

![img](https:////upload-images.jianshu.io/upload_images/6283837-7e10aa6066673c79.png?imageMogr2/auto-orient/strip|imageView2/2/w/1012/format/webp)



换个角度，我们可以将待迁移的table数组，看成一个任务队列，transferIndex看成任务队列的头指针。而扩容线程，就是这个队列的消费者。扩容线程通过CAS设置transferIndex索引的过程，就是消费者从任务队列中获取任务的过程。为了性能考虑，我们当然不会每次只获取一个任务（hash桶），因此ConcurrentHashMap规定，每次至少要获取16个迁移任务



`ForwardingNode节点` 

1.表示其它线程正在扩容，并且当前节点已扩容完毕。

2.关联了`nextTable` ，扩容期间可以通过 `find` 方法，访问已经迁移到 `nextTable` 中的数据



**实际扩容方法transfer**

1.第一个扩容线程进来后创建nextTable数组，并设置transferIndex；

2.线程（第一个或其他）通过transferIndex-stride（扩容步长）来领取一个扩容子任务，transferIndex减到0说明所有子任务领取完成；

3.线程领取到扩容子任务后设置当前处理子任务的下界并更新当前处理节点所在的索引位置；

4.对子任务中的每个节点，扩容线程**从后向前**依次判断该节点是否已经转移，如果没有转移，则对该节点进行加锁，并且把节点对应的链表或红黑树转移到新数组nextTable中去；

5.如果线程处理的节点索引已经到达子任务的下界，则子任务执行结束，并尝试去领取新的子任务，若领取不到再判断当前线程是否是最后一个扩容线程，若是则最后扫描一遍数组，执行清理工作，否则直接退出。



`helptransfer` 协助扩容

**fwd节点下的写/读操作？**

已经扩容完的节点被设置为 `fwd` ，**其它线程进行 `put`/`remove`操作时，会先帮助扩容**，即

假设线程A正在迁移 31-16的桶 ，线程B帮助扩容，则会去迁移15-0的桶

**其它线程若是 `get` 方法，则会调用 `fwd.find()` 方法去 `nextTable` 查找数据。**



**正在扩容中的写/读操作?**

**读操作**仍然可以读取桶上的数据

在扩容过程期间形成的 hn 和 ln链 是使用的类似于复制引用的方式，也就是说 ln 和 hn 链是复制出来的，而非原来的链表迁移过去的，所以原来 hash 桶上的链表并没有受到影响，因此从迁移开始到迁移结束这段时间都是可以正常访问原数组 hash 桶上面的链表

**写操作**

因为在迁移时会先锁住节点，而 `put`操作也需要获取该锁，因此会堵塞直到迁移完毕 

**为什么ConcurrentHashMap以及Hashtable这样的同步容器不允许键值对为null呢？**

因为concurrenthashmap以及hashtable是用于多线程的，如果map.get(key)得到了null，不能判断到底是映射的value是null,还是因为 没有找到对应的key而为空，而用于单线程状态的hashmap却可以用containKey（key） 去判断到底是否包含了这个null。
ConcurrentHashMap为什么就不能containKey(key)？因为一个线程先get(key)再containKey(key)，这两个方法的中间时刻，其他线程怎么操作这个key都会可能发生，例如删掉这个key。



**什么时候发生扩容**

(1) 在调用 addCount 方法增加集合元素计数后发现当前集合元素个数到达扩容阈值时就会触发扩容 。

(2) 扩容状态下其他线程对集合进行插入、修改、删除、合并、compute 等操作时遇到 ForwardingNode 节点会触发扩容 。

(3) putAll 批量插入或者插入节点后发现存在链表长度达到 8 个或以上，但数组长度为 64 以下时会触发扩容 。

注意：桶上链表长度达到 8 个或者以上，并且数组长度为 64 以下时只会触发扩容而不会将链表转为红黑树 。





**size**

用一个 volatile `baseCount` 变量来记录ConcurrentHashMap 当前 `节点的个数`。

- 1. 先尝试通过CAS 修改 `baseCount`
- 1. 如果多线程竞争激烈，某些线程CAS失败，那就CAS尝试将 `CELLSBUSY` 置1，成功则可以把 `baseCount变化的次数` 暂存到一个数组 `counterCells` 里，后续数组 `counterCells` 的值会加到 `baseCount` 中。
- 1. 如果 `CELLSBUSY` 置1失败又会反复进行CAS`baseCount` 和 CAS`counterCells`数组

```
if(root==null) return 0;
        List<TreeNode> queue=new LinkedList<>();
        queue.add(root);
        int res=0;
        while(!queue.isEmpty()){
            List<TreeNode> temp=new LinkedList<>();
            for(TreeNode node:queue){
                if(node.left!=null) temp.add(node.left);
                if(node.right!=null) temp.add(node.right);
            }
            queue=temp;
            res++;
        }
        return res;
```

#### 1.8为什么放弃Segment

**锁的粒度小了**

**JDK1.8的实现降低锁的粒度，JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（首节点）**

Synchronized是将每一个Node对象作为了一个锁,这样做的好处是什么呢?将锁细化了,也就是说,除非两个线程同时操作一个Node,注意,是一个Node而不是一个Node链表哦,那么才会争抢同一把锁.

锁已经被细化到这种程度了,那么出现并发争抢的可能性还高吗?还有就是,哪怕出现争抢了,只要线程可以在30到50次自旋里拿到锁,那么Synchronized就不会升级为重量级锁,而等待的线程也就不用被挂起,我们也就少了挂起和唤醒这个上下文切换的过程开销.

Synchronized和ReentrantLock他们的开销差距

Synchronized是根据不同策略将waitSet中的节点放到cxq or entryList中，尝试获取锁只会是cxq or entryList中的头节点，不会是全部节点尝试获取锁

如果是线程并发量不大的情况下,那么Synchronized因为自旋锁,偏向锁,轻量级锁的原因,不用将等待线程挂起,偏向锁甚至不用自旋,所以在这种情况下要比ReentrantLock高效

## HashTable

数组+链表，无论key和value都不能为null

线程安全，`put` 方法使用`synchronized` 锁住整个Table，所以效率低。

## HashSet

HashSet中不允许有重复元素，这是因为HashSet是基于HashMap实现的，HashSet中的元素都存放在HashMap的key上面，而value中的值都是统一的一个`private static final Object PRESENT = new Object();`。 HashSet跟HashMap一样，都是一个存放链表的数组。

```
public` `boolean add(E e) { 
  ``return` `map.put(e, PRESENT)==``null``; 
  ``} 
```

如果添加的元素不存在则直接添加，否则直接返回false;

**为什么HashTable、ConcurrentHashMap KEY VALUE 不能为NULL，而HashMap可以？**

HashTable、ConcurrentHashMap都是支持并发的，如果通过 containsKey() 判断后再执行下一步操作，再多线程情况下，其它线程有可能已经改变了该状态。

HashMap不支持并发，即有happens-before保证不会出现上述情况。

因为get（key）和contains（key）是两个操作，在单线程情况下两个操作一定是连着的，但是多线程情况下两个操作不一定连着，无法确保中间会不会被修改数据。



## WeakHashMap弱引用

hashmap key value都是强引用

weakhashmap key是弱引用，value是强引用

通过GC时有可能会对没有手动remove的key进行清除

那value是什么时候清除？

key被GC清除的Entry会被放入ReferenceQueue中，通过遍历ReferenceQueue并且设置value为null，对value进行清除

get/put/remove等正常api操作都会做entry的清理工作，防止内存泄漏

**虚引用**

虚引用并不会决定对象的生命周期。如果一个对象仅持有 虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。

当gc时发现对象有虚引用，则在对象回收之前，把该虚引用添加到ReferenceQueue中然后进行额外操作

虚引用主要是用来对象被gc时进行一些额外操作，例如数据清理 堆外内存