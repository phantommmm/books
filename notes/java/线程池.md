### 线程池

**为什么要使用线程池？**

减少线程创建和销毁的次数，每个工作线程可以被重复使用执行任务。

**线程池类型**

**Executors.newSingleThreadExecutor(1,1,LinkedBlockingQueue)**

创建一个单线程的线程池，只有一个线程串行按顺序执行所有任务，如果唯一的线程因为异常借宿，会有一个新的线程代替他。

**Executors.newFixedThreadPool(n,n,LinkedBlockingQueue)**

创建固定大小的线程池。

**Executors.newCachedThreadPool(0,Integer.Max,SynchronizedQueue)**

它是一个可以无限扩大的线程池；

它比较适合处理执行时间比较小的任务；

corePoolSize为0，maximumPoolSize为无限大，意味着线程数量可以无限大；

keepAliveTime为60S，意味着线程空闲时间超过60S就会被杀死；

采用SynchronousQueue装等待的任务，这个阻塞队列没有存储空间，这意味着只要有请求到来，就必须要找到一条工作线程处理他，如果当前没有空闲的线程，那么就会再创建一条新的线程

![img](https://pic1.zhimg.com/80/v2-f9cff0865c6143ace452274046322335_1440w.jpg?source=1940ef5c)

**Executors.newScheduledThreadPool(n,Integer.MAX_VALUE,DelayedWorkQueue)**

创建一个定长线程池，支持定时及周期性任务执行。

```
scheduledThreadPool.scheduleAtFixedRate(new Runnable() {
@Override
public void run() {
System.out.println("delay 1 seconds, and excute every 3 seconds");
}
}, 1, 3, TimeUnit.SECONDS);
```



**缓冲队列**

**LinkedBlockingQueue**

默认大小为Integer.Max，尾部放任务，头部拿任务

takeLock putLock分别加锁

**ArrayBlockingQueue**

创建时设置大小

take put Lock加同一把锁

**SynchronusQueue**

不缓存任务到队列中，来一个任务就消费一个任务。

![image](http://images.cnitblog.com/blog/497634/201401/08000847-0a9caed4d6914485b2f56048c668251a.jpg)

**拒绝策略**

```
ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 
ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 （当作没事）
ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）
ThreadPoolExecutor.CallerRunsPolicy：由调用者线程处理该任务

自定义拒绝策略重写接口方法rejectExecutor();
```

**tasks** 每秒需要处理的最大任务数量

**tasktime** 处理一个任务所需要的实际

**responsetime** 系统允许任务最大的响应时间，比如每个任务的响应时间不得超过2秒。



**corePoolSize** 

每个任务需要tasktime秒处理，则每个线程每钞可处理1/tasktime个任务。系统每秒有tasks个任务需要处理，则需要的线程数为：tasks/(1/tasktime)，即tasks ** tasktime个线程数。*

假设系统每秒任务数为100~1000，每个任务耗时0.1秒，则需要100 * 0.1至1000*0.1，即10~100个线程。那么corePoolSize应该设置为大于10，具体数字最好根据8020原则，80琐碎20重要 则corePoolSize可设置为20。

**queueCapacity**

任务队列的长度要根据核心线程数，以及系统对任务响应时间的要求有关。

队列长度可以设置为(corePoolSize/tasktime) * responsetime： (20/0.1)*2=400，即队列长度可设置为400。

队列长度设置过大，会导致任务响应时间过长，切忌以下写法：

LinkedBlockingQueue queue = new LinkedBlockingQueue();

这实际上是将队列长度设置为Integer.MAX_VALUE，将会导致线程数量永远为corePoolSize，再也不会增加，当任务数量陡增时，任务响应时间也将随之陡增。

**maxPoolSize**

当系统负载达到最大值时，核心线程数已无法按时处理完所有任务，这时就需要增加线程。每秒200个任务需要20个线程，那么当每秒达到1000个任务时，则需要(1000-queueCapacity)*(20/200)，即60个线程，可将maxPoolSize设置为60。

**keepAliveTime**

线程数量只增加不减少也不行。当负载降低时，可减少线程数量，如果一个线程空闲时间达到keepAliveTiime，该线程就退出。默认情况下线程池最少会保持corePoolSize个线程。

**allowCoreThreadTimeout**

默认情况下核心线程不会退出，可通过将该参数设置为true，让核心线程也退出。



**任务类型**

对于不同的任务 需要分配不同参数的线程池

**CPU密集型：** 大量的纯计算

**IO密集型：** 大量网络 文件操作

**CPU密集型任务** 
尽量使用较小的线程池，一般为**CPU核心数+1。** 
因为CPU密集型任务使得CPU使用率很高，若开过多的线程数，只能增加上下文切换的次数，因此会带来额外的开销。

**IO密集型任务 **
可以使用稍大的线程池，一般为**2*CPU核心数+1。** 
IO密集型任务CPU使用率并不高，因此可以让CPU在等待IO的时候去处理别的任务，充分利用CPU时间。

**混合型任务 **
可以将任务分成IO密集型和CPU密集型任务，然后分别用不同的线程池去处理。 
只要分完之后两个任务的执行时间相差不大，那么就会比串行执行来的高效。 
因为如果划分之后两个任务执行时间相差甚远，那么先执行完的任务就要等后执行完的任务，最终的时间仍然取决于后执行完的任务，而且还要加上任务拆分与合并的开销，得不偿失。



![image-20200225163630892](C:\Users\15521\AppData\Roaming\Typora\typora-user-images\image-20200225163630892.png)

比如平均每个线程CPU运行时间为0.5s，而线程等待时间（非CPU运行时间，比如IO）为1.5s，CPU核心数为8，那么根据上面这个公式估算得到：((0.5+1.5)/0.5)*8=32。这个公式进一步转化为：

![image-20200225163641323](C:\Users\15521\AppData\Roaming\Typora\typora-user-images\image-20200225163641323.png)

**线程等待时间所占比例越高，需要越多线程。线程CPU时间所占比例越高，需要越少线程。**

一个系统最快的部分是CPU，所以决定一个系统吞吐量上限的是CPU。增强CPU处理能力，可以提高系统吞吐量上限。但根据短板效应，真实的系统吞吐量并不能单纯根据CPU来计算。那要提高系统吞吐量，就需要从“系统短板”（比如网络延迟、IO）着手：

- 尽量提高短板操作的并行化比率，比如多线程下载技术
- 增强短板能力，比如用NIO替代IO

**是否使用线程池就一定比使用单线程高效呢？**

答案是否定的，比如Redis就是单线程的，但它却非常高效，基本操作都能达到十万量级/s。从线程这个角度来看，部分原因在于：

- 多线程带来线程上下文切换开销，单线程就没有这种开销
- 锁

当然“Redis很快”更本质的原因在于：Redis基本都是内存操作，这种情况下单线程可以很高效地利用CPU。而多线程适用场景一般是：存在相当比例的IO和网络操作。

**怎么监控线程数？**

通过 **继承线程池ThreadPoolExecutor** 并重写 **beforeExecute afterExecute terminated**方法，可以在 **任务执行前** **任务执行后** **线程池关闭前** 做事例如：记录时间 线程数等。

### Wait Notify

**为什么一定要在同步块中？**

**前提**

每一个对象都有一个对应的 **监视器**

每一个监视器里面都有 **一个该对象的锁** 和 **一个等待队列** 和 **一个同步队列**

**wait** 释放当前的锁 并且进入等待队列

**notify** 唤醒一个线程，首先要找到等待队列，不获取对象的锁 怎么去到等待队列?

wait是把线程加入 **等待队列**

notify 是把 **等待队列中的线程** 加入到 **同步队列** 中去竞争

如果不在同步块中，即都没获取到对象的锁 又如何让对象通知线程释放锁、竞争锁呢？

**为什么要使用while 而不是 if?**

当多个线程wait之后，后面的代码就不执行了。

在 **if** 中 那么当对象执行notify后，被唤醒的线程继续执行 **if** 后面的代码并且不会再次判断if是否满足就执行 **if** 之后的代码（而不管是否满足if条件，则会造成错误）

在 **while** 中，被唤醒后 还会判断一次条件是否满足。

```
//消费者	第一次判断商品数量<=0后 wait
//		  等到商品数量增加>0时 被唤醒后 不执行判断 直接notify生产者
if(count<=0){
	wait;
}		
data[count-1];//这里可能会出错
notify;

while(count<=0){
	wait;
}
data[count-1];//因为再执行一次while判断则不会出错
notify;
```



**丢失唤醒**

由于wait不在同步块中，所以对象**执行wait()**到**线程接到通知进入等待这段时间是可以被其他线程插队**，如果这时**插队的线程发出notify信号发出则会被忽略**，因为本来要被wait的线程还在卡着呢。

总之，这里的竞争条件，我们可能在**丢失一个通知**，如果我们使用缓冲区或者只有一个产品，生产者线程将永远等待，你的程序也就挂起了。