# 网络

<img src="https://user-gold-cdn.xitu.io/2017/1/8/2f37ad4d1d33898a58dce80f0eccad0a?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img" style="zoom: 33%;" />

![img](https://user-gold-cdn.xitu.io/2017/1/8/cd9dc78d97726581e081993adbb58b84?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

# HTTP

HTTP是一种不保存状态的协议，即协议对于发送过的请求和接受的响应都不做持久化的处理

HTTP是**明文协议**。**每个HTTP请求和返回的每个byte都会在网络上明文传播，不管是url，header还是body**。这完全不是一个“是否容易在浏览器地址栏上看到“的问题。

**为什么这么做？**

把HTTP设计得简单，为了可以更快的处理大量的事务，确保协议的可伸缩性。

**那我要保存状态怎么做？**

**HTTP/1.1 引入了COOKIE技术**

<img src="https://user-gold-cdn.xitu.io/2017/1/8/4f4dbd71844417c74a36b0382e0f8a98?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img" style="zoom:67%;" />

**HTTP 1.1 引入了流水线（Pipelining）处理**，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。

例如：一个包含有许多图像的网页文件的多个请求和应答可以在一个连接中传输，但每个单独的网页文件的请求和应答仍然需要使用各自的连接。 

HTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容。



**HTTP/1.1加入了一个新的状态码100（Continue）。**客户端事先发送一个只带头域的请求，如果服务器因为权限拒绝了请求，就回送响应码401（Unauthorized）；如果服务器接收此请求就回送响应码100，客户端就可以继续发送带实体的完整请求了。100 (Continue) 状态代码的使用，允许客户端在发request消息body之前先用request header试探一下server，看server要不要接收request body，再决定要不要发request body。

**HTTP/1.1中引入了Chunked transfer-coding**来解决上面这个问题，发送方将消息分割成若干个任意大小的数据块，每个数据块在发送时都会附上块的长度，最后用一个零长度的块作为消息结束的标志。这种方法允许发送方只缓冲消息的一个片段，避免缓冲整个消息带来的过载。

HTTP/1.1在1.0的基础上加入了一些cache的新特性，当缓存对象的Age超过Expire时变为stale对象，cache不需要直接抛弃stale对象，而是与源服务器进行重新激活（revalidation）。

**HTTP/1.1增加host字段** ，在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。

 HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。此外，服务器应该接受以绝对路径标记的资源请求。

### HTTP连接优化

#### 并行连接

服务端接受多条http连接。

**优点：**宽带资源充足情况下，同时建立多个HTTP连接，加快页面加载速度。

**缺点：**宽带资源不足情况下，效率会下降。同一时间建立多条连接消耗大量内存，对服务端来说，大量的用户产生大量的连接可能会超过服务端的处理能力。

#### 持久连接

**非持久连接：HTTP处理完后，TCP连接断开**

**TCP连接不断开**

http允许在事务处理结束后将TCP连接保持在打开状态，以便未来的HTTP请求重用现存的连接。

在事务处理结束之后仍然保持在打开状态的TCP连接称之为持久连接。

重用已对目标服务端打开的空暇持久连接，就能够避免缓慢的连接建立阶段。同一时候，已经打开的连接还能够避免慢启动的拥塞适应阶段。以便更快的进行传输数据。

**目前WEB服务器基本使用 并行连接和持久连接**

#### 持久连接类型

##### HTTP/1.0 keep-alive

需要通过报文首部请求，默认是不支持持久连接的。

客户端发生请求报文头部包含Connection：Keep-Alive 首部请求将连接保持在打开状态。

如果服务器愿意为下一条请求将连接保持在打开状态，就在响应中包含相同的首部。

如果响应中没有Connection：Keep-Alive首部，客户端就认为服务器不支持keep-alive，会在发回响应报文之后关闭连接。

##### HTTP/1.1 persistent

默认情况下都是持久连接。

请求报文中添加一个Connection:close首部用来关闭持久连接。

当客户端收到响应报文中包含close首部，就会关闭连接。

不是没有接受到close首部连接就会一直存在，前提是该连接的所有报文都正确。例如：自定义报文长度和实际报文长度一致时，才能保证连接持久，否则连接断开。

#### 管道化连接

Http1.1允许在持久连接上使用请求管道。

在响应到达之前，可以将多条请求放入队列，当第一条请求通过网络流向服务器时，第二条、第三条请求就可以开始发送。无需等到收到第一条响应再发送。

降低网络的环回实际，提高i性能。

**限制**

如果HTTP客户端无法确定连接是否是持久的，不应该使用管道。

必须按照请求的顺序返回响应。因为http报文中没有序列号标签。因此假设收到的响应失序了。那么就没办法将其与请求匹配起来了。

HTTP客户端必须做好连接会在任意时刻关闭的准备，还要准备好重发所有未完成管道化的请求。

HTTP客户端不应该用管道化的方式发送会产生副作用的请求（POST请求）。比方POST是要买一本书，再运行一次就又买了一本书，显然是不能运行的。

#### HTTP连接的关闭

HTTP通信建立在TCP连接之上，所以http连接的关闭事实上就是TCP连接的关闭。

连接关闭分为全然关闭和半关闭，close会**同一时候关闭输入和输出信道**，shutdown仅仅会**单独关闭输入或者输出信道**。

#### 队头堵塞问题

**TCP 和 HTTP1.1管道化都会出现队头阻塞情况**

**出现原因**

1. 独立的消息数据都在一个链路上传输，也就是有一个“队列”。比如TCP只有一个流，多个HTTP请求共用一个TCP连接
2. 队列上传输的数据有严格的顺序约束。比如TCP要求数据严格按照序号顺序，HTTP管道化要求响应严格按照请求顺序返回

**解决**

使用HTTP2，但若HTTP2底层使用的是TCP，仍可能出现TCP队头阻塞

使用QUIC，底层基于UDP，即不会有TCP队头堵塞。

# HTTPS

https用SSL/TLS协议协商出的密钥加密明文的http数据,保证安全性

假设客户端为爱丽丝，服务器为鲍勃

SSL/TLS握手阶段分为五步：

第一步，客户端给出协议版本号、一个客户端生成的随机数（Client random），以及客户端支持的加密方法。
第二步，服务器确认双方使用的加密方法，并给出数字证书、以及一个服务器生成的随机数（Server random）。
第三步，客户端确认数字证书有效，然后生成一个新的随机数（Premaster secret），并使用数字证书中的公钥，加密这个随机数，发给鲍勃。
第四步，服务器使用自己的私钥，获取客户端发来的随机数（即Premaster secret）。
第五步，客户端和服务器根据约定的加密方法，使用前面的三个随机数，生成"对话密钥"（session key），用来加密接下来的整个对话过程。



![img](http://www.ruanyifeng.com/blogimg/asset/2014/bg2014092003.png)

```
（1）生成对话密钥一共需要三个随机数。

（2）握手之后的对话使用"对话密钥"加密（对称加密），服务器的公钥和私钥只用于加密和解密"对话密钥"（非对称加密），无其他作用。

（3）服务器公钥放在服务器的数字证书之中。
```

非对称加密：加密 解密用的不是同一个密匙

对称加密：加密 解密用的是用一个密匙	

**CA证书：证书授权中心** 用于证明自己是哪个服务器，安不安全等

**CA证书在SSL中的作用？**

客户端需要对服务端的证书进行检查，如果证书不是可信机构颁布、或者证书中的域名与实际域名不一致、或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥(**公钥从证书中获取,证书的正确性由CA保证**)

**证书的申请过程**

<img src="https://img-blog.csdn.net/20170804162718409?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdXN0Y2N3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="证书工作流" style="zoom:50%;" />

**认证流程**

1、服务器生成一对密钥，私钥自己留着，公钥交给数字证书认证机构（CA）
2、CA进行审核，并用CA自己的私钥对服务器提供的公钥**进行签名生成数字证书**
3、在https建立连接时，客户端从服务器获取数字证书，用CA的公钥（根证书）对数字证书进行验证，比对一致，说明该数字证书确实是CA颁发的（得此结论有一个前提就是：客户端的CA公钥确实是CA的公钥，即该CA的公钥与CA对服务器提供的公钥进行签名的私钥确实是一对。），而CA又作为权威机构保证该公钥的确是服务器端提供的，从而可以确认该证书中的公钥确实是合法服务器端提供的。



**浏览器怎么验证https证书的合法性**

1.**验证证书是否过期**

证书中包含有效时间起使和截至时间

**2.验证证书是否已被吊销**

OCSP在线证书状态检查协议，应用按照标准发送一个请求，对某张证书进行查询，之后服务器返回证书状态。

**3.验证证书是否上级CA签发**

每一张证书都是由上级CA证书签发的，上级CA证书可能还有上级，最后会找到根证书。根证书即自签证书，自己签自己。
当你验证一张证书是否是由上级CA证书签发的时候，你必须有这张上级CA证书。通常这张证书会内置在浏览器或者是操作系统中，有些场景下应用系统也会保留。



**为什么握手阶段使用非对称加密而通信时使用对称加密?**

因为非对称加密加密解密算法效率较低，不适合客户端和服务器端这样高频率的通信过程，在某些极端情况下，甚至能比非对称加密慢上1000倍。

非对称加密的优势在于它可以很好帮助完成秘钥的交换，所以前期交换秘钥必须使用非对称加密算法。



**HTTP请求/响应报文**

![img](https://img2018.cnblogs.com/blog/993712/201909/993712-20190903135632412-483353454.jpg)



![img](https://user-gold-cdn.xitu.io/2017/1/8/e6a04516c5718cd294566461d7149aef?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

![img](https://user-gold-cdn.xitu.io/2017/1/8/59b3b008941490fecd38955c42026438?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

#### HTTP首部（1.1）

1.通用类型首部。请求报文和响应报文都会使用到的首部。

2.请求首部字段。从客户端向服务端请求报文的时候使用的首部。

  补充了请求的附加内容、客户端信息、响应客户端内容优先级等信息。

3.响应首部字段。

4.实体首部字段。针对请求报文和响应报文中的实体部分使用的首部。补充了资源内容更新时间等与实体相关的信息。

具体字段值及意义：https://www.cnblogs.com/xzsty/p/11452610.html

<img src="https://upload-images.jianshu.io/upload_images/1784460-e63662d7dd5df93c.png?imageMogr2/auto-orient/strip|imageView2/2/w/844/format/webp" alt="img" style="zoom:67%;" />

<img src="https://upload-images.jianshu.io/upload_images/1784460-26b6686284aa0ca8.png?imageMogr2/auto-orient/strip|imageView2/2/w/851/format/webp" alt="img" style="zoom:67%;" />![img](https://upload-images.jianshu.io/upload_images/1784460-cb4d3825dfb849a7.png?imageMogr2/auto-orient/strip|imageView2/2/w/845/format/webp)

![img](https://upload-images.jianshu.io/upload_images/1784460-cb4d3825dfb849a7.png?imageMogr2/auto-orient/strip|imageView2/2/w/845/format/webp)

<img src="https://upload-images.jianshu.io/upload_images/1784460-78fb6a2fdbaa4fbb.png?imageMogr2/auto-orient/strip|imageView2/2/w/838/format/webp" alt="img" style="zoom:67%;" />

<img src="https://upload-images.jianshu.io/upload_images/1784460-2aaeea57e9245e2f.png?imageMogr2/auto-orient/strip|imageView2/2/w/859/format/webp" alt="img" style="zoom:67%;" />

#### HTTP方法

<img src="https://upload-images.jianshu.io/upload_images/1784460-e71ea66c6f0b48fe.png?imageMogr2/auto-orient/strip|imageView2/2/w/693/format/webp" alt="img" style="zoom:67%;" />



#### GET: 一般用于获取/查询资源 从服务器上获取数据

根据HTTP规范，GET用于信息的获取，而且应该是安全的和幂等的。

安全：即不修改信息，不产生副作用。

幂等：对同一URL的多个请求应该返回相同的结果。数学中，对一个数进行多次相同的运算，结果一样，则该运算时幂等的。

但在实际应用中，以上2条规定并没有这么严格。比如，新闻站点的头版不断更新。虽然第二次请求会返回不同的一批新闻，该操作仍然被认为是安全的和幂等的，因为它总是返回当前的新闻。从根本上说，如果目标是当用户打开一个链接时，他可以确信从自身的角度来看没有改变资源即可。



**提交方式：**请求的数据会附在URL之后（就是把数据放置在HTTP协议头中），以‘?’分割URL和传输数据，多个参数用‘&’连接；地址栏中会显示出参数。

例如：login.action?name=hyddd&password=idontknow&verify=%E4%BD%A0%E5%A5%BD。

如果数据是英文字母/数字，原样发送，如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用BASE64加密，得出如：%E4%BD%A0%E5%A5%BD，其中％XX中的XX为该符号以16进制表示的ASCII。

**传输数据大小：**HTTP规范中没有对传输数据大小限制，但因为参数值在URL后面，但因为特定浏览器和服务器对URL长度有限制。因此对于GET提交时，传输数据就会受到URL长度的限制。

**安全性：**POST的安全性要比GET的安全性高。

比如：通过GET提交数据，用户名和密码将明文出现在URL上。

(1)登录页面有可能被浏览器缓存，(2)其他人查看浏览器的历史纪录，那么别人就可以拿到你的账号和密码了，除此之外，使用GET提交数据还可能会造成Cross-siterequest forgery攻击

#### POST: 一般用于更新/修改资源 往服务器上发送数据

根据HTTP规范，POST表示可能修改变服务器上的资源的请求。还是新闻以网站为例，读者对新闻发表自己的评论应该通过POST实现，因为在评论提交后站点的资源已经不同了，或者说资源被修改了。

**提交方式：**把提交的数据放置在是HTTP包的包体中。地址栏不会有参数列表。

**传输数据大小：**由于不是通过URL传值，理论上数据不受 限。但实际各个WEB服务器会规定对post提交数据大小进行限制。

**安全性：**高于GET。

### 区别

不同浏览器下，有些浏览器在POST在提交表单后，再刷新浏览器，会提示重新提交表单。

刷新浏览器会重新发送已经发送过的最后一个请求。如果是post，那么会再次提交表单。

解决：将最后一次的post改为get，get不会重新发送请求。

![img](https://upload-images.jianshu.io/upload_images/1023733-23175c8412d1fd9a.png?imageMogr2/auto-orient/strip|imageView2/2/w/495/format/webp)



对于GET方式，服务器端用Request.QueryString获取变量的值，

对于POST方式，服务器端用Request.Form获取提交的数据

GET请求只能进行url编码，而POST支持多种编码方式。

GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。

**GET产生一个TCP数据包；POST产生两个TCP数据包（http1.1）？**

对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；

而对于POST，浏览器先发送header，服务器响应100-continue，浏览器再发送data，服务器响应200 ok（返回数据）。

**第一次发送目的是让服务器解析请求头，然后决定怎么处理这个请求，打算处理则返回100-continue，否则返回4xx表示拒绝**

**收到100-continue后，则发送数据**

这样，就可以避免浪费带宽传请求体。但是代价就是会多一次Round Trip。如果刚好请求体的数据也不多，那么一次性全部发给服务器可能反而更好。

例如：比如写一个上传文件的服务，请求url中包含了文件名称，请求体中是个尺寸为几百兆的压缩二进制流。服务器端接收到请求后，就可以先拿到请求头部，查看用户是不是有权限上传，文件名是不是符合规范等。如果不符合，就不再处理请求体的数据了，直接丢弃。而不用等到整个请求都处理完了再拒绝。


在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。

并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。

**为什么浏览器在GET请求时，会主动缓存相应的css、js等静态文件 POST不会？**

因为浏览器GET对服务器的第一次请求会获取很多相关文件，如果每次都加载大量的文件对带宽、时间等有很大的损耗，所以GET请求后，将资源下载到本地，下次直接从本地拿，加快速度、减轻服务器压力

而POST请求一般是往服务器发送数据，每次发送的数据可能千奇百怪，服务端不会去缓存。

![img](https://images2015.cnblogs.com/blog/450613/201510/450613-20151025131542583-2058999195.png)

![img](https://images2015.cnblogs.com/blog/450613/201510/450613-20151025131611317-1162839517.png)



**【HEAD：获得报文首部】**
   HEAD方法和GET方法一样，知识不返回报文的主体部分，用于确认URI的有效性及资源更新的日期时间等。
   具体来说：1、判断类型； 2、查看响应中的状态码，看对象是否存在（响应：请求执行成功了，但无数据返回）； 3、测试资源是否被修改过
   HEAD方法和GET方法的区别： GET方法有实体，HEAD方法无实体。

**【PUT：传输文件】**
   PUT方法用来传输文件，就像FTP协议的文件上传一样，要求在**请求报文的主体中包含文件内容**，然后**保存在请求URI指定的位置**。但是HTTP/1.1的PUT方法自身不带验证机制，任何人都可以上传文件，存在安全问题，故一般不用。

**【DELETE：删除文件】**
   指明客户端想让服务器删除某个资源，与PUT方法相反，按URI删除指定资源

**【OPTIONS：询问支持的方法】**
   OPTIONS方法用来查询针对请求URI指定资源支持的方法（客户端询问服务器可以提交哪些请求方法）

**【TRACE：追踪路径】**
 TRACE方法是让Web服务器端将之前的请求通信还给客户端的方法追踪路径。

使得服务器原样返回任何客户端请求的内容。 

发送请求的时候，在Max-Forwards首部字段中加入数值，每经过一个服务器端该数字就减一，当数值刚好减到0的时候，就停止传输，最后收到请求的服务器返回的200OK的响应。





<img src="https://upload-images.jianshu.io/upload_images/1784460-97523af87c471edc.png?imageMogr2/auto-orient/strip|imageView2/2/w/726/format/webp" alt="img" style="zoom:80%;" />

**【CONNECT：要求用隧道协议连接代理】**
   CONNECT方法要求在与代理服务器通信时建立隧道，实现用隧道协议进行TCP通信。主要使用SSL（安全套接层）和TLS（传输层安全）协议把通信内容加密后经网络隧道传输。

<img src="https://upload-images.jianshu.io/upload_images/1784460-4ea04b8f472d7dea.png?imageMogr2/auto-orient/strip|imageView2/2/w/720/format/webp" alt="img" style="zoom:67%;" />



## HTTP 1.0

规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求。

在1.0时的会话方式：

1.建立连接 2.发出请求信息 3.回送响应信息 4.关掉连接

## HTTP 1.1

HTTP 1.1支持持久连接Persistent Connection, 并且默认使用persistent connection. 在同一个tcp的连接中可以传送多个HTTP请求和响应. 多个请求和响应可以重叠，多个请求和响应可以同时进行. 

HTTP1.1新增请求头：

Connection请求头的值为Keep-Alive时，客户端通知服务器返回本次请求结果后保持连接；Connection请求头的值为close时，客户端通知服务器返回本次请求结果后关闭连接。

HTTP 1.1还提供了与身份认证、状态管理和Cache缓存等机制相关的请求头和响应头。

### 从URL输入一个网址发生了什么？

<img src="https://img-blog.csdnimg.cn/20181204113749239.png" alt="urljieshi " style="zoom:67%;" />

#### 1.输入网址

www.163.com

#### 2.浏览器通过DNS服务器查找网址对应的IP地址

1. 浏览器首先查看**本地硬盘的hosts文件**，查看里面的映射中有没有该域名 对应的IP 有则直接返回。(etc/hosts)
2. 浏览器发起一个DNS请求到**本地DNS服务器**。本地DNS服务器一般都是你的网络接入服务器商提供，比如中国电信，中国移动。
3. 本地DNS服务器首先查询缓存记录，如果缓存中含有此条记录（即对应的IP），直接返回。否则，**本地DNS服务器**向**DNS根服务器查询。**
4. 根DNS服务器没有缓存具体的域名
5. 和IP的映射关系，而是记录了网址属于哪个区域(www.163.com属于.com区域管理)，告诉本地DNS服务器到相应的**域服务器**（.com服务器）上查询，给出相应的域服务器地址。
6. 本地DNS服务器向域服务器发出请求，域服务器返回相应的域名解析服务器地址。（163.com域服务器）
7. 本地DNS服务器向域名解析服务器发送请求，这时才收到域名和IP的映射关系，本地DNS把该IP地址返回给浏览器，还把该映射缓存起来，方便下次查询。

**递归查询--主机向本地域名服务器的查询**

​	如果主机所询问的本地域名服务器不知道被查询的域名的IP地址，那么本地域名服务器就以DNS客户的身份，

​    向其它根域名服务器继续发出查询请求报文(即替主机继续查询)，而不是让主机自己进行下一步查询。

​    因此，递归查询返回的查询结果或者是所要查询的IP地址，或者是报错，表示无法查询到所需的IP地址。

**迭代查询--本地域名服务器向根域名服务器的查询**

​	当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”。

​    然后让本地服务器进行后续的查询。根域名服务器通常是把自己知道的顶级域名服务器的IP地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。

​    顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的IP地址，要么告诉本地服务器下一步应当向哪一个权限域名服务器进行查询。

​    最后，知道了所要解析的IP地址或报错，然后把这个结果返回给发起查询的主机

**递归**：客户端只发一次请求，要求对方给出最终结果。

**迭代**：客户端发出一次请求，对方如果没有授权回答，它就会返回一个能解答这个查询的其它名称服务器列表，客户端会再向返回的列表中发出请求，直到找到最终负责所查域名的名称服务器，从它得到最终结果

**缓存机制**

一条域名的DNS记录会在本地有两种缓存：浏览器缓存和[操作系统](http://lib.csdn.net/base/operatingsystem)(OS)缓存。在浏览器中访问的时候，会优先访问浏览器缓存，

如果未命中则访问OS缓存，最后再访问DNS服务器(一般是ISP提供)，然后DNS服务器会递归式的查找域名记录，然后返回。

即解析过程 **浏览器缓存-->系统缓存-->hosts文件**



![img](https://images2017.cnblogs.com/blog/1171046/201712/1171046-20171226173034151-855747573.jpg)

#### 3.0 ARP寻找Mac地址

通过ARP协议实现通过IP地址获取主机的物理地址。

**1.**每个主机有一个ARP缓冲区建立一个ARP列表，表示IP和MAC的映射

**2.**当源主机要发送数据时，首先检查本机ARP列表中是否有对应IP地址的目的主机的MAC地址，如果有，则直接发送数据，如果没有，就向本网段的所有主机发送ARP数据包，该数据包包括的内容有：源主机 IP地址，源主机MAC地址，目的主机的IP 地址。 

**3.** 当本网络的所有主机收到该ARP数据包时，首先检查数据包中的IP地址是否是自己的IP地址，如果不是，则忽略该数据包，如果是，则首先从数据包中取出源主机的IP和MAC地址写入到ARP列表中，如果已经存在，则覆盖，然后将自己的MAC地址写入ARP响应包中，告诉源主机自己是它想要找的MAC地址。 

**4.**ARP响应包后。将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据。如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。

#### 3.1 使用套接字

调用系统库函数 socket,请求一个TCP流套接字。

请求首先在**传输层**封装成**TCP segment(片)**，在头部添加**目标端口**。

TCP segment 被送往**网络层**，网络层会在其中再加入一个 **IP 头部**，里面包含了目标服务器的IP地址以及本机的IP地址，把它封装成一个**IP packet**。

这个 TCP packet 接下来会进入**链路层**，链路层会在封包中加入 **frame 头部**，里面包含了**本地内置网卡的MAC地址以及网关（本地路由器）的 MAC 地址**。像前面说的一样，如果内核不知道网关的 MAC 地址，它必须进行 ARP 广播来查询其地址。

#### 3.2 建立TCP连接（三次握手）

浏览器拿到IP地址后，会以随机端口（1024--65535）向WEB服务器程序80端口发起TCP连接。

#### 4.浏览器向WEB服务器发起Http请求

HTTP请求：请求方法、URL、协议版本

​					 请求头

​					 请求体

<img src="https://img-blog.csdn.net/20180519235118178?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsZXhzaGk1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img" style="zoom:67%;" />

#### 4.1服务器负载均衡

网站可能设置负载均衡来平衡分配用户请求。

当服务端配置了负载均衡，则前一步dns解析到的ip地址为负载均衡服务器Ip地址，接着再有负载均衡服务器将请求转发到后台服务器。

#### 5.服务器端处理

服务器端收到请求后的由web服务器（准确说应该是http服务器）处理请求，诸如Apache、Ngnix、IIS等。web服务器解析用户请求，知道了需要调度哪些资源文件，再通过相应的这些资源文件处理用户请求和参数，并调用数据库信息，最后将结果通过web服务器返回给浏览器客户端。

<img src="https://img2018.cnblogs.com/blog/1171046/201904/1171046-20190409191054591-1163748805.png" alt="img" style="zoom:67%;" />

#### 6.关闭TCP连接（四次挥手）

为了避免服务器与客户端双方的资源占用和损耗，当双方没有请求或响应传递时，任意一方都可以发起关闭请求。

#### 7.浏览器解析资源

浏览器解析获取到的HTML、CSS、JS、图片等等资源。

#### 8.浏览器布局渲染

浏览器通过解析的资源渲染页面展示给用户

**应用层寻找DNS 发起HTTP请求**

**传输层建立TCP连接**

**网络层IP地址**

**链路层 MAC地址（物理地址）**

### 分布式Session共享？

**问题：** 在搭建完集群环境后，不得不考虑的一个问题就是用户访问产生的session如何处理。如果不做任何处理的话，用户将出现频繁登录的现象，比如集群中存在A、B两台服务器，用户在第一次访问网站时，Nginx通过其负载均衡机制将用户请求转发到A服务器，这时A服务器就会给用户创建一个Session。当用户第二次发送请求时，Nginx将其负载均衡到B服务器，而这时候B服务器并不存在Session，所以就会将用户踢到登录页面。这将大大降低用户体验度，导致用户的流失，这种情况是项目绝不应该出现的。 

**http是无状态协议的**：比如登录邮箱后，进行发送邮件操作（又要登录？）以此引出session

#### 1.粘性Session

**原理：**将用户SessionId锁定到某一服务器上，如将用户a锁定到A服务器上后，以后每次请求都转发到服务器A上。

**优点：**简单，直接

**缺点：**缺乏容错率，当锁定的服务器发生故障，用户信息被转移到第二个服务器，而用户session还未过期时，用户还是得重新登录，之前的session信息失效。

#### 2.服务器session复制

**原理：**任何一个服务器上的session发生变化（增删改），该服务器将该session序列化后，广播给其他所有服务器，保证session同步。

**优点：**容错率高，各个服务器实时同步session

**缺点：**对网络负荷造成一定压力，若同一时刻session量大，可能造成网络堵塞，拖慢服务器性能

#### 3.session基于缓存框架机制（redis、memcached等）

**要求：**redis、memcached是集群的，数据一致性。

​	**①粘性session处理**

**原理：**用户访问时，首先tomcat服务器创建并存放session（依旧是将用户锁定到某一服务器），然后将session复制一份到redis中做备份。（解决服务器挂了，用户得重新登录问题）

​			当某一个服务器挂掉后，先取服务器找（挂了），所以去redis中找到相应的session，然后将该session复制一份到存活的服务器中。（锁到新的服务器中，用户不用重新登录）

<img src="https://img-blog.csdn.net/20160301153058325" alt="这里写图片描述" style="zoom:50%;" />

**②非粘性session处理  spring-session**

**原理：**用户访问时，直接存放到主redis中，redis做主从复制，tomcat不保存sessioin，读写操作都直接访问主redis，当主redis崩了，就访问备份redis，不会影响到用户。

**优点：**将服务器压力转移到redis中，减轻服务器压力同时，容错率高，实现session实时响应。

**缺点：**redis压力大，需要较大的内存，否则会出现用户session从缓存中移除，而且需要redis定期清楚较久的session

<img src="https://img-blog.csdn.net/20160301153116755" alt="这里写图片描述" style="zoom:50%;" />

<img src="https://img-blog.csdn.net/20170419194544279?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYTYwNzgyODg1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img" style="zoom:80%;" />

#### 4.session持久化到数据库

**原理：**将session持久化到数据库

**优点：**服务器崩，数据库中仍然存在着数据

**缺点：**随着用户量增大，数据库压力不断增大



## Http2

**新特性**

**1.二进制分帧** 

http1.x是文本格式传输，http2二进制格式传输，并且被切分未过个帧发送，帧可以根据头部流标识重新组装。 

**2. 单一长连接**

同一个域名使用一个TCP连接,(http1.x 使用6-8个TCP连接，浏览器为减少消耗，进行的限制)，无论请求多少个资源，能减少握手带来的延时，减少创建多个TCP连接

带来的网络开销，提高吞吐量

**3. 多路复用**

http1.x相当于单车道，同一个连接上的请求串行执行

http2相当于多车道，同一个连接上的请求可以并行执行。由于请求被二进制分帧，每个帧都有流编号。同一个请求和响应的帧必须是有序的，不同的请求的帧可以

互相穿插。然后按照流编号重组。 

**4.头部压缩** 

用HPACK压缩头部，使用首部表来进行首部字段存储，只有当首部表中的数据变更或为发送过时，才会发送http头部字段。

首部表分为静态表和动态表，静态表包含常用字段，动态表包含自定义字段等非常用字段，当新增或改变字段时，会增加或修改动态表中的数据。 

**5.服务端推送** 

客户端请求资源X,服务端判断客户端还需要别的资源，可以主动推送这些资源。客户端需要显式允许服务器启用推送功能。并且，客户端可以发送一个RST_STREAM帧来中断推送流，推送受同源策略限制 

例如，请求index.html页面时，服务器同时将index.js和index.css push给浏览器，当浏览器解析html到请求index.css和index.js时，可以直接从缓存中读取

### 头部压缩

http请求和响应都是由【状态行、请求/响应头部、消息主题】三部分组成的。 一般而言，**消息主体都会经过gzip压缩**，或者**本身传输的就是压缩过后的二进制文件**（如图片、音频等），但是**状态行和头部多是没有经过任何压缩，而是直接以纯文本的方式进行传输的。**

请求头UserAgent、Cookie变动比较小，可以通过对请求头压缩减少浪费。

采用哈夫曼编码来压缩整数和字符串

Http2在浏览器和服务器之间

- 维护一份相同的静态字典（Static Table），包含常见的头部名称，以及特别常见的头部名称与值的组合；
- 维护一份相同的动态字典（Dynamic Table），可以动态地添加内容；

静态字典的作用有两个：1）对于完全匹配的头部键值对，例如 `:method: GET`，可以直接使用一个字符  `1` 表示；2）对于头部名称可以匹配的键值对，例如 `cookie: xxxxxxx`，可以将名称使用一个字符表示。

动态字典：浏览器/服务器 可以动态的将 `cookie: xxxxxxx` 添加到字典用一个字符代替。



### Ping用的是什么协议

**网络层协议：ICMP**，是TCP-IP的子协议，用于IP主机、路由器之间传递控制消息。

**功能**

1.确认IP包是否成功到达目标地址

2.通知在发送过程中IP包被丢弃的原因

**注意**

ICMP基于IP协议，辅助IP协议，但是在 网络层 传输。

#### **ICMP报文格式**

ICMP内容放在IP数据包的数据部分。

当IP报头中的协议字段位**1**时，表明是ICMP报文。

**包括 差错报文 询问报文**



![img](https://images2018.cnblogs.com/blog/806469/201803/806469-20180306123940403-1730998630.png)

**ICMP实现Ping命令**

![img](https://images2018.cnblogs.com/blog/806469/201803/806469-20180306124106517-1608215708.png)

**1.向目标服务器发送请求**

发送请求报文 **类型8 代码0** 并且追加 **标识符 序号 字段**（这两个字段填入任意值）。

对于 **标识符** 同一个Ping命令填入相同的值表明是同一个Ping。

对于 **序号** 同一个Ping命令每送出一个报文 值+1。

2.**目标服务器返回响应**

返回响应报文 **类型0（表示成功） 代码0** **标识符** **序号**

3.**本机确认**

通过 **标识符 序号** 确认是否是本次Ping,通过 **类型** 确认Ping是否成功。



##### **ICMP差错报文**

对差错报文进行响应时，做特殊处理，不会生成另一份差错报文，防止出现死循环。

**1.目标不可达 类型3**

网络不可达，主机不可达，协议不可达，端口不可达，需要分片但DF比特已置为1，以及源路由失败等六种情况，其代码字段分别置为0至5。

**2.源抑制 类型4**

目标服务器 **控制流量**。

当路由器或主机由于**拥塞而丢弃数据报**时，就向源站发送源站抑制报文，使源站知道应当将数据报的发送速率放慢。

**3.超时报文 类型11**

代码0 表示传输超时，代码1 表示分段重组超时。

当路由器收到生存时间为零的数据报时，除丢弃该数据报外，还要向源站发送超时报文。

当目的站在预先规定的时间内不能收到一个数据报的全部数据报片时，就将已收到的数据报片都丢弃，并向源站发送时间超过报文。

**4.参数问题**

当路由器或目的主机收到的数据报的**首部中的字段的值不正确**时，就丢弃该数据报，并向源站发送参数问题报文。

**5.改变路由**

改变路由（重定向）**路由器**将**改变路由报文**发送给主机，让主机知道下次应将数据报发送给另外的路由器。



**收到什么报文不会发送差错报文的情况**

**1.ICMP差错报文**（防止死循环）

**2.作为链路层广播的数据报、目的地址为广播地址或多播地址的IP数据报**

（防止ICMP差错报文对广播分组响应所带来的广播风暴）。

**3.对特殊地址**，如 127.0.0.0或0.0.0.0

**这些规则都是为了 防止差错报文广播 带来的广播风暴**

**4.如果 IP数据过大导致分片，则只对第一个数据片发送差错报文**



##### ICMP询问报文

询问报文包括 **回送请求回答 时间戳请求回答 掩码地址请求回答 路由器询问通过**

**回送请求回答：**测试目标能否到达。

**时间戳请求回答：**当前系统向另一个系统查询当前时间。

优点是 提供 **毫秒级 **单位

请求端填写**发起时间**，然后发送报文。应答系统收到请求报文时填写**接收时间戳**，在发送应答时填写**发送时间戳**。大多数的实现是把后面两个字段都设成相同的值。

**路由器询问通过：**了解连接在本网络上的路由器是否正常工作

主机将路由器询问报文进行广播（或多播）。收到询问报文的一个或几个路由器就使用路由器通过报文广播其路由选择信息。

**掩码地址请求回答**

向**子网掩码服务器**得到某个接口的地址掩码。系统广播它的ICMP请求报文。ICMP报文中的标识符和序列号字段由发送端任意选择设定，这些值在应答中将被返回，这样，发送端就可以把应答与请求进行匹配。

**子网掩码：**判断两台计算机IP地址是否属于同一子网络

将两台计算机IP地址分别与子网掩码进行AND运算（获取对外的唯一地址），如果结果相同。说明处于同一个子网络上。

##### traceroute命令

与Ping并列，也是ICMP命令。

返回从主机 到 目标主机 之间经历多少 路由器

```
[root@localhost ~]# traceroute www.baidu.com
traceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets
 192.168.74.2 (192.168.74.2)  2.606 ms  2.771 ms  2.950 ms
 211.151.56.57 (211.151.56.57)  0.596 ms  0.598 ms  0.591 ms
 211.151.227.206 (211.151.227.206)  0.546 ms  0.544 ms  0.538 (61.148.156.138)  1.899 ms  1.951 ms
 * * *
 * * *
[root@localhost ~]#
```

每个记录是 **一跳** ，每跳 表示一个 **网关**。

每次探测 默认发送 三个数据包。

*** 表示 防火墙 封掉了 ICMP返回信息。

有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。

如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题。

![img](https://images2018.cnblogs.com/blog/806469/201803/806469-20180306124141264-1747233430.png)

### HTTP编解码

**http规范，header编解码方式为 iso-8859-1 无法显示中文**

**浏览器编码**

header url form 请求体

request.setCharacterEncoding设置编码

**服务端解码**

header url 请求体

通过浏览器设置的编码进行相应解码

**服务端编码**

header 请求体

response.setCharacterEncoding 请求体的编码格式

response.setContentType请求体和请求头的编码格式

**浏览器解码**

header 请求体

浏览器首先从返回头header中查找编码方案