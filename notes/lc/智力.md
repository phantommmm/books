#### random(5)->random(7)

```
public int random7(){
	int x=25;
	Random random=new Random();
	while(x>21){
	//[1,5]
		int random5=random.nextInt(5)+1;
	//[1,25]
		x=5*(random5-1)+random5;
	}
	//[1,21]
	return x%7+1;
}
```

### 海量数据

#### 海量数据日记，查找某日访问百度次数最多的IP

##### **分而治之+Hash**

1.IP地址最多有 2^32=4G.

2.**分而治之：**根据IP地址 Hash(IP)  分成1024个小文件中。每个文件最多包含4M个IP地址。

3.对每一个小文件，构建一个Hashmap，(IP,出现次数)，同时记录当前出现次数最多的IP。

4.对1024个小文件IP进行排序即可。

#### 100W数找出最大的100个数

创建一个容量100的最小堆。复杂度O（100W*lg100）

#### 这100个数都是0-100之间

##### 哈希结构

创建一个容量为100的hashmap存储。复杂度O（1）

#### 100亿个数找出最大100个数

##### 分而治之

1.100亿个数据hash分区成1000个大区，每个区1000万数据。

2.每个大区细分成100个小区，总共有1000*100=10万个分区。

3.计算每个小区最大的100个数。

4.合并小区，找出每个大区最大的100个数。

5.合并大区，找出最终的100个数。

#### 这100亿个数很多重复的

##### 哈希结构+分而治之

首先用Hash结构除去重复的数，再分治。

#### 100亿个数找只出现一次的数

##### 分而治之+bitmap

bitmap：用两个bit表示出现次数

00未出现，01出现1次，10出现多次 11舍弃。

先分成多个文件，对每个文件进行bitmap存储，依次判断每个文件，出现01的就是出现一次的数。

#### 100亿个数求中位数，内存512M

**第50个亿数不一定是中位数，因为有重复的数**

一个无符号整数大小为4B，范围0~2^32-1（40亿）

512M可以存储2^(9+10+10)约为5亿个数。

1.把无符号整数的范围**0~40亿**划分为每10个数一个区间，也就有**4亿个区间**，划分后第一个区间0~9，第二个区间10~19，......在内存中使用**4亿个数表示**来保存100亿个数中落在每个区间的整数个数。

2.此时内存中还可以存放1亿个数，分**100次**把**100亿**个数加载到内存，每次加载1亿个，统计每个区间的整数个数。（**1亿个数统计每个区间的个数**）

3.然后从最小区间向最大区间拥有的个数开始累加，当累加的数达到50亿时，记住这个区间**起点位置**和**终点位置**（终点 - 起点 + 1 = 10）和**没有加这个区间统计个数时的整数个数**。

4.接着对区间的每个数设置一个桶（这里总共为10个桶），用来统计每个数的元素个数。

5.接着对100亿个数分**20批次**进行遍历，每次加载到内存**5亿**个数。

统计完成之后就可以知道落到区间内的每个元素个数，接着对区间的统计个数进行累加，当这个累加值加上（2）中保存的没有加上该区间的整数个数等于50亿时，该数对应的索引就位中位数。

**总结**

整个过程需要遍历100亿个数两次。

第一次确定第50亿个数所落在的索引区间。

第二次确定第50亿个数所落在的索引。区间大小是一个可以优化的值，优化之后可以使得I/O的次数最少。

### 大数据常用方法