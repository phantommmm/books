# 操作系统

### 进程的三种基本状态 

就绪状态：当进程已分配到除CPU以外的所有必要的资源，只要获得处理机便可立即执行，这时的进程状态称为就绪状态。 

执行状态：当进程已获得CPU，其程序正在被CPU调度执行，此时的进程状态称为执行状态。 

阻塞状态：正在执行的进程，由于等待某个事件发生而无法执行时，便放弃CPU而处于阻塞状态。例如，等待I/O完成、申请缓冲区不能满足、等待信件(信号)等。

![img](https://s1.ax1x.com/2018/11/27/FE8Sfg.png)

### 进程状态间的切换 

(1) 就绪→执行
 处于就绪状态的进程，当进程调度程序为之分配了处理机后，该进程便由就绪状态转变成执行状态。 
(2) 执行→就绪
 处于执行状态的进程在其执行过程中，因分配给它的一个时间片已用完而不得不让出处理机，于是进程从执行状态转变成就绪状态。 
(3) 执行→阻塞
 正在执行的进程因等待某种事件发生而无法继续执行时，便从执行状态变成阻塞状态。 
(4) 阻塞→就绪
 处于阻塞状态的进程，若其等待的事件已经发生，于是进程由阻塞状态转变为就绪状态。



### 用户态和内核态

`内核态` 拥有0权限级别，可以执行任何cpu指令，也可以引用任何内存地址，包括外围设备, 例如硬盘, 网卡，权限等级最高。

`用户态`  应用程序运行的状态， 只能受限的访问内存，且不允许访问外围设备

**用户态和内核态的切换**

当运行用户程序时，大部分时间是运行在用户态。

当需要内核态的操作或资源时，例如从硬盘读取数据, 或者从键盘获取输入等，切换到内核态。

**1.**系统调用：如read(),write()访问系统资源。系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现

2.异常：当cpu在执行运行在用户态下的程序时，发生了一些没有预知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关进程中，也就是切换到了内核态，如缺页异常。

3.外围设备的中断：当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令而转到与中断信号对应的处理程序去执行，如果前面执行的指令时用户态下的程序，那么转换的过程自然就会是 由用户态到内核态的切换。

如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后边的操作等。

**怎么切换？**

若中断时，进程在执行用户态的代码，该中断会引起CPU特权级从**3级到0级**的切换，此时CPU会进行**堆栈的切换**，CPU会从当前任务的TSS中取到新堆栈的段选择符和偏移值；CPU首先会把**原用户态的堆栈指针ss和esp压入内核态堆栈**，随后把标志寄存器eflags的内容和此次中断的返回位置cs，eip压入内核态堆栈。当中断处理函数结束后，将**恢复内核栈中的数据，并继续处理被中断的进程**。

若中断时，进程正在执行内核态的代码，则不需要堆栈的切换，CPU仅把eflags的内容和此次中断的返回位置cs，eip压入内核态堆栈，然后执行中断服务程序。

![img](https://pic2.zhimg.com/80/v2-52e720df015debf52d090c133740c610_1440w.jpg?source=1940ef5c)

**为什么两者切换耗时**

linux下每个进程的栈有两个，一个是用户态栈，一个是内核态栈。在需要从用户态栈切换到内核的时候，需要进行执行栈的转换，保存用户态的状态，包括寄存器状态，然后执行内核态操作，操作完成后要恢复现场，切换到用户态，这个过程是耗时的。

**过程**

1、保存 CPU 寄存器里原来用户态的指令位
2、为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。
3、跳转到内核态运行内核任务。
4、当系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。

所以，**一次系统调用的过程，其实是发生了两次 CPU 上下文切换**。（用户态-内核态-用户态），系统调用过程一直在一个进程中完成。

### 为什么设置内核态和用户态

由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络, CPU划分出两个权限等级 -- 用户态和内核态。



**串行：**多个任务执行，一个执行完再执行另外一个。

**并发(concurrency)**

多个线程在单个核心运行，同一时间一个线程运行，系统不停切换线程，看起来像同时运行，实际上是线程不停切换。

即一个指令 和另一个指令交错执行，操作系统实现这种交错执行的机制称为：上下文切换。

上下文是指操作系统保持跟踪进程或线程运行所需的所有状态信息，如寄存器文件的当前值、主存内容等

**并行（parallelism）**

每个线程分配给独立的核心，线程同时运行。

**总结**

1、单CPU中进程只能是并发，多CPU计算机中进程可以并行。
2、单CPU单核中线程只能并发，单CPU多核中线程可以并行。
3、无论是并发还是并行，使用者来看，看到的是多进程，多线程。

**举例：单CPU4核 可以并行4个线程**



### **进程、线程、协程**

**为什么有进程？**

是在多个程序系统出现后，为了清晰地刻画[动态系统](https://baike.baidu.com/item/动态系统)的内在规律，**有效管理和调度**进入[计算机系统](https://baike.baidu.com/item/计算机系统)[主存储器](https://baike.baidu.com/item/主存储器)运行的**程序**。

**进程：**进程指正在运行的程序的实例。确切的来说，当一个程序进入内存运行，即变成一个进程，进程是处于运行过程中的程序，并且具有一定独立功能。进程是一个具有一定独立功能的程序关于某个数据集合的一次运行活动。

**一个进程里包含什么？**

cpu执行的程序代码、程序处理的数据、程序计数器的值，指示下一条将运行的指令
寄存器的当前值，堆，栈、系统资源(如打开的文件)
总之，进程包含了正在运行的一个程序的所有状态信息。

**进程与程序区别**

程序是产生进程的基础，程序的每次运行构成不同的进程
进程是程序功能的体现，通过多次执行，一个程序可对应多个进程；通过调用关系，一个进程可包括多个程序。

进程是动态的，程序是静态的：程序是有序代码的集合；进程是程序的执行，进程有核心态/用户态
进程是暂时的，程序是永久的：进程是一个状态变化的过程，程序可长久保存
进程与程序的组成不同：进程的组成包括**程序，数据和进程控制块**(进程的状态信息)

**进程控制块PCB**

操作系统为每个进程都维护了一个PCB，用来保存与该进程有关的各种状态信息，PCB是进程存在的唯一标志。

主要包含以下内容

- [程序计数器](https://baike.baidu.com/item/程序计数器)：接着要运行的指令地址。
- 进程状态：可以是new、ready、running、waiting或 blocked等。
- [CPU](https://baike.baidu.com/item/CPU)[暂存器](https://baike.baidu.com/item/暂存器)：如[累加器](https://baike.baidu.com/item/累加器)、索引暂存器（Index register）、[堆栈指针](https://baike.baidu.com/item/堆栈指针)以及一般用途暂存器、状况代码等，主要用途在于中断时暂时存储数据，以便稍后继续利用；其数量及类因电脑架构有所差异。
- CPU排班法：优先级、排班队列等指针以及其他参数。
- [存储器](https://baike.baidu.com/item/存储器)管理：如标签页表等。
- 会计信息：如CPU与实际时间之使用数量、时限、账号、工作或进程号码。
- 输入输出状态：配置进程使用[I/O](https://baike.baidu.com/item/I%2FO)设备，如[磁带机](https://baike.baidu.com/item/磁带机)



**线程：**线程是进程中的一个执行单元，负责当前进程中程序的执行，一个进程中至少有一个线程。一个进程中是可以有多个线程的



**区别**

1、进程是**操作系统**资源分配的基本单位，而线程是**CPU**任务调度和执行的基本单位

2、程序运行先创建进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段。线程是共享进程中的数据的，使用相同的地址空间，因此CPU切换/创建一个线程的花费远比进程要小很多。

3、线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要以管道pipe或者消息队列进行。

4、但是多进程程序更健壮，多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间。

5、进程拥有完整的资源平台，而线程只占有必须的资源，如寄存器，栈、线程本地存储。



**线程有堆吗**

与线程“绑定”的是栈，用于存储局部变量。每一个线程建立的时候，都会新建一个默认栈与之配合。堆则是通常与进程相关，用于存储全局性的变量，进程建立的时候，会建立默认堆。于是，每一个线程都有自己的栈，然后访问共同的堆。

堆：是大家共有的空间，分全局堆和局部堆。全局堆就是所有没有分配的空间，局部堆就是用户分配的空间。堆在操作系统对进程初始化的时候分配，运行过程中也可以向系统要额外的堆，但是记得用完了要还给操作系统，要不然就是内存泄漏。

栈：是个线程独有的，保存其运行状态和局部自动变量的。栈在线程开始的时候初始化，每个线程的栈互相独立，因此，栈是线程安全的。操作系统在切换线程的时候会自动的切换栈，就是切换　ＳＳ／ＥＳＰ寄存器。

### 线程共享、独立资源

**线程共享的资源包括：**

 进程代码段、公有数据（利用这些数据，线程很容易实现相互之间的通讯）、进程的所拥有资源。

**线程独立的资源包括：**

（1）线程ID：每个线程都有自己唯一的ID，用于区分不同的线程。

（2）寄存器组的值：当线程切换时，必须将原有的线程的寄存器集合的状态保存，以便重新切换时得以恢复。

（3）线程的栈：栈是保证线程独立运行所必须的。

（4）错误返回码：由于同一个进程中有很多个线程同时运行，可能某个线程进行系统调用后设置了error值，而在该线程还没有处理这个错误，另外一个线程就在此时被调度器投入运行，这样错误值就有可能被修改。所以，不同的线程应该拥有自己的错误返回码变量。

（5）线程优先级：线程调度的次序（并不是优先级大的一定会先执行，优先级大只是最先执行的机会大）。



**协程： 一种比线程更加轻量级的存在**

一个线程可以含有多个协程。

协程不是被操作系统内核所管理，而完全由程序所控制（用户态执行）

**1.** 协程可以比作子程序，但执行过程中，子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。协程之间的切换不需要涉及任何系统调用或任何阻塞调用

**2.** 协程只在一个线程中执行，是子程序之间的切换，发生在用户态上。而且，线程的阻塞状态是由操作系统内核来完成，发生在内核态上，因此协程相比线程节省线程创建和切换的开销

**3.** 协程中不存在同时写变量冲突，因此，也就不需要用来守卫关键区块的同步性原语，比如互斥锁、信号量等，并且不需要来自操作系统的支持。

协程适用于IO阻塞且需要大量并发的场景，当发生IO阻塞，由协程的调度器进行调度，通过将数据流yield掉，并且记录当前栈上的数据，阻塞完后立刻再通过线程恢复栈，并把阻塞的结果放到这个线程上去运行。

**优势**

**1.** 效率高于多线程，因为协程无需进行线程切换，所以没有线程切换的开销，和多线程相比，数量越大，协程优势越大。

**2.** 无需锁机制，因为只有同一线程，不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。

**那么如何利用多核CPU？**

**多进程 + 协程**

**示例**

JAVA原生语法没有实现协程。

python **yield** 关键字，当协程执行到yield关键字时，会暂停在哪一行，等到主线程调用send方法发送了数据，协程才会街道数据继续执行。

### 进程内存结构

- 代码区：存放CPU执行的机器指令，代码区是可共享，并且是只读的。
- 数据区：存放已初始化的全局变量、静态变量（全局和局部）、常量数据。
- BBS区：存放的是未初始化的全局变量和静态变量。
- 栈区：由编译器自动分配释放，存放函数的参数值、返回值和局部变量，在程序运行过程中实时分配和释放，栈区由操作系统自动管理，无须程序员手动管理。
- 堆区：堆是由malloc()函数分配的内存块，使用free()函数来释放内存，堆的申请释放工作由程序员控制，容易产生内存泄漏。

![img](https://img-blog.csdn.net/20170906083952532?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXcxMjQ1NzEyNQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

### 创建线程需要什么资源

**1.** 为线程栈分配并初始化内存

**2.** 需要对操作系统进行系统调用，创建本地线程

**3.** 需要创建、初始化描述符并将他添加到JVM内部数据结构种

### 为什么不建议创建过多线程

主要涉及 **cpu时间** 问题，创建过多的线程，会在线程切换的时候消耗CPU工作时间，当线程数达到一个极限值以后CPU就会什么都不用做了，只是在切换每一个线程，但是每个线程都没有实际的执行

多线程处理线程同步时可能会使用很多的内核对象来完成同步，这种情况也会消耗内核资源。

### 什么时候适合用多线程什么时候适合用多进程？ 

 1、需要频繁创建销毁的优先使用线程；因为创建和销毁一个进程代价是很大的。
 2、线程的切换速度快，所以在需要大量计算，切换频繁时用线程，还有耗时的操作使用线程可提高应用程序的响应；
 3、因为对CPU系统的效率使用上线程更占优，所以可能要发展到多机分布的用进程，多核分布用线程；
 4、需要更稳定安全时，适合选择进程；需要速度时，选择线程更好。

![图片说明](https://uploadfiles.nowcoder.com/images/20191025/659657122_1572016705907_78D7BE079F0C2406A17C52C294D40B7A)



### 上下文

**上下文** 是指某一时间点 CPU 寄存器和程序计数器的内容。

**寄存器** 是 CPU 内部的数量较少但是速度很快的内存（与之对应的是 CPU 外部相对较慢的 RAM 主内存）。**寄存器通过对常用值（通常是运算的中间值）的快速访问来提高计算机程序运行的速度**。

**程序计数器是一个专用的寄存器**，用于表明指令序列中 CPU 正在执行的位置，**存的值为正在执行的指令的位置或者下一个将要被执行的指令的位置**，具体依赖于特定的系统。

### CPU上下文切换

上下文切换就是把前一个任务的CPU上下文保存起来，然后加载新任务的上下文到这些指令寄存器(IR)和程序寄存器(PC)等寄存器中。这些被保存下来的上下文会存储在操作系统的内核中，等待任务重新调度执行时再次加载进来，这样就能保证任务的原来状态不受影响，让任务看起来是连续运行的。

**CPU的上下文切换又分为进程上下文切换，线程上下文切换以及中断上下文切换。**

### 进程切换和线程切换

进程切换是指一个进程让出处理机，由另一个进程占用处理机的过程。

1.对原来运行进程各种数据的保存，包括栈、全局变量等
2.对新的进程各种数据的恢复
(如:程序计数器、程序状态字、各种数据寄存器等处理机现场信息，这些信息一般保存在进程控制块)

1. 切换虚拟地址空间、页目录
2. 切换CPU上下文
3. 切换内核栈

**TLB**

页表查找是一个很慢的过程，因此通常使用Cache来缓存常用的地址映射，这样可以加速页表查找，这个cache就是TLB.当进程切换后页表也要进行切换，页表切换后TLB就失效了，cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢

**线程上下文切换**

线程的上下文切换需要保存自己的一些数据，比如栈，寄存器等数据

1. 切换CPU上下文
2. 切换内核栈

**区别**

进程切换涉及到虚拟地址空间的切换而线程切换则不会。因为每个进程都有自己的虚拟地址空间，而线程是共享所在进程的虚拟地址空间的，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换。

### linux进程有7种状态

- R运行状态（Running）：处于运行状态的进程并不带表一定就正在被CPU调度运行，它包括了正在被CPU运行的进程和可以被CPU调度运行的程序，也就是说改状态包含了三状态模型中的就绪态和运行态。
- S睡眠状态（Sleeping）：处于改状态的进程表示该进程正在等待某时间的完成，通常也称为可中断睡眠状态，该状态属于三状态模型中的阻塞态。
- D磁盘休眠状态（disk sleep）：该状态也叫做不可中断睡眠状态，处于该状态的进程通常都在等待I/O操作的结束，该状态也属于三状态模型中的阻塞态。
- T停止状态（stopped）：我们可以通过向进程发送SIGSTOP信号让目标进程处于停止状态，通过向处于停止状态的进程发送SIGCON信号让目标进程继续运行，该状态也属于三状态模型中的阻塞态。
- t追踪停止状态（tracing stop）：
- X死亡状态（dead）：该状态只是一个返回状态，不会在任务列表中见到，该状态属于退出状态。
- Z僵尸状态（zombie）：当一个进程退出，但它的父进程并没有去收回该进程的信息时，该进程所处的状态叫做僵尸状态，该状态属于退出状态。

![FEaoQS.png](https://s1.ax1x.com/2018/11/27/FEaoQS.png)



#### 线程通信方式

**共享数据**

**使用volatile关键字**，当多个线程同时监听一个变量，当这个变量发生改变时，线程能够知道最新的变化并执行相应处理

**使用Object.wait notify方法，共享锁资源**

#### 线程安全实现方式

1，用final 修饰，不能修改的变量就是最安全的

2，用原子类或者线程安全的类，Atomic，concurrenthashmap

3，Synchronized锁

4，volatile CAS

5，采用线程封闭，localthread



#### 进程通信（IPC）

不同进程间交换数据必须通过内核,在内核中开辟一块缓冲区，进程1把数据从用户空间 拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信。

**目的：**  

-    数据传输：一个进程需要将它的数据发送给另一个进程，发送的数据量在一个字节到几兆字节之间。    
-    共享数据：多个进程想要操作共享数据，一个进程对共享数据的修改，别的进程应该立刻看到。通知事件：一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程）。    
-    资源共享：多个进程之间共享同样的资源。为了作到这一点，需要内核提供锁和同步机制。    
-    进程控制：有些进程希望完全控制另一个进程的执行（如Debug进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。

##### Socket套接字

**套接字属性**

**int socket( int domain, int type, int ptotocol);**

`domain`  通信域：unix域，IPv4,IPv6等

`type`   通信类型：Stream流式（TCP） 数据报式（UDP）

`protocol` 协议 TCP/UDP 根据前面两个参数 自动选择合适的协议



**Unix套接字与因特网套接字（tcp udp）**

domain 设置为AF_UNIX实现unxi通信。

unix套接口可以实现进程间传递**描述字**，如文件、管道、有名管道及套接口等。

unix套接字只能用于**同一个计算机**的进程间进行通信，速度是tcp套接口速度2倍，因为unix域套接字仅仅进行**数据复制**，不会执行在网络协议栈中需要处理的添加、删除报文头、计算校验和、计算报文顺序等复杂操作，因而在单机的进程间通信中，更加推荐使用Unix域套接字。

unix通信流程和tcp相似，只是指定通信域时不同。



**服务器端**

 首先服务器应用程序用系统调用`socket`来创建一个套接字，它是系统分配给该服务器进程的类似文件描述符的资源，它不能与其他的进程共享。

  接下来，服务器进程会给套接字起个名字，我们使用系统调用`bind`来给套接字命名。然后服务器进程就开始等待客户连接到这个套接字。

  然后，系统调用`listen`来创建一个队列并将其用于存放来自客户的进入连接。

  最后，服务器通过系统调用`accept`来接受客户的连接。它会创建一个与原有的命名套接不同的新套接字，这个套接字只用于与这个特定客户端进行通信，而命名套接字（即原先的套接字）则被保留下来继续处理来自其他客户的连接。

**客户端**

 基于`socket`的客户端比服务器端简单，同样，客户应用程序首先调用`socket`来创建一个未命名的套接字，然后将服务器的命名套接字作为一个地址来调用`connect`与服务器建立连接。

  一旦连接建立，我们就可以像使用底层的文件描述符那样用套接字来实现双向数据的通信。



##### 管道（匿名管道）

**特点**

1.半双工（数据只能在一个方向上流动）单向通信，具有固定的读端和写端。

2.只能用于具有情缘关系的进程之间的通信（父子进程或兄弟进程之间）

3.它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

初始化 `int pipe(int pipefd[2]);`

调用pipe函数，在内核中开辟一块缓冲区用来进行进程间通信，这块**缓冲区**即为**管道**，包含一个**读端**和一个**写端**。

参数pipefd[2]一个指向读端一个指向写端，管道对于用户程序就是一个文件，可以通过read(pipefd [0])；或者write(pipefd [1])进行操作。

**管道通信步骤**

1.父进程创建管道，得到两个文件描述符指向管道的两端

![img](https://img-blog.csdn.net/20180428202630303?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2ODI5MDkx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

2.利用fork函数创建出子进程，则子进程也得到两个文件描述符指向同一管道

![img](https://img-blog.csdn.net/20180428202659963?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2ODI5MDkx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

3.父进程关闭读端（pipe[0]）,子进程关闭写端pipe[1]，则此时父进程可以往管道中进行写操作，子进程可以从管道中读，从而实现了通过管道的进程间通信。（一端关闭，一端打开实现进程间通信）

**说明**

因为管道通信是单向的，在上面的例子中我们是通过子进程写父进程来读，如果想要同时父进程写而子进程来读，就需要再打开另外的管道；

管道的读写端通过打开的**文件描述符**来传递,因此要通信的两个进程必须从它们的公共祖先那里继承管道的件描述符。 

**特殊情况**

1. 所有写端关闭了,而仍然有读端读数据,那么管道中剩余的数据都被读取后,再次read会返回0,就像读到文件末尾一样

2. 有写端还没关闭，也没有向管道中写数据,这时有读端读数据,那么管道中剩余的数据都被读取后,再次read会阻塞,直到管道中有数据可读了才读取数据并返回。

3. 所有读端都关闭了,这时有写端write,那么该进程会收到信号SIGPIPE,通常会导致进程异常终止。

4. 有读端没关闭,而持有管道读端的进程也没有从管道中读数据,这时有进程向管道写端写数据,那么在管道被写满时再write会阻塞,直到管道中有空位置了才写入数据并返回。

##### 命名管道FIFO

解决管道中只有血缘关系的进程才能进行通信。

提供一个**路径名**与之关联，以FIFO的文件形式存储于文件系统中。只要进程访问该路径，就能够通过FIFO相互通信。FIFO先进先出，第一个写入管道的数据被首先读出。

**FIFO创建**

`int mknod(const char *path,mode_t mod,dev_t dev);`

`int mkfifo(const char *path,mode_t mode);`

path为创建的命名管道的全路径名

mod为管道的模 指明存取权限

dev为设备值，取决于文件创建的种类

**命名管道**创建后是一个位于硬盘上的文件，需要调用open()将其打开，**管道**为内存上的特殊文件，无需打开。

![img](https://images2015.cnblogs.com/blog/323808/201603/323808-20160311094842257-893623615.png)



匿名管道和命名管道生命周期都是随着进程，即进程死亡，管道也死亡。

##### 消息队列

**既然有了管道为什么还要消息队列？**

（1）匿名管道和命名管道都是随进程的，意味着管道的生命周期是随进程的退出而退出的。

（2）管道传送数据时以无格式字节流的形式传送，给程序的开发带来不便。

（3）数据传送媒介的管道，其缓冲区大小受到较大的限制，即传递信息量有限。

**消息队列：** 内核地址空间中的内部链表，它允许一个或多个进程向它写消息，一个或多个进程从中读消息，消息可以顺序地发送到队列中，并以几种不同的方式从队列中获取，每个消息队列是由IPC标识符所唯一标识的。

消息队列与管道的不同在于：消息队列是基于消息的，而管道是基于字节流的，且消息队列的读取不一定是先入先出，而且如果你没有显示的删除它，那么在关机之前它一直存在。

**创建**

```
// 创建或打开消息队列：成功返回队列ID，失败返回-1
int msgget(key_t，key, int flag);
// 添加消息：成功返回0，失败返回-1
int msgsnd(int msqid, const void *ptr, size_t size, int flag);
// 读取消息：成功返回消息数据的长度，失败返回-1
int msgrcv(int msqid, void *ptr, size_t size, long  type,int flag);
// 控制消息队列：成功返回0，失败返回-1 cmd表明操作 包括删除
int msgctl(int msqid, int cmd, struct msqid_ds *buf);
```

**特点**

1.具有特定的格式，独立存放在内存中。

2.允许一个或多个进程向它写入或读取消息。

3.随机查询，可以按照消息的类型读取，不用遵循FIFO

具有更大的灵活性，消息具有类型，可以根据消息类型进行读取，不用遵循FIFO,可以在几个进程间复用，而不管这几个进程是否具有亲缘关系,生命周期随内核，生命力更强。

（1）消息队列可以独立于发送和接收数据的进程而存在，从而消除了在同步命名管道的打开和关闭可能产生的困难。

（2）可以通过发送消息可以避免命名管道的同步和阻塞问题，不需要由进程自己来提供同步方法。

（3）接受程序可以通过消息类型有选择的接收数据，而不像命名管道中的那样，只能默认的接受。

（4）双向通信，生命周期随内核。

消息队列克服了信号传递信息少,管道只能承载无格式字节流以及缓冲区大小受限等特点

因为[消息传送](https://baike.baidu.com/item/消息传送)的过程中要经过从[用户空间](https://baike.baidu.com/item/用户空间)到[内核空间](https://baike.baidu.com/item/内核空间)，再从内核空间到用户空间的拷贝，所以，大消息的传送其性能较差。另外，消息队列不支持广播，而且[内核](https://baike.baidu.com/item/内核)不知道消息的接收者。



##### 信号量

信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。

**特点**

1.用于进程间同步，若要在进程间传递数据需要结合共享内存。

2.信号量是一个整数，基于操作系统的PV操作，程序对信号量的操作都是原子操作。

3.每次对信号量的PV操作不仅限于对信号量值加1或减1，而且可以加减任意正整数。

4.支持信号量组。

**如果一个进程需要访问共享资源，操作如下：**

1.测试控制该资源的信号量。

2.若信号量大于0，则访问该资源，并将信号量-1。

3.若小于等于0，则进程进入休眠状态，直至值大于0，才被唤醒。

4.进程不再使用共享资源时，将信号量+1。

**创建**

```
// 创建或获取一个信号量组：若成功返回信号量集ID，失败返回-1
int semget(key_t key, int num_sems, int sem_flags); num_sems指定信号量数目 几乎总是为1
// 对信号量组进行操作，改变信号量的值：成功返回0，失败返回-1
int semop(int semid, struct sembuf semoparray[], size_t numops);  
// 控制信号量的相关信息
int semctl(int semid, int sem_num, int cmd, ...);
```

##### 共享内存

指多个进程共享一个给定的存储区，允许多个进程同时访问数据，在写入数据时另外一个进程可以立即获得最新数据，会造成同步问题。

**特点**

1.是最快的IPC，因为直接对内存进行存取。

2.通常是**信号量+共享内存**一起使用，信号量用于同步问题。

```
// 创建或获取一个共享内存：成功返回共享内存ID，失败返回-1
int shmget(key_t key, size_t size, int flag);
// 连接共享内存到当前进程的地址空间：成功返回指向共享内存的指针，失败返回-1
void *shmat(int shm_id, const void *addr, int flag);
// 断开与共享内存的连接：成功返回0，失败返回-1
int shmdt(void *addr); 
// 销毁共享内存的相关信息：成功返回0，失败返回-1
int shmctl(int shm_id, int cmd, struct shmid_ds *buf);
```

当一段共享内存被创建以后，它并不能被任何进程访问。必须使用`shmat`函数连接该共享内存到当前进程的地址空间，连接成功后把共享内存区对象映射到调用进程的地址空间，随后可像本地空间一样访问。

`shmdt`函数是用来断开`shmat`建立的连接的。注意，这并不是从系统中删除该共享内存，只是当前进程不能再访问该共享内存而已。

##### 五种通讯方式区别

1.管道：速度慢，容量有限，只有父子进程能通讯   

2.FIFO：任何进程间都能通讯，但速度慢   

3.消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题   

4.信号量：不能传递复杂消息，只能用来同步   

5.共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存

##### 文件锁

Linux内核支持的文件锁包括**劝告锁**和**强制锁**。

多个进程可以同时对一个文件加共享锁（读锁），而当有一个进程对文件加了排他锁（写锁）时，那么其它进程无权对该文件加任何锁，直到排他锁释放。

不论是使用劝告锁还是强制锁，都是同时使用共享锁和排写锁。

|                  | **是否满足请求** |        |
| :--------------- | :--------------: | ------ |
| **当前加上的锁** |      共享锁      | 排他锁 |
| 无               |        是        | 是     |
| 共享锁           |        是        | 否     |
| 排他锁           |        否        | 否     |

**劝告锁**

劝告锁是一种协同工作的锁。对于这一种锁来说，内核只提供**加锁**以及**检测文件是否已经加锁**的手段，但是内核并不参与锁的控制和协调。

也就是说，如果有进程不遵守“游戏规则”，不检查目标文件是否已经由别的进程加了锁就往其中写入数据，那么内核是不会加以阻拦的。因此，劝告锁并不能阻止进程对文件的访问，而只能依靠各个进程**自觉在访问文件之前检查该文件**是否已经被其他进程加锁来实现并发控制。进程需要事先对锁的状态做一个约定，并根据锁的当前状态和相互关系来确定其他进程是否能对文件执行指定的操作。从这点上来说，劝告锁的工作方式与使用信号量保护临界区的方式非常类似。

劝告锁可以对文件的任意一个部分进行加锁，也可以对整个文件进行加锁，甚至可以对文件将来增大的部分也进行加锁。由于进程可以选择对文件的某个部分进行加锁，所以**一个进程**可以获得**关于某个文件不同部分的多个锁**。

**强制锁**

每当有系统调用 open()、read() 以及write() 发生的时候，内核都要检查并确保这些系统调用不会违反在所访问文件上加的强制锁约束。有进程不遵守游戏规则，硬要往加了锁的文件中写入内容，内核就会加以阻拦。

如果一个文件已经被加上了共享锁，那么其他进程再对这个文件进行写操作就会被内核阻止；

如果一个文件已经被加上了排他锁，那么其他进程再对这个文件进行读取或者写操作就会被内核阻止。

如果其他进程试图访问一个已经加有强制锁的文件，进程行为取决于所执行的操作模式和文件锁的类型，如下：

| 当前锁类型 |    阻塞读    | 阻塞写 |   非阻塞读   | 非阻塞写 |
| :--------: | :----------: | :----: | :----------: | :------: |
|    读锁    | 正常读取数据 |  阻塞  | 正常读取数据 |  EAGAIN  |
|    写锁    |     阻塞     |  阻塞  |    EAGAIN    |  EAGAIN  |

**系统调用**

**int flock(int fd,int operation) 对整个文件加锁**

fd标识文件描述符，operation指定加锁类型。通常情况下flock()获取锁失败会阻塞进程，可以将 LOCK_NB 和 LOCK_SH 或者 LOCK_EX 联合使用，就不会阻塞进程。

**int fcntl(int fd,int cmd,struct flock *lock) 对记录进行加锁**

fd标识文件描述符，cmd指定要进行的锁操作,flock指定锁类型等。

#### 用户进程缓冲区

每个用户进程都维护一个用户进程缓冲区

程序在读取文件时，会先申请一块内存数组，称为buffer，然后每次调用read，读取设定字节长度的数据，写入buffer。（用较小的次数填满buffer）。之后的程序都是从buffer中获取数据，当buffer使用完后，在进行下一次调用，填充buffer。

**目的是为了减少系统调用次数，从而降低操作系统在用户态与内核态切换所耗费的时间和资源**

#### 进程调度时机

1. 主动放弃：（1）进程正常终止 （2）运行过程中发送异常而终止（3）主动阻塞（如 提出I/O请求后阻塞、调用阻塞原语sleep将自己阻塞进入睡眠状态）
2. 被动放弃：（1）分给进程的时间片用完 （2）有更紧急的事情需要处理（如I、O中断）（3）有更高级的进程进入就绪队列

#### 不能进行进程调度情况

1.在处理中断的过程中。中断处理过程复杂，与硬件密切相关，很难做到在中断处理过程中进行进程切换。
2.进程在操作系统内核程序临界区中。
3.在原子操作过程中(原语)。原子操作不可中断，要一气呵成(如之前讲过的修改PCB中进程状态标志，并把PCB放到相应队列)



#### 进程调度策略（CPU调度算法）

进程调度指的是从就绪队列中选中一个要运行的进程

**先进先出（FIFO）**

按照进程进入就绪队列的先后顺序，运行进程，为之分配处理机，使之投入运行。

**时间片轮转（RR）**

**理解：**为了解决排在前面的进程消耗大量CPU（时间）而后面只需一点点CPU（进程）却要等待很久的问题。即一点一点使用。

将CPU的处理时间划分成一个个的时间片。

根据先来先服务的原则，将需要执行的所有进程按照到达时间的大小排成一个升序的序列，每次都给一个进程同样大小的时间片，在这个时间片内如果进程执行结束了，那么把进程从进程队列中删去，如果进程没有结束，那么把该进程停止然后改为等待状态，放到进程队列的尾部，直到所有的进程都已执行完毕。

**时间片大小选择**

时间片过小，进程切换频繁，造成CPU资源的浪费。

时间片过大，则退化成FIFO策略。

**短作业优先**

从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。在同时到达的进程中优先执行最短的进程。

是会根据之前的执行历史有一个统计平均运行时间记录在头部信息去判断进程是否短作业

**最高优先级**

进程调度每次将处理机分配给具有最高优先级的就绪进程。最高优先级算法可与不同的CPU方式结合形成可抢占式最高优先级算法和不可抢占式最高优先级算法。

1) 非抢占式优先权算法

在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。

2) 抢占式优先权调度算法

在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。因此，在采用这种调度算法时，是每当系统中出现一个新的就绪进程i 时，就将其优先权Pi与正在执行的进程j 的优先权Pj进行比较。如果Pi≤Pj，原进程Pj便继续执行；但如果是Pi>Pj，则立即停止Pj的执行，做进程切换，使i 进程投入执行。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。

**高响应比优先**

从就绪队列中选出响应比最高的作业投入运行。

`响应比=（等待时间+需要执行的时间）/需要执行的时间`

当作业的等待时间相同时，则要求服务时间越短，其响应比越高，有利于短作业。

当要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，其响应比越高，因而它实现的是先来先服务。

对于长作业，作业的响应比可以随等待时间的增加而提高，当其等待时间足够长时，其响应比便可升到很高，从而也可获得处理机。克服了饥饿状态，兼顾了长作业。

#### 内存分配算法

![img](https://img-blog.csdnimg.cn/20190514181700962.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTkyODU0NA==,size_16,color_FFFFFF,t_70)

`首次适应算法（FirstFit）`：使用该算法进行内存分配时，从空闲分区链首开始查找，直至找到一个能满足其大小要求的空闲分区为止。然后再按照作业的大小，从该分区中划出一块内存分配给请求者，余下的空闲分区仍留在空闲分区链中。

该算法倾向于使用内存中低地址部分的空闲分区，在高地址部分的空闲分区很少被利用，从而保留了高地址部分的大空闲区。显然为以后到达的大作业分配大的内存空间创造了条件。

缺点在于低址部分不断被划分，留下许多难以利用、很小的空闲区,过于碎片化，而每次查找又都从低址部分开始，这无疑会增加查找的开销。

`最佳适应算法（BestFit)`： 该算法总是把既能满足要求，又是最小的空闲分区分配给作业。为了加速查找，该算法要求将所有的空闲区按其大小排序后，以递增顺序形成一个空白链。这样每次找到的第一个满足要求的空闲区，必然是最优的。

因为每次分配后剩余的空间一定是最小的，在存储器中将留下许多难以利用的小空闲区。同时每次分配后必须重新排序，这也带来了一定的开销

`最差适应算法（WorstFit)`：该算法按大小递减的顺序形成空闲区链，分配时直接从空闲区链的第一个空闲分区中分配（不能满足需要则不分配）。

在大空闲区中放入程序后，剩下的空闲区常常也很大，于是还能装下一个较大的新程序。最坏适应算法与最佳适应算法的排序正好相反，它的队列指针总是指向最大的空闲区，在进行分配时，总是从最大的空闲区开始查寻。
但保留大的空闲区的可能性减小了，而且空闲区回收也和最佳适应算法一样复杂。

#### 页面调度算法

`最佳置换算法（OPT）` ：每次选择未来长时间不被访问的或者以后永不使用的页面进行淘汰。 最佳置换算法是一种理想化算法，具有较好的性能，但是实际上无法实现 （无法预知一个进程中的若干页面哪一个最长时间不被访问）

`先进先出页面置换算法（FIFO）` ：淘汰最先进入内存的页面，即选择在页面待的时间最长的页面淘汰。 

`最近最久未使用置换算法（LRU）` 实现原理：选择最近且最久未被使用的页面进行淘汰

#### IO多路复用

**单个线程通过记录跟踪每一个Sock(I/O流)的状态(对应空管塔里面的Fight progress strip槽)来同时管理多个I/O流**. 主要是为了尽量多的提高服务器的吞吐能力。



##### select(最早) O（n）

通过设置或者检查存放fd标志位的数据结构来进行下一步处理

它仅仅知道了，有Socket I/O事件（操作）发生了，却并不知道是哪几个流（什么操作）（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。

**原理：**内核轮询查询已注册的socket列表中，哪些连接就绪（有需求发生）。

​		即每次 select/poll 用户态将所有的socket连接拷贝到内核态，然后进行轮询。

**问题**

 1.单个进程可监视的fd数量被限制，即能监听端口（连接）的大小有限。32位 1024个 64位 2048个

 2.对socket进行扫描时是线性遍历扫描，即采用轮询的方法，效率较低，浪费cpu：    
 3.需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大
 4.select 不是线程安全的，如果你把一个socket加入到select, 然后突然另外一个线程发现，尼玛，这个socket不用，要收回。对不起，这个select 不支持的，如果你丧心病狂的竟然关掉这个sock, select的标准行为是。。呃。。不可预测的， 这个可是写在文档中的哦.
 5.每次调用select需要把fd集合从用户态拷贝到内核态，当fd很大时，开销大。

 **fd集合** ：可以理解为即一个客户端需要的操作集合（文件描述符集合）



##### poll O(n)

本质上和select没有区别，只是去掉了 **连接个数限制** 原因是基于链表存储，任然是线程不安全的，这就意味着，不管服务器有多强悍，你也只能在一个线程里面处理一组I/O流。你当然可以那多进程来配合了，不过然后你就有了多进程的各种问题。



##### epoll O(1)

**原理：** 维护一个简易的文件系统（创建一个(epoll对象)eventpoll），包含一颗红黑树（每个节点都是一个socket，注册了回调函数，当产生事件（有需求时）放入链表中），一张准备就绪句柄双向链表（存放的是红黑树节点上产生事件（有需求）的节点），少量的内核cache。

<img src="https://img-blog.csdnimg.cn/20190627183709895.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODEwMjc3MQ==,size_16,color_FFFFFF,t_70" alt="img" style="zoom:67%;" />

把 select/poll 分成3步

```
int epoll_create(int size);  //建立一个epoll对象
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); 
//epoll对象中添加套接字（连接）
int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout);
//收集发生事件的连接
```

`epoll_create` 内核在epoll文件系统里建了个file结点，在内核cache里建了个红黑树用于存储socket外，还会再建立一个rdllist双向链表，用于存储准备就绪的事件。

`epoll_ctl` 增加socket句柄，则检查在红黑树中是否存在，存在立即返回，不存在则添加到树干上，**关键是然后向内核（网卡）注册回调函数**，用于当中断事件来临时向准备就绪链表中插入数据，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。

当一个socket上有数据到了，内核在把网卡上的数据copy到内核中后就来把socket插入到准备就绪链表里了，唤醒等待队列中的进程进入运行状态。

`epoll_wait` 立刻返回准备就绪链表里的数据即可。

所有添加到epoll中的事件都会与设备(如网卡)驱动程序建立回调关系，也就是说相应事件的发生时会调用这里的回调方法。这个回调方法在内核中叫做**ep_poll_callback**，它会把这样的事件放到上面的rdllist双向链表中。

**当fd状态改变 （不可读->可读 不可写->可写）触发fd上的回调函数ep_poll_callback被调用**



**触发模式**

`epolllt(默认):` LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作
只要有数据没有被获取，内核就不断通知你，因此不用担心事件丢失的情况。

`epollet(高速):` 如果一次读写数据没有完全读写完，会有老数据残留，直到下次再有数据流入之前才会再提示了，无论fd中是否还有数据可读。
所以在ET模式下，read一个fd的时候一定要把它的buffer读光，也就是说一直读到read的返回值小于请求值，或者遇到EAGAIN错误

**为什么要有epollet模式?**

如果采用EPOLLLT模式的话，系统中一旦有大量你不需要关心读写的就绪文件描述符，它们每次调用epoll_wait都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率.
而采用EPOLLET这种边沿触发模式的话，当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写.
如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你！！！
这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符 

**epoll优点？**

1、有最大连接数限制，但很大几乎接近无限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口 2G 20万）；
2、效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；
   即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。  
3、内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。
4.线程安全          

**总结** 

1、表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。

2、select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善



#### 内核缓冲区

当一个用户进程要从磁盘读取数据时，内核一般不直接读磁盘，而是将内核缓冲区中的数据复制到进程缓冲区中。

但若是内核缓冲区中没有数据，内核会把对数据块的请求，加入到请求队列，然后把请求用户进程挂起（基本不占CPU资源），为其它用户进程提供服务。

等到系统进程将数据已经读取到内核缓冲区时，把内核缓冲区中的数据读取到用户进程中，才会通知进程，当然不同的io模型，在调度和使用内核缓冲区的方式上有所不同。

你可以认为，read是把数据从内核缓冲区复制到进程缓冲区。write是把进程缓冲区复制到内核缓冲区。

当然，write并不一定导致内核的写动作，比如os可能会把内核缓冲区的数据积累到一定量后，再一次写入。这也就是为什么断电有时会导致数据丢失。

**内核缓冲区，是为了在OS级别，减少对磁盘的读写次数，提高磁盘IO效率，优化磁盘写操作。**



#### java IO读写流程

<img src="https://img-blog.csdnimg.cn/20190105163657587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:67%;" />

<img src="https://img-blog.csdnimg.cn/2019072110111033.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2FsbG93YW5jZWRlYnVn,size_16,color_FFFFFF,t_70" alt="img" style="zoom:67%;" />

（1）客户端请求

Linux通过网卡，读取客户断的请求数据，将数据读取到内核缓冲区。

（2）获取请求数据

服务器从内核缓冲区读取数据到Java进程缓冲区。

（1）服务器端业务处理

Java服务端在自己的用户空间中，处理客户端的请求。

（2）服务器端返回数据

Java服务端已构建好的响应，从用户缓冲区写入系统缓冲区。

（3）发送给客户端

Linux内核通过网络 I/O ，将内核缓冲区中的数据，写入网卡，网卡通过底层的通讯协议，会将数据发送给目标客户端。

##### CPU分配

JAVA使用抢占式分配：优先让优先级高的线程使用 CPU，如果线程的优先级相同，那么会随机选择一个(线程随机性)。

实际上，CPU(中央处理器)使用抢占式调度模式在多个线程间进行着高速的切换。对于CPU的一个核而言，某个时刻，只能执行一个线程，而 CPU的在多个线程间切换速度相对我们的感觉要快，看上去就是在同一时刻运行。

其实，多线程程序并不能提高程序的运行速度，但能够提高程序运行效率，让CPU的使用率更高。

### 死锁的产生和解除 

  **死锁定义：**
 死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态，这些在互相等待的进程称为死锁进程。 

  **产生死锁的必要条件：**  

  互斥条件：一个资源一次只能被一个进程使用 

  请求保持条件：一个进程因请求资源而阻塞时，对已获得独占性资源保持不放 

  不可剥夺条件：进程获得的资源，在未完全使用完之前，不能强行剥夺 

  循环等待条件：若干进程之间形成一种头尾相接的环形等待资源关系 

  **死锁避免：**  

系统对进程发出每一个系统能够满足的资源申请进行动态检查，并根据检查结果决定是否分配资源，如果分配后系统可能发生死锁,则不予分配，否则予以分配。这是一种保证系统不进入死锁状态的动态策略。 

  **死锁预防：**
 只要打破四个必要条件之一就能有效预防死锁的发生： 

 ● **打破互斥条件：** 允许资源能共享使用 
 ● **打破不可剥夺条件：** 当一进程占有一独占性资源后又申请一独占性资源而无法满足，则退出原占有的资源。 
 ● **打破请求并保持条件：** 采用资源预先分配策略，即进程运行前申请全部资源，满足则运行，不然就等待，这样就不会占有且申请。 
 ● **打破循环等待条件：** 实现资源有序分配策略，对所有设备实现分类编号，所有进程只能采用按序号递增的形式申请资源。 

  **死锁避免和死锁预防的区别：**   死锁预防是设法至少破坏产生死锁的四个必要条件之一，严格的防止死锁的出现；而死锁避免则不那么严格的限制产生死锁的必要条件的存在，因为即使死锁的必要条件存在，也不一定发生死锁。死锁避免是在系统运行过程中注意避免死锁的最终发生。

**解除死锁**

- 资源剥夺法：挂起某些死进程并抢夺它的资源，以便让其他进程继续推进
- 撤销进程法：强制撤销部分，甚至全部死锁进程并剥夺这些进程的资源
- 进程回退法：让进程回退到足以避免死锁的地步

### 虚拟内存

 一个进程的虚拟地址空间包括内核虚拟内存和用户栈等等。  

![虚拟地址.PNG](https://img2018.cnblogs.com/blog/1297993/201909/1297993-20190930103057635-739146041.png)

**页：**将进程划分的块，对应的大小就叫页面大小

**页框：**将内存划分的块

一个页里有一个页框，理论上，页和页框的大小相同

**页表：**页和页框一一对应的关系表，存放在内存中，通过页表能查找到哪个页对应哪个页框

**为什么要有虚拟内存？**

**物理内存：物理地址即实际内存地址**

1.因为机器物理内存是有限的，当有多个进程要执行的时候，都要给4G内存，当机器内存小的时候，这很快就分配完了，于是没有得到分配资源的进程就只能等待，当一个进程执行完了以后，再将等待的进程装入内存。这种频繁的装入内存的操作是很没效率的。
2.由于指令都是直接访问物理内存的，那么我这个进程就可以修改其他进程的数据，甚至会修改内核地址空间的数据，这是我们不想看到的
3.因为内存是随机分配的，所以程序运行的地址也是不正确的。

**虚拟内存：**

每个进程得到一个4G虚拟内存，（可以当作是每个进程认为自己拥有4G的空间，但实际上，在虚拟内存对应的物理内存上，可能只对应一点点的物理内存，即实际使用了多少内存就对应多少物理内存）

进程得到的这4G虚拟内存是一个**连续的地址空间（这也只是进程认为），而实际上，它通常是被分隔成多个物理内存碎片，还有一部分存储在外部磁盘存储器上，在需要时进行数据交换。**

**进程访问一个内存地址，会发生**

1.每次我要访问地址空间上的某一个地址，都需要把虚拟地址翻译为实际物理内存地址
2.所有进程共享这整一块物理内存，每个进程只把自己目前需要的虚拟地址空间映射到物理内存上
3.进程需要知道哪些地址空间上的数据在物理内存上，哪些不在（可能这部分存储在磁盘上），还有在物理内存上的哪里，这就需要通过页表来记录
4.页表的每一个表项分两部分，第一部分记录此页是否在物理内存上，第二部分记录物理内存页的地址（如果在的话）
5.当进程访问某个虚拟地址的时候，就会先去看页表，如果发现对应的数据不在物理内存上，就会发生缺页异常
6.缺页异常的处理过程，操作系统立即阻塞该进程，并将硬盘里对应的页换入内存，然后使该进程就绪，如果内存已经满了，没有空地方了，那就找一个页覆盖，至于具体覆盖的哪个页，就需要看操作系统的页面置换算法是怎么设计的了。

内存被分为大小相等的多个块,称为页(Page).每个页都是一段连续的地址。

对于进程来看,逻辑上貌似有很多内存空间，其中一部分对应物理内存上的一块(称为页框，通常页和页框大小相等)，还有一些没加载在内存中的对应在硬盘上。

![这里写图片描述](https://img-blog.csdn.net/20160425230659015)

虚拟内存实际上可以比物理内存大。

虚拟内存和物理内存的匹配是通过页表实现，页表存在MMU中。

页表中每个项通常为32位，既4byte,除了存储虚拟地址和页框地址之外，还会存储一些标志位，比如是否缺页，是否修改过，写保护等。

可以把MMU想象成一个接收虚拟地址项返回物理地址的方法。

**进程中的内核地址空间（1G）直接映射到物理内存，即所有的进程都共享这1G内核空间，只有3G用户内存是进程私有的**

**为什么需要区分用户空间和内核空间？**

在 CPU 的所有指令中，有些指令是非常危险的，如果错用，将导致系统崩溃，比如清内存、设置时钟等。如果允许所有的程序都可以使用这些指令，那么系统崩溃的概率将大大增加。
所以，CPU 将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通应用程序只能使用那些不会造成灾难的指令。比如 Intel 的 CPU 将特权等级分为 4 个级别：Ring0~Ring3。
其实 Linux 系统只使用了 Ring0 和 Ring3 两个运行级别(Windows 系统也是一样的)。当进程运行在 Ring3 级别时被称为运行在用户态，而运行在 Ring0 级别时被称为运行在内核态。

**当进程运行在内核空间时就处于内核态，而进程运行在用户空间时则处于用户态。**

**页表存放在内核空间中**



![img](https://img-blog.csdn.net/20180830111258836?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x2eWliaW44OTA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![img](https://img-blog.csdn.net/20180830114901391?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x2eWliaW44OTA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

**共享同一块内存的两个进程，当内存里面内存发送变化时，另一个进程能马上知道**

1.我们的cpu想访问虚拟地址所在的虚拟页(VP3)，根据页表，找出页表中第三条的值.判断有效位。 如果有效位为1，DRMA缓存命中，根据物理页号，找到物理页当中的内容，返回。
2.若有效位为0，参数缺页异常，调用内核缺页异常处理程序。内核通过页面置换算法选择一个页面作为被覆盖的页面，将该页的内容刷新到磁盘空间当中。然后把VP3映射的磁盘文件缓存到该物理页上面。然后页表中第三条，有效位变成1，第二部分存储上了可以对应物理内存页的地址的内容。
3.缺页异常处理完毕后，返回中断前的指令，重新执行，此时缓存命中，执行1。
4.将找到的内容映射到告诉缓存当中，CPU从告诉缓存中获取该值，结束。

**总结**

当每个进程创建的时候，内核会为进程分配4G的虚拟内存，当进程还没有开始运行时，这只是一个内存布局。实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射）。这个时候数据和代码还是在磁盘上的。当运行到对应的程序时，进程去寻找页表，发现页表中地址没有存放在物理内存上，而是在磁盘上，于是发生缺页异常，于是将磁盘上的数据拷贝到物理内存中。

另外在进程运行过程中，要通过malloc来动态分配内存时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。

可以认为虚拟空间都被映射到了磁盘空间中（事实上也是按需要映射到磁盘空间上，通过mmap，mmap是用来建立虚拟空间和磁盘空间的映射关系的）

**优点**

1.既然每个进程的内存空间都是一致而且固定的（32位平台下都是4G），所以链接器在链接可执行文件时，可以设定内存地址，而不用去管这些数据最终实际内存地址，这交给内核来完成映射关系
2.当不同的进程使用同一段代码时，比如库文件的代码，在物理内存中可以只存储一份这样的代码，不同进程只要将自己的虚拟内存映射过去就好了，这样可以节省物理内存
3.在程序需要分配连续空间的时候，只需要在虚拟内存分配连续空间，而不需要物理内存时连续的，实际上，往往物理内存都是断断续续的内存碎片。这样就可以有效地利用我们的物理内存

### 用户态和内核态的共享内存

也是通过页表实现

映射给内核空间的物理页面也同样映射一份给用户进程，并且修改掉权限属性。这样的话分属不同地址空间的两块内存实际上对应的是同一个物理页面，一方修改数据，另一方也能够实时看到变化。



### 为什么会出现分段、分页？

**为了更好的管理计算机内存**

#### 之前的问题

某个程序大小是10M，然后，就需要有**连续的**10M内存空间才能把这个程序装载到内存里面。如果无法找到连续的10M内存，就无法把这个程序装载进内存里面，程序也就无法得到运行。

##### 1.地址空间不隔离。

只能操作连续的地址空间，一旦不小心操作了其它地址空间则程序出错。

假设我有两个程序，一个是程序A，一个是程序B。程序A在内存中的地址假设是0x00000000~0x00000099，程序B在内存中的地址假设是0x00000100~x00000199。那么假设你在程序A中，本来想操作地址0x00000050，不小心手残操作了地址0x00000150，那么，不好的事情或许会发生。你影响了程序A也就罢了，你把程序B也搞了一顿。

##### 2.程序运行时地址不确定

每次装载进程序的内存位置发生改变时，用户无法及时更改操作。

因为我们程序每次要运行的时候，都是需要装载到内存中的，假设你在程序中写死了要操作某个地址的内存，例如你要地址0x00000010。但是问题来了，你能够保证你操作的地址0x00000010真的就是你原来想操作的那个位置吗？很可能程序第一次装载进内存的位置是0x00000000~0x00000099，而程序第二次运行的时候，这个程序装载进内存的位置变成了0x00000200~0x00000299，而你操作的0x00000010地址压根就不是属于这个程序所占有的内存。

##### 3.内存使用率低下

举个例子，假设你写了3个程序，其中程序A大小为10M，程序B为70M，程序C的大小为30M你的计算机的内存总共有100M。

这三个程序加起来有110M，显然这三个程序是无法同时存在于内存中的。

并且最多只能够同时运行两个程序。可能是这样的，程序A占有的内存空间是0x00000000～0x00000009，程序B占有的内存空间是0x00000010～0x00000079。假设这个时候程序C要运行该怎么做？可以把其中的一个程序换出到磁盘上，然后再把程序C装载到内存中。假设是把程序A换出，那么程序C还是无法装载进内存中，因为内存中空闲的连续区域有两块，一块是原来程序A占有的那10M，还有就是从0x00000080～0x00000099这20M，所以，30M的程序C无法装载进内存中。那么，唯一的办法就是把程序B换出，保留程序A，但是，此时会有60M的内存无法利用起来，很浪费对吧。

### 分段存储管理

将一个程序分成代码段、数据段、堆栈段等。

**把虚拟地址空间映射到了物理地址空间，并且你写的程序操作的是虚拟地址**。

解决上面1.2问题，**分段机制映射的是一片连续的物理内存**，无法解决问题3.

![img](https://img-blog.csdnimg.cn/20190308111258854.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5nbG9uZ180NDQ0,size_16,color_FFFFFF,t_70)

### 分页存储管理

将这些段，例如代码段分成均匀的小块，然后这些给这些小块编号，然后就可以放到内存中去，由于编号了的，所以也不怕顺序乱

分页仍然是**把虚拟地址空间映射到了物理地址空间**但是粒度更小，单位不是整个程序，而是某个“页”。

分页，它的虚拟地址空间仍然是连续的，但是，每一页映射后的物理地址就不一定是连续的了。

### 段页式管理

先将程序分段（代码段，数据段，堆栈段），再将分好的段进行分页，例如代码段分成均匀的小块，然后这些给这些小块编号，然后就可以放到内存中去，由于编号了的，所以也不怕顺序乱。我们就能通过段号，页号，页内偏移找到程序的地址

### **分页和分段的区别**

**主要区别：粒度大小**

**a)**页是信息的物理单位，分页是为实现离散分配方式，以消减内存的外零头，提高内存的利用率；或者说，分页仅仅是由于系统管理的需要，而不是用户的需要（也是对用户透明的）。

段是信息的逻辑单位，它含有一组其意义相对完整的信息（比如数据段、代码段和堆栈段等）。分段的目的是为了能更好的满足用户的需要（用户也是可以使用的）。

**b)**页的大小固定且由系统确定，把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而一个系统只能有一种大小的页面。段的长度却不固定，决定于用户所编写的程序，通常由编辑程序在对源程序进行编辑时，根据信息的性质来划分。

**c)**分页的作业地址空间是一维的，即单一的线性空间，程序员只须利用一个记忆符（线性地址的16进制表示），即可表示一地址。

分段的作业地址空间是二维的，程序员在标识一个地址时，既需给出段名（比如数据段、代码段和堆栈段等），又需给出段内地址。

**d)**页和段都有存储保护机制。但存取权限不同：段有读、写和执行三种权限；而页只有读和写两种权限。

### 逻辑地址 ->>物理地址

**逻辑地址 = 页号 + 页内地址**

**物理地址 = 块号 + 页内地址**

1.已知某个分页系统，页面大小为1K(即1024字节)，某一个作业有4个页面，分别装入到主存的第3、4、6、8块中，求**逻辑地址2100**对应的物理地址。

**解**

第一步：求该逻辑地址的页号 = 2100/1024=2 （整除）
第二步：求它的页内偏移量 = 2100 % 1024 =52 （取余）
第三步：根据题目产生页表：
页号   页框号/帧号
  0      3
  1      4
  2      6 
  3      8
第四步：根据逻辑地址的页号查出物理地址的页框号/帧号： 
如上图，逻辑地址的第2页对应物理地址的第6块。
第五步：求出物理地址 = 6*1024 + 52 = 6196

**十六进制逻辑地址转物理地址**

一分页存储管理系统中逻辑地址长度为16位，页面大小为4KB字节，现有一逻辑地址为2F6AH，且第0、1、2页依次存放在物理块5、10、11中。求逻辑地址2F6AH对应的物理地址 

**解**

第一步：将逻辑地址2F6AH转换为二进制为：0010 1110 0110 1010 
第二步：由于页面大小为4KB字节，（4KB=2的12次方）。所以逻辑地址的后12位为“页内地址”(也叫做页内偏移量) 
第三步：由于逻辑地址的后12位为页内地址，所以剩下的前4位为页号：即0010为页号 
第三步：根据页表可知，0010(十进制为2)对于的页框号（块）为11(二进制为1011) 
所以最终的物理地址为：1011 1111 0110 1010 
即BF6AH

### 僵尸进程与孤儿进程

linux中，子进程由父进程创建。子进程和父进程的运行是一个异步过程，即父进程永远无法预测子进程什么时候结束。

当一个 进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。

**孤儿进程：** 一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

**僵尸进程：**  一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。

**问题及危害**

unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到。

这种机制就是: 在每个进程退出的时候,内核释放该进程所有的资源,包括打开的文件,占用的内存等。 但是仍然为其保留一定的信息(包括进程号the process ID,退出状态the termination status of the process,运行时间the amount of CPU time taken by the process等)。

直到父进程通过wait / waitpid来取时才释放。

**问题** 

如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其**进程号就会一直被占用**，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。

**孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上**。

init进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。

每当出现一个孤儿进程的时候，内核就把孤 儿进程的父进程设置为init，而init进程会**循环地wait()它的已经退出的子进程**。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。**因此孤儿进程并不会有什么危害。**

**任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。**

用PS命令查看僵尸进程 状态未 ‘Z’

**解决方法**

1.**信号机制**

子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。

**2.fork两次**

子进程再创建子进程

原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。

即 只需父进程处理第一个子进程 第二个子进程交由init进程处理

### 文件描述符fd

fd是一个非负整数，起到 **索引** 作用。

Linux中所有都是文件，一个Linux进程可以打开成百上千个文件，为了表示和区分已打开的文件，linux为每个文件分配一个编号 即 fd。

一个linux进程启动后会在内核空间开辟一块PCB控制块，PCB内部有一个 文件描述符表，记录当前进程所有打开的文件。

![Linux文件描述符表示意图](http://c.biancheng.net/uploads/allimg/190410/1-1Z4101H45S13.gif)

**文件描述符fd-->>文件指针-->>i-node指针**

**Socket套接字也是文件描述符fd存放在文件描述符表中**

**Select**

![img](https://pic4.zhimg.com/80/v2-0cccb4976f8f2c2f8107f2b3a5bc46b3_1440w.jpg)

![img](https://pic4.zhimg.com/80/v2-a86b203b8d955466fff34211d965d9eb_1440w.jpg)

```
//首先程序（用户态）将所有的socket集合拷贝到内核态
int[] fds=new int[];//数组存放socket
//进程内核轮询 已注册的socket fds
for(int i=0;i<fds.length;i++){
select...
}
该select过程阻塞直到有一个socket接受到数据，返回唤醒进程。
然后程序（用户态）遍历fds判断是哪个socket收到数据，做出处理。
```

**问题**

遍历两次 一次内核 一次用户

每次用户态需要将所有的socket集合拷贝到内核态

单个进程可监视的fd数量有限

**poll**

本质和select一样，但没有最大连接数限制，基于链表存储。

**epoll**

![img](https://pic4.zhimg.com/80/v2-5c552b74772d8dbc7287864999e32c4f_1440w.jpg)

```
int epoll_create(int size);  //建立一个epoll对象
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); 
//epoll对象中添加套接字（连接）
int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout);
//收集发生事件的连接 检查就绪队列
```

每个epoll对象有一个独立的eventpoll结构体，用于存放 添加进来的事件。

<img src="https://pic4.zhimg.com/80/v2-e63254878f67751dcc07a25b93f974bb_1440w.jpg" alt="img" style="zoom:80%;" />

**rdlist**是就绪列表，双向链表。

**rbr**是socket列表，红黑树。O（log(N)）

epoll是通过内核与用户空间mmap同一块内存实现的。

**mmap将用户空间的一块地址和内核空间的一块地址同时映射到相同的一块物理内存地址**（不管是用户空间还是内核空间都是虚拟地址，最终要通过地址映射映射到物理地址），使得这块物理内存对内核和对用户均可见，减少用户态和内核态之间的数据交换。

内核可以直接看到epoll监听的句柄，效率高。  

### 内、外碎片

内部碎片是已经被分配出去的的内存空间大于请求所需的内存空间，**指的是在进程使用中产生的**，即，它们是被进程所占用的，但是进程并没有利用它们。（当然，系统也无法利用，除非进程释放了这些内存）

外部碎片是指还没有分配出去，但是由于大小太小而无法分配给申请空间的新进程的内存空间空闲块，**还没分配的小的、分散的内存块**

分页管理会造成内碎片，分段管理会造成外碎片                     
